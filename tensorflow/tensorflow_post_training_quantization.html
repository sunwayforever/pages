<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>Tensorflow Post Training Quantization</title>


<link rel="stylesheet" type="text/css" href="/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="./htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../htmlize.css"/>
<link rel="stylesheet" type="text/css" href="/readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="./readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="../readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
</head>
<body>
<div id="content" class="content">
<h1 class="title">Tensorflow Post Training Quantization</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0000007">1. Tensorflow Post Training Quantization</a>
<ul>
<li><a href="#org0000000">1.1. 测试模型</a></li>
<li><a href="#ID-30721fc0-2acb-4612-94b6-9b0d96e2e2e2">1.2. Dynamic Range Quantization</a></li>
<li><a href="#org0000004">1.3. Full Integer Quantization</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000007" class="outline-2">
<h2 id="org0000007"><span class="section-number-2">1.</span> Tensorflow Post Training Quantization</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="https://www.tensorflow.org/lite/performance/post_training_quantization">https://www.tensorflow.org/lite/performance/post_training_quantization</a>
</p>
</div>

<div id="outline-container-org0000000" class="outline-3">
<h3 id="org0000000"><span class="section-number-3">1.1.</span> 测试模型</h3>
<div class="outline-text-3" id="text-1-1">
<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf
import numpy as np
from tensorflow.keras import layers, losses, metrics, optimizers, models

X = tf.random.uniform([100, 1], minval=1, maxval=10.0)
Y = tf.pow(X, 2)

tf.keras.backend.clear_session()

model = models.Sequential()
model.add(layers.Dense(100, input_shape=(1,), activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(1))

model.summary()

model.compile(optimizer="adam", loss="mse")
history = model.fit(X, Y, batch_size=20, epochs=2000, verbose=0)
print(model.predict([2.0, 10.0, 20]))

model.save("/tmp/pow")
</pre>
</div>

<p>
Model: "sequential"
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
Layer (type)                 Output Shape              Param #   
<code>===============================================================</code>
dense (Dense)                (None, 100)               200       
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_1 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_2 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_3 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_4 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_5 (Dense)              (None, 1)                 101       
<code>===============================================================</code>
Total params: 40,701
Trainable params: 40,701
Non-trainable params: 0
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
[[  3.9891944]
 [ 98.814255 ]
 [251.58577  ]]
</p>
</div>
</div>

<div id="outline-container-ID-30721fc0-2acb-4612-94b6-9b0d96e2e2e2" class="outline-3">
<h3 id="ID-30721fc0-2acb-4612-94b6-9b0d96e2e2e2"><span class="section-number-3">1.2.</span> Dynamic Range Quantization</h3>
<div class="outline-text-3" id="text-1-2">
<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model("/tmp/pow")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]

tflite = converter.convert()
with open ("/tmp/pow-q.tflite","wb") as f:
    f.write(tflite)
    print("size of tflite-q:", len(tflite))

</pre>
</div>

<p>
size of tflite-q: 46496
</p>

<ol class="org-ol">
<li>node 的权重会进行量化, 但 node 的输入输出还是 float32</li>

<li>最初 weight 会在运行时被还原成 float32, 以便收集校准数据</li>

<li>收集到足够数据后 activation 会在运行时被量化成 int8, 再用整型来计算, 而不是把
weight 还原成float32 后用 float32 来计算, 但输出还是 float32</li>

<li>bias 不会进行量化 (可能因为它的范围过大)</li>

<li>不支持量化的 node 会跳过, 继续用 float32</li>
</ol>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-function-name">Eval</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>)
  <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">filter</span> = GetInput(context, node, kWeightsTensor);
  <span class="org-keyword">switch</span> (filter-&gt;type)
    <span class="org-keyword">case</span> kTfLiteFloat32:
      <span class="org-comment-delimiter">// </span><span class="org-comment">&#27491;&#24120;&#30340;&#20840; float32 &#30340;&#36816;&#31639;</span>
    <span class="org-keyword">case</span> kTfLiteInt8:
      <span class="org-comment-delimiter">// </span><span class="org-comment">wegiht &#20026; int8</span>
      EvalQuantized&lt;kernel_type&gt;(context, node, params, data, input,
                                 filter, bias, output);

<span class="org-type">TfLiteStatus</span> <span class="org-function-name">EvalQuantized</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>,
                           <span class="org-type">TfLiteFullyConnectedParams</span>* <span class="org-variable-name">params</span>, <span class="org-type">OpData</span>* <span class="org-variable-name">data</span>,
                           <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">input</span>,
                           <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">filter</span>, <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">bias</span>,
                           <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">output</span>)
  <span class="org-comment-delimiter">// </span><span class="org-comment">&#21160;&#24577;&#33539;&#22260;&#37327;&#21270;</span>
  <span class="org-keyword">if</span> (input-&gt;type == kTfLiteFloat32)
    <span class="org-keyword">return</span> EvalHybrid(context, node, params, data, input, filter, bias,
                      input_quantized, scaling_factors, accum_scratch, row_sums,
                      input_offsets, output);      
  <span class="org-keyword">else</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#20840;&#25972;&#25968;</span>
    <span class="org-constant">reference_ops</span>::FullyConnected(
        op_params, GetTensorShape(input), GetTensorData&lt;<span class="org-type">uint8_t</span>&gt;(input),
        GetTensorShape(filter), GetTensorData&lt;<span class="org-type">uint8_t</span>&gt;(filter),
        GetTensorShape(bias), GetTensorData&lt;<span class="org-type">int32_t</span>&gt;(bias),
        GetTensorShape(output), GetTensorData&lt;<span class="org-type">uint8_t</span>&gt;(output));


<span class="org-type">TfLiteStatus</span> <span class="org-function-name">EvalHybrid</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>,
                        <span class="org-type">TfLiteFullyConnectedParams</span>* <span class="org-variable-name">params</span>, <span class="org-type">OpData</span>* <span class="org-variable-name">data</span>,
                        <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">input</span>, <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">filter</span>,
                        <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">bias</span>, <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">input_quantized</span>,
                        <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">scaling_factors</span>,
                        <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">accum_scratch</span>, <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">row_sums</span>,
                        <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">input_offsets</span>, <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">output</span>)
  <span class="org-comment-delimiter">// </span><span class="org-comment">Quantize input from float to uint8 + quantization params (scaling factor).</span>
  <span class="org-type">float</span>* <span class="org-variable-name">scaling_factors_ptr</span> = GetTensorData&lt;<span class="org-type">float</span>&gt;(scaling_factors);
  <span class="org-type">int8_t</span>* <span class="org-variable-name">quant_data</span> = GetTensorData&lt;<span class="org-type">int8_t</span>&gt;(input_quantized);
  <span class="org-keyword">const</span> <span class="org-type">int8_t</span>* <span class="org-variable-name">filter_data</span> = GetTensorData&lt;<span class="org-type">int8_t</span>&gt;(filter);
  <span class="org-keyword">const</span> <span class="org-type">float</span>* <span class="org-variable-name">input_ptr</span> = GetTensorData&lt;<span class="org-type">float</span>&gt;(input);
  <span class="org-constant">tensor_utils</span>::BatchQuantizeFloats(
    input_ptr, batch_size, input_size, quant_data, scaling_factors_ptr,
    input_offset_ptr, params-&gt;asymmetric_quantize_inputs);
  <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">b</span> = 0; b &lt; batch_size; ++b) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">Incorporate scaling of the filter.</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#26368;&#32456;&#20351;&#29992;&#30340; scale &#26159; input_scale * filter_scale</span>
    scaling_factors_ptr[b] *= filter-&gt;params.scale;
  }

  <span class="org-comment-delimiter">// </span><span class="org-comment">Compute output += weight * quantized_input</span>
  <span class="org-type">int32_t</span>* <span class="org-variable-name">scratch</span> = GetTensorData&lt;<span class="org-type">int32_t</span>&gt;(accum_scratch);
  <span class="org-constant">tensor_utils</span>::MatrixBatchVectorMultiplyAccumulate(
    filter_data, num_units, input_size, quant_data, scaling_factors_ptr,
    batch_size, GetTensorData&lt;<span class="org-type">float</span>&gt;(output), <span class="org-comment-delimiter">/*</span><span class="org-comment">per_channel_scale=</span><span class="org-comment-delimiter">*/</span><span class="org-constant">nullptr</span>,
    input_offset_ptr, scratch, row_sums_ptr, &amp;data-&gt;compute_row_sums,
    <span class="org-constant">CpuBackendContext</span>::GetFromContext(context));

  <span class="org-comment-delimiter">// </span><span class="org-comment">&#26368;&#32456;&#30340; output &#26159; float</span>
  <span class="org-constant">tensor_utils</span>::ApplyActivationToVector(
    GetTensorData&lt;<span class="org-type">float</span>&gt;(output), batch_size * num_units, params-&gt;activation,
    GetTensorData&lt;<span class="org-type">float</span>&gt;(output));

<span class="org-comment-delimiter">// </span><span class="org-comment">&#30697;&#38453;&#36816;&#31639;&#26102;&#36755;&#20837;&#26159;&#20004;&#20010; int8 &#30340;&#30697;&#38453;, &#20294;&#36755;&#20986;&#30340;&#32467;&#26524;&#26159; float</span>
<span class="org-type">void</span> <span class="org-function-name">PortableMatrixBatchVectorMultiplyAccumulate</span>(
    <span class="org-keyword">const</span> <span class="org-type">int8_t</span>* <span class="org-variable-name">__restrict__</span> matrix, <span class="org-keyword">const</span> <span class="org-type">int</span> <span class="org-variable-name">m_rows</span>, <span class="org-keyword">const</span> <span class="org-type">int</span> <span class="org-variable-name">m_cols</span>,
    <span class="org-keyword">const</span> <span class="org-type">int8_t</span>* <span class="org-variable-name">__restrict__</span> vectors, <span class="org-keyword">const</span> <span class="org-type">float</span>* <span class="org-variable-name">scaling_factors</span>,
    <span class="org-type">int</span> <span class="org-variable-name">n_batch</span>, <span class="org-type">float</span>* <span class="org-variable-name">__restrict__</span> result) {
    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">batch</span> = 0; batch &lt; n_batch; ++batch, vectors += m_cols) {
        <span class="org-keyword">const</span> <span class="org-type">float</span> <span class="org-variable-name">batch_scaling_factor</span> = scaling_factors[batch];
        <span class="org-comment-delimiter">// </span><span class="org-comment">Get the address of the first row.</span>
        <span class="org-keyword">const</span> <span class="org-type">int8_t</span>* <span class="org-variable-name">row_ptr</span> = matrix;
        <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">row</span> = 0; row &lt; m_rows; ++row) {
            <span class="org-comment-delimiter">// </span><span class="org-comment">Initialize the dot product sum for the row to 0.</span>
            <span class="org-type">int32_t</span> <span class="org-variable-name">dotprod</span> = 0;
            <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">col</span> = 0; col &lt; m_cols; ++col, ++row_ptr) {
                dotprod += (*row_ptr) * (vectors[col]);
            }  <span class="org-comment-delimiter">// </span><span class="org-comment">for col</span>
            *result += dotprod * batch_scaling_factor;
            ++result;
        }  <span class="org-comment-delimiter">// </span><span class="org-comment">for row</span>
    }    <span class="org-comment-delimiter">// </span><span class="org-comment">for batch</span>
}
</pre>
</div>
</div>
</div>


<div id="outline-container-org0000004" class="outline-3">
<h3 id="org0000004"><span class="section-number-3">1.3.</span> Full Integer Quantization</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>weight 的对称量化, 即 zero_point 为 0</li>
<li>activation 是非对称量化</li>
<li>zero_point 为整数</li>
<li>tflite 的量化规范来自 <a href="gemmlowp_quantization.html#org0000000">Gemmlowp Quantization</a></li>
</ul>

<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model("/tmp/pow")

X = tf.random.uniform([100, 1], minval=1, maxval=10.0)


def representative_dataset_gen():
    for i in range(10):
        yield [[X[i]]]


converter.representative_dataset = representative_dataset_gen

converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

tflite = converter.convert()
with open("/tmp/pow-q.tflite", "wb") as f:
    f.write(tflite)
    print("size of tflite-q:", len(tflite))
</pre>
</div>

<p>
size of tflite-q: 46944
</p>

<ol class="org-ol">
<li>所有数据, 包含模型的输入, 都会量化, 且所有 node 的输入输出都是 int8. 由于量化需要依据 (min, max), 针对模型输入, 需要提供一个 representative_dataset_gen,
用来提供这一数据, 才能完成对 input 的量化</li>

<li><p>
全整数的量化需要 node 本身支持全整数运算, 否则量化过程会失败, 例如 floor 是无法量化的 op, 所以下面的模型使用全整数量化时会失败
</p>

<pre class="example" id="org0000003">
RuntimeError: Quantization not yet supported for op: FLOOR
</pre>

<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers

n = 100

X = tf.random.uniform([n, 1], minval = 1, maxval = 10.)
Y = tf.pow(X,2)

tf.keras.backend.clear_session()

inputs = keras.Input(shape = (1, ))
dense = layers.Dense(50, activation = "relu")(inputs)
floor = tf.floor(dense)
outputs = layers.Dense(1)(floor)

model = keras.Model(inputs, outputs)
model.compile(optimizer="adam",loss="mse")
history = model.fit(X,Y,batch_size = 20,epochs = 50, verbose = 0)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
X = tf.random.uniform([100, 1], minval=1, maxval=10.0)
def representative_dataset_gen():
    for i in range(10):
        yield [[X[i]]]

converter.representative_dataset = representative_dataset_gen
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

tflite = converter.convert()
</pre>
</div>

<p>
tflite 目前不支持 floor 的量化, 但也许通过一个查找表可以实现.
</p></li>
</ol>
</div>
</div>
</div>




<div id="outline-container-org000000a" class="outline-2 references">
<h2 id="org000000a">Backlinks</h2>
<div class="outline-text-2" id="text-org000000a">
<p>
<a href="quantization.html#ID-6ad56dfa-9772-478b-9872-6f8294d6cb19">Quantization</a>
(<i>Quantization &gt; Tensorflow Post Training Quantization</i>):   <a href="tensorflow_post_training_quantization.html#ID-0d9ef45d-9547-4523-a104-c52a3e9c6673">Tensorflow Post Training Quantization</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway@dogdog.run<br />
Date: 2021-08-24 Tue 00:00<br />
Last updated: 2022-03-07 Mon 21:33</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
</div>
</body>
</html>