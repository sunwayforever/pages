<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-01-26 Wed 11:42 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Tensorflow Post Training Quantization</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Wei Sun (孙伟)" />
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<h1 class="title">Tensorflow Post Training Quantization</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org9f5c267">1. Tensorflow Post Training Quantization</a>
<ul>
<li><a href="#org2246fb1">1.1. 测试模型</a></li>
<li><a href="#org20affda">1.2. 动态范围量化</a></li>
<li><a href="#org253c4cf">1.3. 全整数量化</a></li>
<li><a href="#orgd4726fc">1.4. 量化误差过大</a></li>
<li><a href="#orgcb9a392">1.5. 无法量化的操作</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org9f5c267" class="outline-2">
<h2 id="org9f5c267"><span class="section-number-2">1</span> Tensorflow Post Training Quantization</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="https://www.tensorflow.org/lite/performance/post_training_quantization">https://www.tensorflow.org/lite/performance/post_training_quantization</a>
</p>
</div>

<div id="outline-container-org2246fb1" class="outline-3">
<h3 id="org2246fb1"><span class="section-number-3">1.1</span> 测试模型</h3>
<div class="outline-text-3" id="text-1-1">
<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf
import numpy as np
from tensorflow.keras import layers, losses, metrics, optimizers, models

X = tf.random.uniform([100, 1], minval=1, maxval=10.0)
Y = tf.pow(X, 2)

tf.keras.backend.clear_session()

model = models.Sequential()
model.add(layers.Dense(100, input_shape=(1,), activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(100, activation="relu"))
model.add(layers.Dense(1))

model.summary()

model.compile(optimizer="adam", loss="mse")
history = model.fit(X, Y, batch_size=20, epochs=2000, verbose=0)
print(model.predict([2.0, 10.0, 20]))

model.save("/tmp/pow")
</pre>
</div>

<p>
Model: "sequential"
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
Layer (type)                 Output Shape              Param #   
<code>===============================================================</code>
dense (Dense)                (None, 100)               200       
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_1 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_2 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_3 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_4 (Dense)              (None, 100)               10100     
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
dense_5 (Dense)              (None, 1)                 101       
<code>===============================================================</code>
Total params: 40,701
Trainable params: 40,701
Non-trainable params: 0
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
[[  3.9891944]
 [ 98.814255 ]
 [251.58577  ]]
</p>
</div>
</div>

<div id="outline-container-org20affda" class="outline-3">
<h3 id="org20affda"><span class="section-number-3">1.2</span> 动态范围量化</h3>
<div class="outline-text-3" id="text-1-2">
<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model("/tmp/pow")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]

tflite = converter.convert()
with open ("/tmp/pow-q.tflite","wb") as f:
    f.write(tflite)
    print("size of tflite-q:", len(tflite))

</pre>
</div>

<p>
size of tflite-q: 46496
</p>

<ol class="org-ol">
<li><p>
node 的权重会进行量化, 但 node 的输入输出还是 float32, 但 node 在 eval 时实际
上会把 input 量化后再用整型来计算, 提高计算速度, 而不是把 weight 还原成
float32 后用 float32 来计算
</p>

<p>
把 input 按照本次运行时的范围进行量化后再计算, 即是所谓的 "dynamic range
quantization"
</p></li>

<li>bias 不会进行量化 (可能因为它的范围过大)</li>

<li>不支持量化的 node 会跳过, 继续用 float32</li>
</ol>

<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold; text-decoration: underline;">TfLiteStatus</span> <span style="font-weight: bold;">Eval</span>(<span style="font-weight: bold; text-decoration: underline;">TfLiteContext</span>* <span style="font-weight: bold; font-style: italic;">context</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteNode</span>* <span style="font-weight: bold; font-style: italic;">node</span>)
  <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">filter</span> = GetInput(context, node, kWeightsTensor);
  <span style="font-weight: bold;">switch</span> (filter-&gt;type)
    <span style="font-weight: bold;">case</span> kTfLiteFloat32:
      <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">&#27491;&#24120;&#30340;&#20840; float32 &#30340;&#36816;&#31639;</span>
    <span style="font-weight: bold;">case</span> kTfLiteInt8:
      <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">wegiht &#20026; int8</span>
      EvalQuantized&lt;kernel_type&gt;(context, node, params, data, input,
                                 filter, bias, output);

<span style="font-weight: bold; text-decoration: underline;">TfLiteStatus</span> <span style="font-weight: bold;">EvalQuantized</span>(<span style="font-weight: bold; text-decoration: underline;">TfLiteContext</span>* <span style="font-weight: bold; font-style: italic;">context</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteNode</span>* <span style="font-weight: bold; font-style: italic;">node</span>,
                           <span style="font-weight: bold; text-decoration: underline;">TfLiteFullyConnectedParams</span>* <span style="font-weight: bold; font-style: italic;">params</span>, <span style="font-weight: bold; text-decoration: underline;">OpData</span>* <span style="font-weight: bold; font-style: italic;">data</span>,
                           <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">input</span>,
                           <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">filter</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">bias</span>,
                           <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">output</span>)
  <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">&#21160;&#24577;&#33539;&#22260;&#37327;&#21270;</span>
  <span style="font-weight: bold;">if</span> (input-&gt;type == kTfLiteFloat32)
    <span style="font-weight: bold;">return</span> EvalHybrid(context, node, params, data, input, filter, bias,
                      input_quantized, scaling_factors, accum_scratch, row_sums,
                      input_offsets, output);      
  <span style="font-weight: bold;">else</span>
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">&#20840;&#25972;&#25968;</span>
    <span style="font-weight: bold; text-decoration: underline;">reference_ops</span>::FullyConnected(
        op_params, GetTensorShape(input), GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">uint8_t</span>&gt;(input),
        GetTensorShape(filter), GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">uint8_t</span>&gt;(filter),
        GetTensorShape(bias), GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">int32_t</span>&gt;(bias),
        GetTensorShape(output), GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">uint8_t</span>&gt;(output));


<span style="font-weight: bold; text-decoration: underline;">TfLiteStatus</span> <span style="font-weight: bold;">EvalHybrid</span>(<span style="font-weight: bold; text-decoration: underline;">TfLiteContext</span>* <span style="font-weight: bold; font-style: italic;">context</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteNode</span>* <span style="font-weight: bold; font-style: italic;">node</span>,
                        <span style="font-weight: bold; text-decoration: underline;">TfLiteFullyConnectedParams</span>* <span style="font-weight: bold; font-style: italic;">params</span>, <span style="font-weight: bold; text-decoration: underline;">OpData</span>* <span style="font-weight: bold; font-style: italic;">data</span>,
                        <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">input</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">filter</span>,
                        <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">bias</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">input_quantized</span>,
                        <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">scaling_factors</span>,
                        <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">accum_scratch</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">row_sums</span>,
                        <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">input_offsets</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">output</span>)
  <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Quantize input from float to uint8 + quantization params (scaling factor).</span>
  <span style="font-weight: bold; text-decoration: underline;">float</span>* <span style="font-weight: bold; font-style: italic;">scaling_factors_ptr</span> = GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">float</span>&gt;(scaling_factors);
  <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">quant_data</span> = GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">int8_t</span>&gt;(input_quantized);
  <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">filter_data</span> = GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">int8_t</span>&gt;(filter);
  <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">float</span>* <span style="font-weight: bold; font-style: italic;">input_ptr</span> = GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">float</span>&gt;(input);
  <span style="font-weight: bold; text-decoration: underline;">tensor_utils</span>::BatchQuantizeFloats(
    input_ptr, batch_size, input_size, quant_data, scaling_factors_ptr,
    input_offset_ptr, params-&gt;asymmetric_quantize_inputs);
  <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">b</span> = 0; b &lt; batch_size; ++b) {
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Incorporate scaling of the filter.</span>
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">!!! &#26368;&#32456;&#20351;&#29992;&#30340; scale &#26159; input_scale * filter_scale</span>
    scaling_factors_ptr[b] *= filter-&gt;params.scale;
  }

  <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Compute output += weight * quantized_input</span>
  <span style="font-weight: bold; text-decoration: underline;">int32_t</span>* <span style="font-weight: bold; font-style: italic;">scratch</span> = GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">int32_t</span>&gt;(accum_scratch);
  <span style="font-weight: bold; text-decoration: underline;">tensor_utils</span>::MatrixBatchVectorMultiplyAccumulate(
    filter_data, num_units, input_size, quant_data, scaling_factors_ptr,
    batch_size, GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">float</span>&gt;(output), <span style="font-weight: bold; font-style: italic;">/*</span><span style="font-weight: bold; font-style: italic;">per_channel_scale=</span><span style="font-weight: bold; font-style: italic;">*/</span><span style="font-weight: bold; text-decoration: underline;">nullptr</span>,
    input_offset_ptr, scratch, row_sums_ptr, &amp;data-&gt;compute_row_sums,
    <span style="font-weight: bold; text-decoration: underline;">CpuBackendContext</span>::GetFromContext(context));

  <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">&#26368;&#32456;&#30340; output &#26159; float</span>
  <span style="font-weight: bold; text-decoration: underline;">tensor_utils</span>::ApplyActivationToVector(
    GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">float</span>&gt;(output), batch_size * num_units, params-&gt;activation,
    GetTensorData&lt;<span style="font-weight: bold; text-decoration: underline;">float</span>&gt;(output));

<span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">&#30697;&#38453;&#36816;&#31639;&#26102;&#36755;&#20837;&#26159;&#20004;&#20010; int8 &#30340;&#30697;&#38453;, &#20294;&#36755;&#20986;&#30340;&#32467;&#26524;&#26159; float</span>
<span style="font-weight: bold; text-decoration: underline;">void</span> <span style="font-weight: bold;">PortableMatrixBatchVectorMultiplyAccumulate</span>(
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">__restrict__</span> matrix, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">m_rows</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">m_cols</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">__restrict__</span> vectors, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">float</span>* <span style="font-weight: bold; font-style: italic;">scaling_factors</span>,
    <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">n_batch</span>, <span style="font-weight: bold; text-decoration: underline;">float</span>* <span style="font-weight: bold; font-style: italic;">__restrict__</span> result) {
    <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">batch</span> = 0; batch &lt; n_batch; ++batch, vectors += m_cols) {
        <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">float</span> <span style="font-weight: bold; font-style: italic;">batch_scaling_factor</span> = scaling_factors[batch];
        <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Get the address of the first row.</span>
        <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">row_ptr</span> = matrix;
        <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">row</span> = 0; row &lt; m_rows; ++row) {
            <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Initialize the dot product sum for the row to 0.</span>
            <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">dotprod</span> = 0;
            <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">col</span> = 0; col &lt; m_cols; ++col, ++row_ptr) {
                dotprod += (*row_ptr) * (vectors[col]);
            }  <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">for col</span>
            *result += dotprod * batch_scaling_factor;
            ++result;
        }  <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">for row</span>
    }    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">for batch</span>
}
</pre>
</div>
</div>
</div>


<div id="outline-container-org253c4cf" class="outline-3">
<h3 id="org253c4cf"><span class="section-number-3">1.3</span> 全整数量化</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>weight 的对称量化, 即 zero_point 为 0</li>
<li>activation 是非对称量化</li>
<li>zero_point 为整数</li>
<li>tflite 的量化规范来自 <a href="gemmlowp_quantization.html#org42e1f97">Gemmlowp Quantization</a></li>
</ul>

<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model("/tmp/pow")

X = tf.random.uniform([100, 1], minval=1, maxval=10.0)


def representative_dataset_gen():
    for i in range(10):
        yield [[X[i]]]


converter.representative_dataset = representative_dataset_gen

converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

tflite = converter.convert()
with open("/tmp/pow-q.tflite", "wb") as f:
    f.write(tflite)
    print("size of tflite-q:", len(tflite))
</pre>
</div>

<p>
size of tflite-q: 46944
</p>

<ol class="org-ol">
<li>所有数据, 包含模型的输入, 都会量化, 且所有 node 的输入输出都是 int8. 由于量化
需要依据 (min, max), 针对模型输入, 需要提供一个 representative_dataset_gen,
用来提供这一数据, 才能完成对 input 的量化</li>

<li>全整数的量化需要 node 本身支持全整数运算, 否则量化过程会失败</li>
</ol>


<p>
Q: 全量化时, 权重变为 int8 后结果会不会变得很大?
</p>

<p>
A: 不会. 全量化时, 虽然 input 和 权重都是 int8 可以直接运算, 但运算后还是会根据
   提前获得的量化参数 (scale, zero 或 multiplier, shift) 处理一下计算结果, 类似
   于 dynamic range 量化时使用的 batch_scaling_factor
</p>

<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold; text-decoration: underline;">void</span> <span style="font-weight: bold; text-decoration: underline;">reference_integer_ops</span>::<span style="font-weight: bold;">FullyConnected</span>(
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">FullyConnectedParams</span>&amp; <span style="font-weight: bold; font-style: italic;">params</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">input_shape</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">input_data</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">filter_shape</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">filter_data</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">bias_shape</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32_t</span>* <span style="font-weight: bold; font-style: italic;">bias_data</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">output_shape</span>,
    <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">output_data</span>) {
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">...</span>
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">output_multiplier</span> = params.output_multiplier;
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">output_shift</span> = params.output_shift;
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">...</span>
    <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">b</span> = 0; b &lt; batches; ++b) {
        <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">out_c</span> = 0; out_c &lt; output_depth; ++out_c) {
            <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">acc</span> = 0;
            <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">d</span> = 0; d &lt; accum_depth; ++d) {
                <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">input_val</span> = input_data[b * accum_depth + d];
                <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">filter_val</span> = filter_data[out_c * accum_depth + d];
                acc +=
                    (filter_val + filter_offset) * (input_val + input_offset);
            }
            <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">...</span>
            <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">!!! output_shift &#21644; output_multiplier &#21363;&#37327;&#21270;&#21442;&#25968;</span>
            acc = MultiplyByQuantizedMultiplier(acc, output_multiplier,
                                                output_shift);
            acc += output_offset;
            output_data[out_c + output_depth * b] = <span style="font-weight: bold;">static_cast</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int8_t</span>&gt;(acc);
        }
    }
}
</pre>
</div>
</div>
</div>


<div id="outline-container-orgd4726fc" class="outline-3">
<h3 id="orgd4726fc"><span class="section-number-3">1.4</span> 量化误差过大</h3>
<div class="outline-text-3" id="text-1-4">
<p>
若权重或 activation 的范围特别不均匀, 可能会导致量化误差过大, 通过 batchnorm 看
起来能缓解这一问题
</p>
</div>
</div>

<div id="outline-container-orgcb9a392" class="outline-3">
<h3 id="orgcb9a392"><span class="section-number-3">1.5</span> 无法量化的操作</h3>
<div class="outline-text-3" id="text-1-5">
<p>
floor 是无法量化的 op, 所以下面的模型使用全整数量化时会失败
</p>

<pre class="example" id="org62c1877">
RuntimeError: Quantization not yet supported for op: FLOOR
</pre>

<div class="org-src-container">
<pre class="src src-ipython">import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers

n = 100

X = tf.random.uniform([n, 1], minval = 1, maxval = 10.)
Y = tf.pow(X,2)

tf.keras.backend.clear_session()

inputs = keras.Input(shape = (1, ))
dense = layers.Dense(50, activation = "relu")(inputs)
floor = tf.floor(dense)
outputs = layers.Dense(1)(floor)

model = keras.Model(inputs, outputs)
model.compile(optimizer="adam",loss="mse")
history = model.fit(X,Y,batch_size = 20,epochs = 50, verbose = 0)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
X = tf.random.uniform([100, 1], minval=1, maxval=10.0)
def representative_dataset_gen():
    for i in range(10):
        yield [[X[i]]]

converter.representative_dataset = representative_dataset_gen
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

tflite = converter.convert()
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-orgdb88a92" class="outline-2 references">
<h2 id="orgdb88a92">Backlinks</h2>
<div class="outline-text-2" id="text-orgdb88a92">
<p>
<a href="quantization.html#ID-6ad56dfa-9772-478b-9872-6f8294d6cb19">Quantization</a>
(<i>Quantization &gt; Tensorflow Post Training Quantization</i>):   <a href="tensorflow_post_training_quantization.html#ID-0d9ef45d-9547-4523-a104-c52a3e9c6673">Tensorflow Post Training Quantization</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2021-08-24 Tue 00:00<br />
Last updated: 2022-01-26 Wed 11:25</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
