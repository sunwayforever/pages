<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>CMSIS Quantization Example</title>

<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">CMSIS Quantization Example</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org000001f">1. CMSIS Quantization Example</a>
<ul>
<li><a href="#org0000006">1.1. output_shift 与 bias_shift</a>
<ul>
<li><a href="#org0000000">1.1.1. dec_bit</a></li>
<li><a href="#org0000003">1.1.2. 计算 dense layer 的 shift</a></li>
</ul>
</li>
<li><a href="#org0000009">1.2. weight 量化</a></li>
<li><a href="#org000000c">1.3. activiation 量化</a></li>
<li><a href="#org0000010">1.4. 坑</a></li>
<li><a href="#org0000019">1.5. 完整代码</a>
<ul>
<li><a href="#org0000013">1.5.1. 模型定义</a></li>
<li><a href="#org0000016">1.5.2. 量化</a></li>
</ul>
</li>
<li><a href="#org000001c">1.6. cmsis-nn 与 tflite 量化</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org000001f" class="outline-2">
<h2 id="org000001f"><span class="section-number-2">1.</span> CMSIS Quantization Example</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org0000006" class="outline-3">
<h3 id="org0000006"><span class="section-number-3">1.1.</span> output_shift 与 bias_shift</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org0000000" class="outline-4">
<h4 id="org0000000"><span class="section-number-4">1.1.1.</span> dec_bit</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
dec_bit 指 float 最多可以左移 dec_bit 而不超过量化范围.
</p>

<p>
例如, 假设量化范围为 uint8, 则 [-128, 127),  若 float 为 2.0, 则 dec_bit 为 5,
因为 2.0 &lt;&lt; 5 = 64, 而 2.0 &lt;&lt; 6 = 128, 所以最大移位为 5
</p>

<p>
以 uint8 量化为例, 计算 dec_bit 的公式为
</p>

<p>
7 - (np.ceil(np.log2(float_number)))
</p>
</div>
</div>

<div id="outline-container-org0000003" class="outline-4">
<h4 id="org0000003"><span class="section-number-4">1.1.2.</span> 计算 dense layer 的 shift</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
定义:
</p>

<ol class="org-ol">
<li>fi: input dec_bit</li>
<li>fw: weight dec_bit</li>
<li>fo: output dec_bit</li>
<li>fb: bias dec_bit</li>
</ol>

<p>
则:
</p>

<ul class="org-ul">
<li>output_shift = fi+fw-fo</li>
<li>bias_shift = fi+fw-fb</li>
</ul>

<p>
解释:
</p>

<p>
为便于理解, 把 dec_bit 看作是 10 的幂 (而不是 2 的幂)
</p>

<p>
假设 input 为 0.1, weight 为 0.01, bias = 0.1.
</p>

<p>
未量化时 wx+b 的值为 0.001+0.1=0.101
</p>

<p>
设对 x/w/b/o 量化的 dec_bit 分别为 1/2/1/2; W/X/B/O 分别是 w/x/b/o 量化后的结果.
</p>

<p>
如何使用 W/X/B 得到 O?
</p>

<p>
\(wx+b=o \implies wx+b=(\frac{X}{10})*(\frac{W}{100})+\frac{B}{10}=\frac{XW}{1000}+\frac{B}{10}=\frac{XW+100B}{1000}=\frac{O}{100}\implies
\frac{XW+100B}{10}=O\)
</p>

<p>
最后的式子显示于 B 需要左移 2 (fi+fw-fb), 且 output 需要右移 1 (fi+fw-fo) 才能最终得于 O
</p>

<p>
以 fc 为例, 计算的过程大约是: (XW+ (B &lt;&lt;bias_shift)) &gt;&gt; output_shift
</p>
</div>
</div>
</div>

<div id="outline-container-org0000009" class="outline-3">
<h3 id="org0000009"><span class="section-number-3">1.2.</span> weight 量化</h3>
<div class="outline-text-3" id="text-1-2">
<p>
根据 weight 本身的范围确定 weight 的 dec_bit, 然后令 W=w*(2**dec_bit) 即可
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-variable-name">dec_bit</span> = 7 - (np.ceil(np.log2(np.<span class="org-builtin">max</span>([<span class="org-builtin">abs</span>(min_weight), <span class="org-builtin">abs</span>(max_weight)], axis=0))))
</pre>
</div>
</div>
</div>

<div id="outline-container-org000000c" class="outline-3">
<h3 id="org000000c"><span class="section-number-3">1.3.</span> activiation 量化</h3>
<div class="outline-text-3" id="text-1-3">
<p>
使用一些参考输入, 确定每一层的输入输出的范围, 计算各自的 dec_bit 做为相应的 fi,
fo, 配合 fw 可以获得 output_shift 和 bias_shift
</p>
</div>
</div>

<div id="outline-container-org0000010" class="outline-3">
<h3 id="org0000010"><span class="section-number-3">1.4.</span> 坑</h3>
<div class="outline-text-3" id="text-1-4">
<ol class="org-ol">
<li><p>
keras layer activation
</p>

<p>
keras.Layers.Dense(16, activiation="softmax"), 这一层的输出会包含 softmax 的结果, 所以使用这一层的输出计算的量化参数并不是 dense layer 的参数.
</p>

<p>
解决的方法是把 softmax 做为单独的一层, 不要和 dense 写在一起
</p></li>

<li><p>
ReLU 导致的问题
</p>

<p>
假设网络结构为:
</p>

<p>
FC1 -&gt; ReLU -&gt; FC2
</p>

<p>
当计算 FC2 的 input 量化参数时, 不能使用 ReLU 的输出做为 FC2 的 input, 因为
FC1 的 ouptut 与 FC2 的 input 的值并不相同, 但 cmsis-nn 针对 ReLU 并没有对应的 output_shift 参数. 所以 inference 时, FC1 的输出与 FC1 输出量化参数一致,但与 FC2 输入量化参数并不一致.
</p>

<p>
为解决这个问题, FC2 的 input 可以直接使用 FC1 output 的量化参数, 或者给
cmsis-nn 加 patch, 使 ReLU 计算时完成如下的操作:
</p>

<pre class="example" id="org000000f">
Quantize(
  Dequantize(FC1_OUT,FC1_OUTPUT_QUANT_PARAM),
  FC2_INPUT_QUANT_PARAM
 )
</pre>

<p>
除了 ReLU, CMSIS 中的 average pooling, max pooling, 也有类似的问题 (softmax
是否有这个问题还不确定&#x2026;)
</p>

<p>
Q: FC, CONV 为什么不像 ReLU 一样直接忽略 output_shift?
</p>

<p>
A: 两个 uint8 相乘, 结果用 uint8 是保存不了的, output_shift 实际上代表的是
Quantize(Dequantize(output_1, dec_bit_output_1), dec_bit_input_2) 这个过程&#x2026;但
ReLU, pooling 不存在这个问题
</p></li>

<li><p>
训练的越多越不准确&#x2026;
</p>

<p>
最初的模型使用了 dropout 做正则化 (而没有使用 batch norm 或 l1/l2
regularizer), 导致训练的越多 weight 越大 (从 0.x 增加到 2.x), 而 weight 变大又导致 activiation 变大 (从几十增加到几千), 而 cmsis-nn 的 output_shift 只支持右移, 即它假设 activiation 总是在 [-128,128) 范围内, 当 activiation 远远大于这个范围时, 缺失的左移操作会导致结果不准确.
</p>

<p>
解决的方法:
</p>

<ol class="org-ol">
<li>使用 batch norm, 保证 activiation 在一定范围</li>

<li>使用 l1/l2 regularizer, 保证 weight 在较小的范围</li>
</ol></li>
</ol>
</div>
</div>


<div id="outline-container-org0000019" class="outline-3">
<h3 id="org0000019"><span class="section-number-3">1.5.</span> 完整代码</h3>
<div class="outline-text-3" id="text-1-5">
</div>
<div id="outline-container-org0000013" class="outline-4">
<h4 id="org0000013"><span class="section-number-4">1.5.1.</span> 模型定义</h4>
<div class="outline-text-4" id="text-1-5-1">
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">cnn</span>():
    <span class="org-variable-name">inputs</span> = keras.Input(shape=(FRAMES, DCT_COEFFICIENT_COUNT))
    outputs = tf.expand_dims(inputs, axis=-1)

    outputs = layers.Conv2D(
        filters=28, kernel_size=[10, 4], strides=[1, 1], name=<span class="org-string">"conv1"</span>
    )(outputs)
    <span class="org-comment-delimiter"># </span><span class="org-comment">outputs = layers.BatchNormalization()(outputs)</span>
    outputs = layers.ReLU()(outputs)
    outputs = layers.Dropout(0.3)(outputs)

    outputs = layers.Conv2D(
        filters=30, kernel_size=[10, 4], strides=[2, 1], name=<span class="org-string">"conv2"</span>
    )(outputs)
    <span class="org-comment-delimiter"># </span><span class="org-comment">outputs = layers.BatchNormalization()(outputs)</span>
    outputs = layers.ReLU()(outputs)
    outputs = layers.Dropout(0.2)(outputs)

    outputs = layers.Flatten()(outputs)

    outputs = layers.Dense(16, name=<span class="org-string">"dense1"</span>)(outputs)
    <span class="org-comment-delimiter"># </span><span class="org-comment">outputs = layers.BatchNormalization()(outputs)</span>
    outputs = layers.ReLU()(outputs)
    outputs = layers.Dropout(0.1)(outputs)

    outputs = layers.Dense(128, name=<span class="org-string">"dense2"</span>)(outputs)
    outputs = layers.ReLU()(outputs)
    outputs = layers.Dense(<span class="org-builtin">len</span>(WORDS), name=<span class="org-string">"dense3"</span>)(outputs)
    outputs = layers.Softmax()(outputs)

    <span class="org-keyword">return</span> keras.Model(inputs, outputs)
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000016" class="outline-4">
<h4 id="org0000016"><span class="section-number-4">1.5.2.</span> 量化</h4>
<div class="outline-text-4" id="text-1-5-2">
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> tensorflow <span class="org-keyword">as</span> tf
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">from</span> tensorflow <span class="org-keyword">import</span> keras
<span class="org-keyword">from</span> tensorflow.keras <span class="org-keyword">import</span> layers, losses, metrics, optimizers, models

tf.keras.backend.clear_session()


<span class="org-keyword">def</span> <span class="org-function-name">collect_inference_statistics</span>(model, ref_input):
    <span class="org-builtin">input</span> = model.layers[0].output
    <span class="org-variable-name">prev</span> = model.layers[0]
    <span class="org-variable-name">outputs</span> = []
    <span class="org-keyword">for</span> layer <span class="org-keyword">in</span> model.<span class="org-variable-name">layers</span>:
        <span class="org-keyword">if</span> layer.name.startswith(<span class="org-string">"conv"</span>) <span class="org-keyword">or</span> layer.name.startswith(<span class="org-string">"dense"</span>):
            outputs.append(prev.output)
            outputs.append(layer.output)
            prev = layer

    <span class="org-variable-name">model</span> = keras.Model(<span class="org-builtin">input</span>, outputs)

    <span class="org-variable-name">max_value</span>, <span class="org-variable-name">min_value</span> = [], []
    <span class="org-keyword">for</span> x <span class="org-keyword">in</span> <span class="org-variable-name">ref_input</span>[0:2000]:
        value = [(i.numpy().<span class="org-builtin">min</span>(), i.numpy().<span class="org-builtin">max</span>()) <span class="org-keyword">for</span> i <span class="org-keyword">in</span> model(x)]
        min_value.append([v[0] <span class="org-keyword">for</span> v <span class="org-keyword">in</span> value])
        max_value.append([v[1] <span class="org-keyword">for</span> v <span class="org-keyword">in</span> value])
        <span class="org-variable-name">min_value</span>, <span class="org-variable-name">max_value</span> = (
            np.asarray(min_value).<span class="org-builtin">min</span>(axis=0),
            np.asarray(max_value).<span class="org-builtin">max</span>(axis=0),
        )
        shift = (
            (7 - (np.ceil(np.log2(np.<span class="org-builtin">max</span>([<span class="org-builtin">abs</span>(min_value), <span class="org-builtin">abs</span>(max_value)], axis=0)))))
            .astype(<span class="org-builtin">int</span>)
            .tolist()
        )
    <span class="org-keyword">return</span> [(s[0], s[1]) <span class="org-keyword">for</span> s <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(shift[0::2], shift[1::2])]


<span class="org-keyword">def</span> <span class="org-function-name">quantize</span>(model, shift, ref_input):
    KWS_CMSIS_NN = <span class="org-string">"model/kws_cmsis_nn.h"</span>

    int_bits = <span class="org-builtin">int</span>(np.ceil(np.log2(<span class="org-builtin">max</span>(<span class="org-builtin">abs</span>(ref_input.<span class="org-builtin">min</span>()), <span class="org-builtin">abs</span>(ref_input.<span class="org-builtin">max</span>())))))
    dec_bits = 7 - int_bits

    <span class="org-keyword">with</span> <span class="org-builtin">open</span>(KWS_CMSIS_NN, <span class="org-string">"w"</span>) <span class="org-keyword">as</span> f:
        f.write(<span class="org-string">"// -*- eval: (sw/large-file-mode); -*-\n"</span>)
        f.write(<span class="org-string">"#define MFCC_DEC_BITS {}\n"</span>.<span class="org-builtin">format</span>(dec_bits))

    i = -1
    <span class="org-keyword">for</span> layer <span class="org-keyword">in</span> model.layers:
        <span class="org-keyword">if</span> layer.name.startswith(<span class="org-string">"conv"</span>) <span class="org-keyword">or</span> layer.name.startswith(<span class="org-string">"dense"</span>):
            i += 1
            <span class="org-builtin">print</span>(layer.name)
            fw = <span class="org-constant">None</span>
            <span class="org-keyword">for</span> (t, value) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(layer.get_weights()):
                int_bits = <span class="org-builtin">int</span>(
                    np.ceil(np.log2(<span class="org-builtin">max</span>(<span class="org-builtin">abs</span>(value.<span class="org-builtin">min</span>()), <span class="org-builtin">abs</span>(value.<span class="org-builtin">max</span>()))))
                )
                dec_bits = 7 - int_bits
                q_value = np.<span class="org-builtin">round</span>(value * 2 ** dec_bits)

                <span class="org-keyword">if</span> t == 0:
                    shift_name = layer.name + <span class="org-string">"_out"</span>
                    var_name = layer.name + <span class="org-string">"_weight"</span>
                    <span class="org-comment-delimiter"># </span><span class="org-comment">fi+fw-fo</span>
                    fw = dec_bits
                    shift_bits = shift[i][0] + fw - shift[i][1]
                <span class="org-keyword">else</span>:
                    shift_name = layer.name + <span class="org-string">"_bias"</span>
                    var_name = layer.name + <span class="org-string">"_bias"</span>
                    shift_bits = shift[i][0] + fw - dec_bits

                <span class="org-keyword">if</span> shift_bits &lt; 0:
                    shift_bits = 0

                <span class="org-keyword">with</span> <span class="org-builtin">open</span>(KWS_CMSIS_NN, <span class="org-string">"a"</span>) <span class="org-keyword">as</span> f:
                    f.write(
                        <span class="org-string">"#define {}_SHIFT {}\n"</span>.<span class="org-builtin">format</span>(shift_name.upper(), shift_bits)
                    )

                    f.write(<span class="org-string">"#define {} {{"</span>.<span class="org-builtin">format</span>(var_name.upper()))

                    <span class="org-keyword">if</span> <span class="org-builtin">len</span>(value.shape) == 4:
                        <span class="org-comment-delimiter"># </span><span class="org-comment">tf   : HWNC</span>
                        <span class="org-comment-delimiter"># </span><span class="org-comment">cmsis: CHWN</span>
                        q_value_t = np.transpose(q_value, (3, 0, 1, 2))
                    <span class="org-keyword">else</span>:
                        q_value_t = np.transpose(q_value)
                        q_value_t.tofile(f, sep=<span class="org-string">", "</span>, <span class="org-builtin">format</span>=<span class="org-string">"%d"</span>)
                        f.write(<span class="org-string">"}\n"</span>)


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> == <span class="org-string">"__main__"</span>:
    MODEL_PATH = <span class="org-string">"./model/kws"</span>
    model = keras.models.load_model(MODEL_PATH)

    ref_input = np.load(<span class="org-string">"./temp/test_x.npy"</span>)
    shift = collect_inference_statistics(model, ref_input)
    <span class="org-builtin">print</span>(shift)
    quantize(model, shift, ref_input)

</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org000001c" class="outline-3">
<h3 id="org000001c"><span class="section-number-3">1.6.</span> cmsis-nn 与 tflite 量化</h3>
<div class="outline-text-3" id="text-1-6">
<p>
tflite for mcu 底层支持 cmsis-nn, 但 tflite 的量化规范来自于 gemmlowp, 与前面描述的基于 2^n 的对称量化并不一致. 事实上, cmsis-nn 针对 tflite 的量化需求提供了另外一套 api
</p>

<p>
<a href="file:///home/sunway/source/tensorflow/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/README.md#org0000000">file:///home/sunway/source/tensorflow/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/README.md#org0000000</a>
</p>
</div>
</div>
</div>


<div id="outline-container-org0000022" class="outline-2 references">
<h2 id="org0000022">Backlinks</h2>
<div class="outline-text-2" id="text-org0000022">
<p>
<a href="quantization.html#ID-6ad56dfa-9772-478b-9872-6f8294d6cb19">Quantization</a>
(<i>Quantization &gt; CMSIS Quantization Example</i>):   <a href="cmsis_quantization_example.html#ID-d51beea9-ed7e-4308-9659-7832d723f6e3">CMSIS Quantization Example</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2020-09-21 Mon 00:00<br />
Last updated: 2022-01-26 Wed 11:29</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
