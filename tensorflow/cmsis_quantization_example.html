<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-01-26 Wed 11:42 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>CMSIS Quantization Example</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Wei Sun (孙伟)" />
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">CMSIS Quantization Example</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgefad077">1. CMSIS Quantization Example</a>
<ul>
<li><a href="#orgdc30799">1.1. output_shift 与 bias_shift</a>
<ul>
<li><a href="#org89b2a37">1.1.1. dec_bit</a></li>
<li><a href="#orga2042e6">1.1.2. 计算 dense layer 的 shift</a></li>
</ul>
</li>
<li><a href="#org9dd5f95">1.2. weight 量化</a></li>
<li><a href="#org5fe8525">1.3. activiation 量化</a></li>
<li><a href="#org17cd227">1.4. 坑</a></li>
<li><a href="#orgce0dcba">1.5. 完整代码</a>
<ul>
<li><a href="#org277e2c8">1.5.1. 模型定义</a></li>
<li><a href="#org7a9c10f">1.5.2. 量化</a></li>
</ul>
</li>
<li><a href="#org328e08b">1.6. cmsis-nn 与 tflite 量化</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgefad077" class="outline-2">
<h2 id="orgefad077"><span class="section-number-2">1</span> CMSIS Quantization Example</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-orgdc30799" class="outline-3">
<h3 id="orgdc30799"><span class="section-number-3">1.1</span> output_shift 与 bias_shift</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org89b2a37" class="outline-4">
<h4 id="org89b2a37"><span class="section-number-4">1.1.1</span> dec_bit</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
dec_bit 指 float 最多可以左移 dec_bit 而不超过量化范围.
</p>

<p>
例如, 假设量化范围为 uint8, 则 [-128, 127),  若 float 为 2.0, 则 dec_bit 为 5,
因为 2.0 &lt;&lt; 5 = 64, 而 2.0 &lt;&lt; 6 = 128, 所以最大移位为 5
</p>

<p>
以 uint8 量化为例, 计算 dec_bit 的公式为
</p>

<p>
7 - (np.ceil(np.log2(float_number)))
</p>
</div>
</div>

<div id="outline-container-orga2042e6" class="outline-4">
<h4 id="orga2042e6"><span class="section-number-4">1.1.2</span> 计算 dense layer 的 shift</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
定义:
</p>

<ol class="org-ol">
<li>fi: input dec_bit</li>
<li>fw: weight dec_bit</li>
<li>fo: output dec_bit</li>
<li>fb: bias dec_bit</li>
</ol>

<p>
则:
</p>

<ul class="org-ul">
<li>output_shift = fi+fw-fo</li>
<li>bias_shift = fi+fw-fb</li>
</ul>

<p>
解释:
</p>

<p>
为便于理解, 把 dec_bit 看作是 10 的幂 (而不是 2 的幂)
</p>

<p>
假设 input 为 0.1, weight 为 0.01, bias = 0.1.
</p>

<p>
未量化时 wx+b 的值为 0.001+0.1=0.101
</p>

<p>
设对 x/w/b/o 量化的 dec_bit 分别为 1/2/1/2; W/X/B/O 分别是 w/x/b/o 量化后的结果.
</p>

<p>
如何使用 W/X/B 得到 O?
</p>

<p>
\(wx+b=o \implies wx+b=(\frac{X}{10})*(\frac{W}{100})+\frac{B}{10}=\frac{XW}{1000}+\frac{B}{10}=\frac{XW+100B}{1000}=\frac{O}{100}\implies
\frac{XW+100B}{10}=O\)
</p>

<p>
最后的式子显示于 B 需要左移 2 (fi+fw-fb), 且 output 需要右移 1 (fi+fw-fo) 才能最
终得于 O
</p>

<p>
以 fc 为例, 计算的过程大约是: (XW+ (B &lt;&lt;bias_shift)) &gt;&gt; output_shift
</p>
</div>
</div>
</div>

<div id="outline-container-org9dd5f95" class="outline-3">
<h3 id="org9dd5f95"><span class="section-number-3">1.2</span> weight 量化</h3>
<div class="outline-text-3" id="text-1-2">
<p>
根据 weight 本身的范围确定 weight 的 dec_bit, 然后令 W=w*(2**dec_bit) 即可
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">dec_bit</span> = 7 - (np.ceil(np.log2(np.<span style="font-weight: bold;">max</span>([<span style="font-weight: bold;">abs</span>(min_weight), <span style="font-weight: bold;">abs</span>(max_weight)], axis=0))))
</pre>
</div>
</div>
</div>

<div id="outline-container-org5fe8525" class="outline-3">
<h3 id="org5fe8525"><span class="section-number-3">1.3</span> activiation 量化</h3>
<div class="outline-text-3" id="text-1-3">
<p>
使用一些参考输入, 确定每一层的输入输出的范围, 计算各自的 dec_bit 做为相应的 fi,
fo, 配合 fw 可以获得 output_shift 和 bias_shift
</p>
</div>
</div>

<div id="outline-container-org17cd227" class="outline-3">
<h3 id="org17cd227"><span class="section-number-3">1.4</span> 坑</h3>
<div class="outline-text-3" id="text-1-4">
<ol class="org-ol">
<li><p>
keras layer activation
</p>

<p>
keras.Layers.Dense(16, activiation="softmax"), 这一层的输出会包含 softmax 的
结果, 所以使用这一层的输出计算的量化参数并不是 dense layer 的参数.
</p>

<p>
解决的方法是把 softmax 做为单独的一层, 不要和 dense 写在一起
</p></li>

<li><p>
ReLU 导致的问题
</p>

<p>
假设网络结构为:
</p>

<p>
FC1 -&gt; ReLU -&gt; FC2
</p>

<p>
当计算 FC2 的 input 量化参数时, 不能使用 ReLU 的输出做为 FC2 的 input, 因为
FC1 的 ouptut 与 FC2 的 input 的值并不相同, 但 cmsis-nn 针对 ReLU 并没有对应
的 output_shift 参数. 所以 inference 时, FC1 的输出与 FC1 输出量化参数一致,但
与 FC2 输入量化参数并不一致.
</p>

<p>
为解决这个问题, FC2 的 input 可以直接使用 FC1 output 的量化参数, 或者给
cmsis-nn 加 patch, 使 ReLU 计算时完成如下的操作:
</p>

<pre class="example" id="orge4ac81a">
Quantize(
  Dequantize(FC1_OUT,FC1_OUTPUT_QUANT_PARAM),
  FC2_INPUT_QUANT_PARAM
 )
</pre>

<p>
除了 ReLU, CMSIS 中的 average pooling, max pooling, 也有类似的问题 (softmax
是否有这个问题还不确定&#x2026;)
</p>

<p>
Q: FC, CONV 为什么不像 ReLU 一样直接忽略 output_shift?
</p>

<p>
A: 两个 uint8 相乘, 结果用 uint8 是保存不了的, output_shift 实际上代表的是
Quantize(Dequantize(output_1, dec_bit_output_1), dec_bit_input_2) 这个过程&#x2026;但
ReLU, pooling 不存在这个问题
</p></li>

<li><p>
训练的越多越不准确&#x2026;
</p>

<p>
最初的模型使用了 dropout 做正则化 (而没有使用 batch norm 或 l1/l2
regularizer), 导致训练的越多 weight 越大 (从 0.x 增加到 2.x), 而 weight 变大
又导致 activiation 变大 (从几十增加到几千), 而 cmsis-nn 的 output_shift 只支
持右移, 即它假设 activiation 总是在 [-128,128) 范围内, 当 activiation 远远大
于这个范围时, 缺失的左移操作会导致结果不准确.
</p>

<p>
解决的方法:
</p>

<ol class="org-ol">
<li>使用 batch norm, 保证 activiation 在一定范围</li>

<li>使用 l1/l2 regularizer, 保证 weight 在较小的范围</li>
</ol></li>
</ol>
</div>
</div>


<div id="outline-container-orgce0dcba" class="outline-3">
<h3 id="orgce0dcba"><span class="section-number-3">1.5</span> 完整代码</h3>
<div class="outline-text-3" id="text-1-5">
</div>
<div id="outline-container-org277e2c8" class="outline-4">
<h4 id="org277e2c8"><span class="section-number-4">1.5.1</span> 模型定义</h4>
<div class="outline-text-4" id="text-1-5-1">
<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">def</span> <span style="font-weight: bold;">cnn</span>():
    <span style="font-weight: bold; font-style: italic;">inputs</span> = keras.Input(shape=(FRAMES, DCT_COEFFICIENT_COUNT))
    <span style="font-weight: bold; font-style: italic;">outputs</span> = tf.expand_dims(inputs, axis=-1)

    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Conv2D(
        filters=28, kernel_size=[10, 4], strides=[1, 1], name=<span style="font-style: italic;">"conv1"</span>
    )(outputs)
    <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">outputs = layers.BatchNormalization()(outputs)</span>
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.ReLU()(outputs)
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Dropout(0.3)(outputs)

    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Conv2D(
        filters=30, kernel_size=[10, 4], strides=[2, 1], name=<span style="font-style: italic;">"conv2"</span>
    )(outputs)
    <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">outputs = layers.BatchNormalization()(outputs)</span>
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.ReLU()(outputs)
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Dropout(0.2)(outputs)

    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Flatten()(outputs)

    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Dense(16, name=<span style="font-style: italic;">"dense1"</span>)(outputs)
    <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">outputs = layers.BatchNormalization()(outputs)</span>
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.ReLU()(outputs)
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Dropout(0.1)(outputs)

    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Dense(128, name=<span style="font-style: italic;">"dense2"</span>)(outputs)
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.ReLU()(outputs)
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Dense(<span style="font-weight: bold;">len</span>(WORDS), name=<span style="font-style: italic;">"dense3"</span>)(outputs)
    <span style="font-weight: bold; font-style: italic;">outputs</span> = layers.Softmax()(outputs)

    <span style="font-weight: bold;">return</span> keras.Model(inputs, outputs)
</pre>
</div>
</div>
</div>

<div id="outline-container-org7a9c10f" class="outline-4">
<h4 id="org7a9c10f"><span class="section-number-4">1.5.2</span> 量化</h4>
<div class="outline-text-4" id="text-1-5-2">
<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">import</span> tensorflow <span style="font-weight: bold;">as</span> tf
<span style="font-weight: bold;">import</span> numpy <span style="font-weight: bold;">as</span> np

<span style="font-weight: bold;">from</span> tensorflow <span style="font-weight: bold;">import</span> keras
<span style="font-weight: bold;">from</span> tensorflow.keras <span style="font-weight: bold;">import</span> layers, losses, metrics, optimizers, models

tf.keras.backend.clear_session()


<span style="font-weight: bold;">def</span> <span style="font-weight: bold;">collect_inference_statistics</span>(model, ref_input):
    <span style="font-weight: bold;">input</span> = model.layers[0].output
    <span style="font-weight: bold; font-style: italic;">prev</span> = model.layers[0]
    <span style="font-weight: bold; font-style: italic;">outputs</span> = []
    <span style="font-weight: bold;">for</span> layer <span style="font-weight: bold;">in</span> model.layers:
        <span style="font-weight: bold;">if</span> layer.name.startswith(<span style="font-style: italic;">"conv"</span>) <span style="font-weight: bold;">or</span> layer.name.startswith(<span style="font-style: italic;">"dense"</span>):
            outputs.append(prev.output)
            outputs.append(layer.output)
            <span style="font-weight: bold; font-style: italic;">prev</span> = layer

    <span style="font-weight: bold; font-style: italic;">model</span> = keras.Model(<span style="font-weight: bold;">input</span>, outputs)

    <span style="font-weight: bold; font-style: italic;">max_value</span>, <span style="font-weight: bold; font-style: italic;">min_value</span> = [], []
    <span style="font-weight: bold;">for</span> x <span style="font-weight: bold;">in</span> ref_input[0:2000]:
        <span style="font-weight: bold; font-style: italic;">value</span> = [(i.numpy().<span style="font-weight: bold;">min</span>(), i.numpy().<span style="font-weight: bold;">max</span>()) <span style="font-weight: bold;">for</span> i <span style="font-weight: bold;">in</span> model(x)]
        min_value.append([v[0] <span style="font-weight: bold;">for</span> v <span style="font-weight: bold;">in</span> value])
        max_value.append([v[1] <span style="font-weight: bold;">for</span> v <span style="font-weight: bold;">in</span> value])
        <span style="font-weight: bold; font-style: italic;">min_value</span>, <span style="font-weight: bold; font-style: italic;">max_value</span> = (
            np.asarray(min_value).<span style="font-weight: bold;">min</span>(axis=0),
            np.asarray(max_value).<span style="font-weight: bold;">max</span>(axis=0),
        )
        <span style="font-weight: bold; font-style: italic;">shift</span> = (
            (7 - (np.ceil(np.log2(np.<span style="font-weight: bold;">max</span>([<span style="font-weight: bold;">abs</span>(min_value), <span style="font-weight: bold;">abs</span>(max_value)], axis=0)))))
            .astype(<span style="font-weight: bold;">int</span>)
            .tolist()
        )
    <span style="font-weight: bold;">return</span> [(s[0], s[1]) <span style="font-weight: bold;">for</span> s <span style="font-weight: bold;">in</span> <span style="font-weight: bold;">zip</span>(shift[0::2], shift[1::2])]


<span style="font-weight: bold;">def</span> <span style="font-weight: bold;">quantize</span>(model, shift, ref_input):
    <span style="font-weight: bold; font-style: italic;">KWS_CMSIS_NN</span> = <span style="font-style: italic;">"model/kws_cmsis_nn.h"</span>

    <span style="font-weight: bold; font-style: italic;">int_bits</span> = <span style="font-weight: bold;">int</span>(np.ceil(np.log2(<span style="font-weight: bold;">max</span>(<span style="font-weight: bold;">abs</span>(ref_input.<span style="font-weight: bold;">min</span>()), <span style="font-weight: bold;">abs</span>(ref_input.<span style="font-weight: bold;">max</span>())))))
    <span style="font-weight: bold; font-style: italic;">dec_bits</span> = 7 - int_bits

    <span style="font-weight: bold;">with</span> <span style="font-weight: bold;">open</span>(KWS_CMSIS_NN, <span style="font-style: italic;">"w"</span>) <span style="font-weight: bold;">as</span> f:
        f.write(<span style="font-style: italic;">"// -*- eval: (sw/large-file-mode); -*-\n"</span>)
        f.write(<span style="font-style: italic;">"#define MFCC_DEC_BITS {}\n"</span>.<span style="font-weight: bold;">format</span>(dec_bits))

    <span style="font-weight: bold; font-style: italic;">i</span> = -1
    <span style="font-weight: bold;">for</span> layer <span style="font-weight: bold;">in</span> model.layers:
        <span style="font-weight: bold;">if</span> layer.name.startswith(<span style="font-style: italic;">"conv"</span>) <span style="font-weight: bold;">or</span> layer.name.startswith(<span style="font-style: italic;">"dense"</span>):
            <span style="font-weight: bold; font-style: italic;">i</span> += 1
            <span style="font-weight: bold;">print</span>(layer.name)
            <span style="font-weight: bold; font-style: italic;">fw</span> = <span style="font-weight: bold; text-decoration: underline;">None</span>
            <span style="font-weight: bold;">for</span> (t, value) <span style="font-weight: bold;">in</span> <span style="font-weight: bold;">enumerate</span>(layer.get_weights()):
                <span style="font-weight: bold; font-style: italic;">int_bits</span> = <span style="font-weight: bold;">int</span>(
                    np.ceil(np.log2(<span style="font-weight: bold;">max</span>(<span style="font-weight: bold;">abs</span>(value.<span style="font-weight: bold;">min</span>()), <span style="font-weight: bold;">abs</span>(value.<span style="font-weight: bold;">max</span>()))))
                )
                <span style="font-weight: bold; font-style: italic;">dec_bits</span> = 7 - int_bits
                <span style="font-weight: bold; font-style: italic;">q_value</span> = np.<span style="font-weight: bold;">round</span>(value * 2 ** dec_bits)

                <span style="font-weight: bold;">if</span> t == 0:
                    <span style="font-weight: bold; font-style: italic;">shift_name</span> = layer.name + <span style="font-style: italic;">"_out"</span>
                    <span style="font-weight: bold; font-style: italic;">var_name</span> = layer.name + <span style="font-style: italic;">"_weight"</span>
                    <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">fi+fw-fo</span>
                    <span style="font-weight: bold; font-style: italic;">fw</span> = dec_bits
                    <span style="font-weight: bold; font-style: italic;">shift_bits</span> = shift[i][0] + fw - shift[i][1]
                <span style="font-weight: bold;">else</span>:
                    <span style="font-weight: bold; font-style: italic;">shift_name</span> = layer.name + <span style="font-style: italic;">"_bias"</span>
                    <span style="font-weight: bold; font-style: italic;">var_name</span> = layer.name + <span style="font-style: italic;">"_bias"</span>
                    <span style="font-weight: bold; font-style: italic;">shift_bits</span> = shift[i][0] + fw - dec_bits

                <span style="font-weight: bold;">if</span> shift_bits &lt; 0:
                    <span style="font-weight: bold; font-style: italic;">shift_bits</span> = 0

                <span style="font-weight: bold;">with</span> <span style="font-weight: bold;">open</span>(KWS_CMSIS_NN, <span style="font-style: italic;">"a"</span>) <span style="font-weight: bold;">as</span> f:
                    f.write(
                        <span style="font-style: italic;">"#define {}_SHIFT {}\n"</span>.<span style="font-weight: bold;">format</span>(shift_name.upper(), shift_bits)
                    )

                    f.write(<span style="font-style: italic;">"#define {} {{"</span>.<span style="font-weight: bold;">format</span>(var_name.upper()))

                    <span style="font-weight: bold;">if</span> <span style="font-weight: bold;">len</span>(value.shape) == 4:
                        <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">tf   : HWNC</span>
                        <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">cmsis: CHWN</span>
                        <span style="font-weight: bold; font-style: italic;">q_value_t</span> = np.transpose(q_value, (3, 0, 1, 2))
                    <span style="font-weight: bold;">else</span>:
                        <span style="font-weight: bold; font-style: italic;">q_value_t</span> = np.transpose(q_value)
                        q_value_t.tofile(f, sep=<span style="font-style: italic;">", "</span>, <span style="font-weight: bold;">format</span>=<span style="font-style: italic;">"%d"</span>)
                        f.write(<span style="font-style: italic;">"}\n"</span>)


<span style="font-weight: bold;">if</span> <span style="font-weight: bold;">__name__</span> == <span style="font-style: italic;">"__main__"</span>:
    <span style="font-weight: bold; font-style: italic;">MODEL_PATH</span> = <span style="font-style: italic;">"./model/kws"</span>
    <span style="font-weight: bold; font-style: italic;">model</span> = keras.models.load_model(MODEL_PATH)

    <span style="font-weight: bold; font-style: italic;">ref_input</span> = np.load(<span style="font-style: italic;">"./temp/test_x.npy"</span>)
    <span style="font-weight: bold; font-style: italic;">shift</span> = collect_inference_statistics(model, ref_input)
    <span style="font-weight: bold;">print</span>(shift)
    quantize(model, shift, ref_input)

</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org328e08b" class="outline-3">
<h3 id="org328e08b"><span class="section-number-3">1.6</span> cmsis-nn 与 tflite 量化</h3>
<div class="outline-text-3" id="text-1-6">
<p>
tflite for mcu 底层支持 cmsis-nn, 但 tflite 的量化规范来自于 gemmlowp, 与前面描
述的基于 2^n 的对称量化并不一致. 事实上, cmsis-nn 针对 tflite 的量化需求提供了另
外一套 api
</p>

<p>
<a href="file:///home/sunway/source/tensorflow/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/README.md#org0933d36">file:///home/sunway/source/tensorflow/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/README.md#org0933d36</a>
</p>
</div>
</div>
</div>


<div id="outline-container-org0ea879a" class="outline-2 references">
<h2 id="org0ea879a">Backlinks</h2>
<div class="outline-text-2" id="text-org0ea879a">
<p>
<a href="quantization.html#ID-6ad56dfa-9772-478b-9872-6f8294d6cb19">Quantization</a>
(<i>Quantization &gt; CMSIS Quantization Example</i>):   <a href="cmsis_quantization_example.html#ID-d51beea9-ed7e-4308-9659-7832d723f6e3">CMSIS Quantization Example</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2020-09-21 Mon 00:00<br />
Last updated: 2022-01-26 Wed 11:25</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
