<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>CMSIS Quantization</title>

<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">CMSIS Quantization</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0000021">1. CMSIS Quantization</a>
<ul>
<li><a href="#ID-7bbad843-6d6f-47b6-a89e-19ace4a617ed">1.1. output_shift 与 bias_shift</a>
<ul>
<li><a href="#org0000000">1.1.1. dec_bit</a></li>
<li><a href="#org0000003">1.1.2. 计算 dense layer 的量化参数</a></li>
</ul>
</li>
<li><a href="#org0000009">1.2. weight 量化</a></li>
<li><a href="#org000000c">1.3. activiation 量化</a></li>
<li><a href="#org000000f">1.4. 坑</a></li>
<li><a href="#org000001b">1.5. Sample</a>
<ul>
<li><a href="#org0000012">1.5.1. keras 模型</a></li>
<li><a href="#org0000015">1.5.2. cmsis 模型</a></li>
<li><a href="#org0000018">1.5.3. 量化</a></li>
</ul>
</li>
<li><a href="#org000001e">1.6. cmsis-nn 与 tflite 量化</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000021" class="outline-2">
<h2 id="org0000021"><span class="section-number-2">1</span> CMSIS Quantization</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-ID-7bbad843-6d6f-47b6-a89e-19ace4a617ed" class="outline-3">
<h3 id="ID-7bbad843-6d6f-47b6-a89e-19ace4a617ed"><span class="section-number-3">1.1</span> output_shift 与 bias_shift</h3>
<div class="outline-text-3" id="text-1-1">
</div>

<div id="outline-container-org0000000" class="outline-4">
<h4 id="org0000000"><span class="section-number-4">1.1.1</span> dec_bit</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
dec_bit 指 float 最多可以左移 dec_bit 而不超过量化范围.
</p>

<p>
例如, 假设量化范围为 int8, 则 [-128, 127), 若 float 为 2.0, 则 dec_bit 为 5,因为
2.0 &lt;&lt; 5 = 64, 而 2.0 &lt;&lt; 6 = 128, 所以最大移位为 5
</p>

<p>
以 int8 量化为例, 计算 dec_bit 的公式为
</p>

<p>
\(dec\_bit(x)=7 - (np.ceil(np.log2(x)))\)
</p>

<p>
CMSIS 是对称量化, 且 scale 为 \(2^{dec\_bit(abs(x)_{max})}\)
</p>

<p>
需要注意的是后面提到的 scale, shift 等都是指 dec_bit, 而不是 \(2^{dec\_bit}\)
</p>
</div>
</div>

<div id="outline-container-org0000003" class="outline-4">
<h4 id="org0000003"><span class="section-number-4">1.1.2</span> 计算 dense layer 的量化参数</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
实际上 dense layer 涉及到四个量化参数:
</p>

<ul class="org-ul">
<li>fi: input scale</li>
<li>fw: weight scale</li>
<li>fo: output scale</li>
<li>fb: bias scale</li>
</ul>

<p>
但 cmsis_nn api 要求提供两个参数做为量化参数:
</p>

<ul class="org-ul">
<li>output_shift</li>
<li>bias_shift</li>
</ul>

<p>
其中:
</p>

<ul class="org-ul">
<li>\(output\_shift = fi+fw-fo\)</li>
<li>\(bias\_shift = fi+fw-fb\)</li>
</ul>

<p>
之所以需要这两个参数是因为:
</p>

<p>
假设要计算 \(o=w*x+b\), w,x,b 是原始的浮点数, W,X,B,O 是分别量化的结果. 如何通过
W,X,B 得到 O?
</p>

<p>
并不能直接通过 \(O=W*X+B\), 因为各部分是分别量化的, scale 不同, 不能直接运算.
</p>

<ol class="org-ol">
<li>B 与 W*X 相加时, 需要 B 左移 \(f_i+f_w-f_b\) 位变成和 W*X 相同的 scale</li>

<li>\(W*X+(B\ll bias\_shift)\) 的结果需要先右移 \(f_i+f_w\) 得到浮点数, 再左移 \(f_o\) 得到 OUTPUT, 合并起来就是右移 output_shift</li>
</ol>

<p>
所以最终的过程是: \((W*X+ (B \ll bias\_shift)) \gg output\_shift\)
</p>

<p>
例如:
</p>

<p>
为便于理解, 把 scale 看作是 10 的幂 (而不是 2 的幂)
</p>

<p>
假设 input 为 0.1, weight 为 0.01, bias = 0.1.
</p>

<p>
未量化时 wx+b 的值为 0.001+0.1=0.101
</p>

<p>
设对 x/w/b/o 量化的 dec_bit 分别为 1/2/1/2; W/X/B/O 分别是 w/x/b/o 量化后的结果.
</p>

<p>
如何使用 W/X/B 得到 O?
</p>

<p>
\(wx+b=o \implies wx+b=(\frac{X}{10})*(\frac{W}{100})+\frac{B}{10}=\frac{XW}{1000}+\frac{B}{10}=\frac{XW+100B}{1000}=\frac{O}{100}\implies
\frac{XW+100B}{10}=O\)
</p>

<p>
最后的式子显示于 B 需要左移 2 (fi+fw-fb), 且 output 需要右移 1 (fi+fw-fo) 才能最终得于 O
</p>

<p>
用 tflite 的量化模型进行推理时, 在 <a href="tflite_quantization_detail.html#ID-0aa3a8eb-ef6b-42e7-9192-059a100f2af5">Prepare</a> 阶段同样使用 output_shift, 不过名字叫
real_multiplier
</p>
</div>
</div>


<div id="outline-container-org0000006" class="outline-4 references">
<h4 id="org0000006">Backlinks</h4>
<div class="outline-text-4" id="text-org0000006">
<p>
<a href="quantization.html#ID-6ad56dfa-9772-478b-9872-6f8294d6cb19">Quantization</a>
(<i>Quantization &gt; Overview</i>):  其中两个 layer 之间的 `DQ&#x2013;Q` 是一个常量, 可以提前转换成近似的整数操作 (例如 cmsis 的 <a href="#ID-7bbad843-6d6f-47b6-a89e-19ace4a617ed">output_shift</a> 和 tflite 的 <a href="tflite_quantization_detail.html#ID-0aa3a8eb-ef6b-42e7-9192-059a100f2af5">real_multiplier</a>)
</p>
</div>
</div>
</div>


<div id="outline-container-org0000009" class="outline-3">
<h3 id="org0000009"><span class="section-number-3">1.2</span> weight 量化</h3>
<div class="outline-text-3" id="text-1-2">
<p>
根据 weight 本身的范围确定 weight 的 dec_bit, 然后令 W=w*(2**dec_bit) 即可
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-variable-name">dec_bit</span> = 7 - (np.ceil(np.log2(np.<span class="org-builtin">max</span>([<span class="org-builtin">abs</span>(min_weight), <span class="org-builtin">abs</span>(max_weight)], axis=0))))
</pre>
</div>
</div>
</div>

<div id="outline-container-org000000c" class="outline-3">
<h3 id="org000000c"><span class="section-number-3">1.3</span> activiation 量化</h3>
<div class="outline-text-3" id="text-1-3">
<p>
使用一些参考输入, 确定每一层的输入输出的范围, 计算各自的 dec_bit 做为相应的 fi,
fo, 配合 fw 可以获得 output_shift 和 bias_shift
</p>
</div>
</div>

<div id="outline-container-org000000f" class="outline-3">
<h3 id="org000000f"><span class="section-number-3">1.4</span> 坑</h3>
<div class="outline-text-3" id="text-1-4">
<ol class="org-ol">
<li><p>
keras layer activation
</p>

<p>
keras.Layers.Dense(16, activiation="softmax"), 这一层的输出会包含 softmax 的结果, 所以使用这一层的输出计算的量化参数并不是 dense layer 的参数.
</p>

<p>
解决的方法是把 softmax 做为单独的一层, 不要和 dense 写在一起
</p></li>

<li><p>
ReLU 导致的问题
</p>

<p>
假设网络结构为:
</p>

<p>
FC1 -&gt; ReLU -&gt; FC2
</p>

<p>
正常情况下, cmsis relu 的代码应该是这样的:
</p>

<div class="org-src-container">
<pre class="src src-C"><span class="org-type">void</span> <span class="org-function-name">relu</span>(input, output_shift, ouput) {
    <span class="org-comment-delimiter">/* </span><span class="org-comment">cmsis &#26159;&#23545;&#31216;&#37327;&#21270;, &#25152;&#20197; input_bias=0</span><span class="org-comment-delimiter"> */</span>
    <span class="org-type">int</span> <span class="org-variable-name">input_bias</span> = 0;
    <span class="org-keyword">if</span> (input &gt; input_bias) {
        <span class="org-keyword">return</span> input &gt;&gt; output_shift
    }
    <span class="org-keyword">return</span> 0
}
</pre>
</div>

<p>
但实际上 cmsis 的 relu api 并不支持 output_shift 参数, 或者说 output_shift 为
0, 即 relu 的 output_scale 等于 input_scale (因为
output_shift=input_scale-output_scale)
</p>

<p>
所以 FC2 的 input_scale 应该直接使用 ReLU 的 input_scale, 而不能自己根据 FC2
input 范围来计算, 相当于量化时 relu 被 `pass throught`.
</p>

<p>
除了 ReLU, CMSIS 中的 average pooling, max pooling, 也有类似的问题 (softmax
是否有这个问题还不确定&#x2026;)
</p>

<p>
Q: FC, CONV 为什么不像 ReLU 一样直接忽略 output_shift?
</p>

<p>
A: FC, CONV 会进行乘加, 结果会很快超出 int8 范围, output_shift 相当于是通过
Q(DQ(output_1, dec_bit_output_1), dec_bit_input_2) 保证输出在 int8 范围内. 但
ReLU, pooling 不存在这个问题
</p></li>

<li><p>
训练的越多越不准确&#x2026;
</p>

<p>
最初的模型使用了 dropout 做正则化 (而没有使用 batch norm 或 l1/l2
regularizer), 导致训练的越多 weight 越大 (从 0.x 增加到 2.x), 而 weight 变大又导致 activiation 变大 (从几十增加到几千), 而 cmsis-nn 的 output_shift 只支持右移, 即它假设 activiation 总是在 [-128,128) 范围内, 当 activiation 远远大于这个范围时, 缺失的左移操作会导致结果不准确.
</p>

<p>
解决的方法:
</p>

<ol class="org-ol">
<li>使用 batch norm, 保证 activiation 在一定范围</li>

<li>使用 l1/l2 regularizer, 保证 weight 在较小的范围</li>
</ol></li>
</ol>
</div>
</div>


<div id="outline-container-org000001b" class="outline-3">
<h3 id="org000001b"><span class="section-number-3">1.5</span> Sample</h3>
<div class="outline-text-3" id="text-1-5">
</div>
<div id="outline-container-org0000012" class="outline-4">
<h4 id="org0000012"><span class="section-number-4">1.5.1</span> keras 模型</h4>
<div class="outline-text-4" id="text-1-5-1">
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">cnn</span>():
    <span class="org-variable-name">inputs</span> = keras.Input(shape=(FRAMES, DCT_COEFFICIENT_COUNT))
    <span class="org-variable-name">outputs</span> = tf.expand_dims(inputs, axis=-1)

    <span class="org-variable-name">outputs</span> = layers.Conv2D(
        filters=28, kernel_size=[10, 4], strides=[1, 1], name=<span class="org-string">"conv1"</span>
    )(outputs)
    <span class="org-comment-delimiter"># </span><span class="org-comment">outputs = layers.BatchNormalization()(outputs)</span>
    <span class="org-variable-name">outputs</span> = layers.ReLU()(outputs)
    <span class="org-variable-name">outputs</span> = layers.Dropout(0.3)(outputs)

    <span class="org-variable-name">outputs</span> = layers.Conv2D(
        filters=30, kernel_size=[10, 4], strides=[2, 1], name=<span class="org-string">"conv2"</span>
    )(outputs)
    <span class="org-comment-delimiter"># </span><span class="org-comment">outputs = layers.BatchNormalization()(outputs)</span>
    <span class="org-variable-name">outputs</span> = layers.ReLU()(outputs)
    <span class="org-variable-name">outputs</span> = layers.Dropout(0.2)(outputs)

    <span class="org-variable-name">outputs</span> = layers.Flatten()(outputs)

    <span class="org-variable-name">outputs</span> = layers.Dense(16, name=<span class="org-string">"dense1"</span>)(outputs)
    <span class="org-comment-delimiter"># </span><span class="org-comment">outputs = layers.BatchNormalization()(outputs)</span>
    <span class="org-variable-name">outputs</span> = layers.ReLU()(outputs)
    <span class="org-variable-name">outputs</span> = layers.Dropout(0.1)(outputs)

    <span class="org-variable-name">outputs</span> = layers.Dense(128, name=<span class="org-string">"dense2"</span>)(outputs)
    <span class="org-variable-name">outputs</span> = layers.ReLU()(outputs)
    <span class="org-variable-name">outputs</span> = layers.Dense(<span class="org-builtin">len</span>(WORDS), name=<span class="org-string">"dense3"</span>)(outputs)
    <span class="org-variable-name">outputs</span> = layers.Softmax()(outputs)

    <span class="org-keyword">return</span> keras.Model(inputs, outputs)
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000015" class="outline-4">
<h4 id="org0000015"><span class="section-number-4">1.5.2</span> cmsis 模型</h4>
<div class="outline-text-4" id="text-1-5-2">
<div class="org-src-container">
<pre class="src src-C"><span class="org-type">void</span> <span class="org-function-name">CNN</span>::run_nn(<span class="org-type">q7_t</span>* <span class="org-variable-name">in_data</span>, <span class="org-type">q7_t</span>* <span class="org-variable-name">out_data</span>) {
    arm_convolve_HWC_q7_basic_nonsquare(
        in_data, CONV1_IN_X, CONV1_IN_Y, CONV1_IN_CH, conv1_wt, CONV1_OUT_CH,
        CONV1_KERNEL_X, CONV1_KERNEL_Y, CONV1_PADDING_X, CONV1_PADDING_Y,
        CONV1_STRIDE_X, CONV1_STRIDE_Y, conv1_bias, CONV1_BIAS_SHIFT,
        CONV1_OUT_SHIFT, buffer1, CONV1_OUT_X, CONV1_OUT_Y, (<span class="org-type">q15_t</span>*)buffer3,
        <span class="org-constant">NULL</span>);
    arm_relu_q7(buffer1, CONV1_OUT_X * CONV1_OUT_Y * CONV1_OUT_CH);
    arm_convolve_HWC_q7_basic_nonsquare(
        buffer1, CONV2_IN_X, CONV2_IN_Y, CONV2_IN_CH, conv2_wt, CONV2_OUT_CH,
        CONV2_KERNEL_X, CONV2_KERNEL_Y, CONV2_PADDING_X, CONV2_PADDING_Y,
        CONV2_STRIDE_X, CONV2_STRIDE_Y, conv2_bias, CONV2_BIAS_SHIFT,
        CONV2_OUT_SHIFT, buffer2, CONV2_OUT_X, CONV2_OUT_Y, (<span class="org-type">q15_t</span>*)buffer3,
        <span class="org-constant">NULL</span>);
    arm_relu_q7(buffer2, CONV2_OUT_X * CONV2_OUT_Y * CONV2_OUT_CH);
    arm_fully_connected_q7(
        buffer2, dense1_wt, DENSE1_INPUT_DIM, DENSE1_OUTPUT_DIM,
        DENSE1_BIAS_SHIFT, DENSE1_OUT_SHIFT, dense1_bias, buffer1,
        (<span class="org-type">q15_t</span>*)buffer3);
    arm_relu_q7(buffer1, DENSE1_OUTPUT_DIM);
    arm_fully_connected_q7(
        buffer1, dense2_wt, DENSE2_INPUT_DIM, DENSE2_OUTPUT_DIM,
        DENSE2_BIAS_SHIFT, DENSE2_OUT_SHIFT, dense2_bias, buffer2,
        (<span class="org-type">q15_t</span>*)buffer3);
    arm_relu_q7(buffer2, DENSE2_OUTPUT_DIM);
    arm_fully_connected_q7(
        buffer2, dense3_wt, DENSE3_INPUT_DIM, DENSE3_OUTPUT_DIM,
        DENSE3_BIAS_SHIFT, DENSE3_OUT_SHIFT, dense3_bias, out_data,
        (<span class="org-type">q15_t</span>*)buffer3);
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000018" class="outline-4">
<h4 id="org0000018"><span class="section-number-4">1.5.3</span> 量化</h4>
<div class="outline-text-4" id="text-1-5-3">
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> tensorflow <span class="org-keyword">as</span> tf
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">from</span> tensorflow <span class="org-keyword">import</span> keras
<span class="org-keyword">from</span> tensorflow.keras <span class="org-keyword">import</span> layers, losses, metrics, optimizers, models

tf.keras.backend.clear_session()


<span class="org-keyword">def</span> <span class="org-function-name">collect_inference_statistics</span>(model, ref_input):
    <span class="org-builtin">input</span> = model.layers[0].output
    <span class="org-variable-name">prev</span> = model.layers[0]
    <span class="org-variable-name">outputs</span> = []
    <span class="org-keyword">for</span> layer <span class="org-keyword">in</span> model.layers:
        <span class="org-keyword">if</span> layer.name.startswith(<span class="org-string">"conv"</span>) <span class="org-keyword">or</span> layer.name.startswith(<span class="org-string">"dense"</span>):
            outputs.append(prev.output)
            outputs.append(layer.output)
            <span class="org-variable-name">prev</span> = layer

    <span class="org-variable-name">model</span> = keras.Model(<span class="org-builtin">input</span>, outputs)

    <span class="org-variable-name">max_value</span>, <span class="org-variable-name">min_value</span> = [], []
    <span class="org-keyword">for</span> x <span class="org-keyword">in</span> ref_input[0:2000]:
        <span class="org-variable-name">value</span> = [(i.numpy().<span class="org-builtin">min</span>(), i.numpy().<span class="org-builtin">max</span>()) <span class="org-keyword">for</span> i <span class="org-keyword">in</span> model(x)]
        min_value.append([v[0] <span class="org-keyword">for</span> v <span class="org-keyword">in</span> value])
        max_value.append([v[1] <span class="org-keyword">for</span> v <span class="org-keyword">in</span> value])
        <span class="org-variable-name">min_value</span>, <span class="org-variable-name">max_value</span> = (
            np.asarray(min_value).<span class="org-builtin">min</span>(axis=0),
            np.asarray(max_value).<span class="org-builtin">max</span>(axis=0),
        )
        <span class="org-variable-name">shift</span> = (
            (7 - (np.ceil(np.log2(np.<span class="org-builtin">max</span>([<span class="org-builtin">abs</span>(min_value), <span class="org-builtin">abs</span>(max_value)], axis=0)))))
            .astype(<span class="org-builtin">int</span>)
            .tolist()
        )
    <span class="org-keyword">return</span> [(s[0], s[1]) <span class="org-keyword">for</span> s <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(shift[0::2], shift[1::2])]


<span class="org-keyword">def</span> <span class="org-function-name">quantize</span>(model, shift, ref_input):
    <span class="org-variable-name">KWS_CMSIS_NN</span> = <span class="org-string">"model/kws_cmsis_nn.h"</span>

    <span class="org-variable-name">int_bits</span> = <span class="org-builtin">int</span>(np.ceil(np.log2(<span class="org-builtin">max</span>(<span class="org-builtin">abs</span>(ref_input.<span class="org-builtin">min</span>()), <span class="org-builtin">abs</span>(ref_input.<span class="org-builtin">max</span>())))))
    <span class="org-variable-name">dec_bits</span> = 7 - int_bits

    <span class="org-keyword">with</span> <span class="org-builtin">open</span>(KWS_CMSIS_NN, <span class="org-string">"w"</span>) <span class="org-keyword">as</span> f:
        f.write(<span class="org-string">"// -*- eval: (sw/large-file-mode); -*-\n"</span>)
        f.write(<span class="org-string">"#define MFCC_DEC_BITS {}\n"</span>.<span class="org-builtin">format</span>(dec_bits))

    <span class="org-variable-name">i</span> = -1
    <span class="org-keyword">for</span> layer <span class="org-keyword">in</span> model.layers:
        <span class="org-keyword">if</span> layer.name.startswith(<span class="org-string">"conv"</span>) <span class="org-keyword">or</span> layer.name.startswith(<span class="org-string">"dense"</span>):
            <span class="org-variable-name">i</span> += 1
            <span class="org-keyword">print</span>(layer.name)
            <span class="org-variable-name">fw</span> = <span class="org-constant">None</span>
            <span class="org-keyword">for</span> (t, value) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(layer.get_weights()):
                <span class="org-variable-name">int_bits</span> = <span class="org-builtin">int</span>(
                    np.ceil(np.log2(<span class="org-builtin">max</span>(<span class="org-builtin">abs</span>(value.<span class="org-builtin">min</span>()), <span class="org-builtin">abs</span>(value.<span class="org-builtin">max</span>()))))
                )
                <span class="org-variable-name">dec_bits</span> = 7 - int_bits
                <span class="org-variable-name">q_value</span> = np.<span class="org-builtin">round</span>(value * 2 ** dec_bits)

                <span class="org-keyword">if</span> t == 0:
                    <span class="org-variable-name">shift_name</span> = layer.name + <span class="org-string">"_out"</span>
                    <span class="org-variable-name">var_name</span> = layer.name + <span class="org-string">"_weight"</span>
                    <span class="org-comment-delimiter"># </span><span class="org-comment">fi+fw-fo</span>
                    <span class="org-variable-name">fw</span> = dec_bits
                    <span class="org-variable-name">shift_bits</span> = shift[i][0] + fw - shift[i][1]
                <span class="org-keyword">else</span>:
                    <span class="org-variable-name">shift_name</span> = layer.name + <span class="org-string">"_bias"</span>
                    <span class="org-variable-name">var_name</span> = layer.name + <span class="org-string">"_bias"</span>
                    <span class="org-variable-name">shift_bits</span> = shift[i][0] + fw - dec_bits

                <span class="org-keyword">if</span> shift_bits &lt; 0:
                    <span class="org-variable-name">shift_bits</span> = 0

                <span class="org-keyword">with</span> <span class="org-builtin">open</span>(KWS_CMSIS_NN, <span class="org-string">"a"</span>) <span class="org-keyword">as</span> f:
                    f.write(
                        <span class="org-string">"#define {}_SHIFT {}\n"</span>.<span class="org-builtin">format</span>(shift_name.upper(), shift_bits)
                    )

                    f.write(<span class="org-string">"#define {} {{"</span>.<span class="org-builtin">format</span>(var_name.upper()))

                    <span class="org-keyword">if</span> <span class="org-builtin">len</span>(value.shape) == 4:
                        <span class="org-comment-delimiter"># </span><span class="org-comment">tf   : HWNC</span>
                        <span class="org-comment-delimiter"># </span><span class="org-comment">cmsis: CHWN</span>
                        <span class="org-variable-name">q_value_t</span> = np.transpose(q_value, (3, 0, 1, 2))
                    <span class="org-keyword">else</span>:
                        <span class="org-variable-name">q_value_t</span> = np.transpose(q_value)
                        q_value_t.tofile(f, sep=<span class="org-string">", "</span>, <span class="org-builtin">format</span>=<span class="org-string">"%d"</span>)
                        f.write(<span class="org-string">"}\n"</span>)


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> == <span class="org-string">"__main__"</span>:
    <span class="org-variable-name">MODEL_PATH</span> = <span class="org-string">"./model/kws"</span>
    <span class="org-variable-name">model</span> = keras.models.load_model(MODEL_PATH)

    <span class="org-variable-name">ref_input</span> = np.load(<span class="org-string">"./temp/test_x.npy"</span>)
    <span class="org-variable-name">shift</span> = collect_inference_statistics(model, ref_input)
    <span class="org-keyword">print</span>(shift)
    quantize(model, shift, ref_input)

</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org000001e" class="outline-3">
<h3 id="org000001e"><span class="section-number-3">1.6</span> cmsis-nn 与 tflite 量化</h3>
<div class="outline-text-3" id="text-1-6">
<p>
tflite for mcu 底层支持 cmsis-nn, 但 tflite 的量化规范来自于 gemmlowp, 与前面描述的基于 2^n 的对称量化并不一致. 事实上, cmsis-nn 针对 tflite 的量化需求提供了另外一套 api
</p>

<p>
<a href="file:///home/sunway/source/tensorflow/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/README.md#org0000000">file:///home/sunway/source/tensorflow/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/README.md#org0000000</a>
</p>
</div>
</div>
</div>


<div id="outline-container-org0000024" class="outline-2 references">
<h2 id="org0000024">Backlinks</h2>
<div class="outline-text-2" id="text-org0000024">
<p>
<a href="quantization.html#ID-6ad56dfa-9772-478b-9872-6f8294d6cb19">Quantization</a>
(<i>Quantization &gt; Overview</i>):  scale 正常为浮点数, 但有些框架例如 <a href="cmsis_quantization_example.html#ID-d51beea9-ed7e-4308-9659-7832d723f6e3">CMSIS</a> 会要求 scale 的值必须是 \(2^{n}\) 的形式, 这样可以避免浮点数乘法, 同时可以用移位代替整数乘法. tflite 会使用浮点数 scale, 但是可以用 <a href="tflite_quantization_detail.html#ID-4c9c1064-5ff5-4111-95bf-2916a5b24e9e">rounding_doubling_high_mul</a> 转换为整数乘法.
</p>

<p>
<a href="quantization.html#ID-6ad56dfa-9772-478b-9872-6f8294d6cb19">Quantization</a>
(<i>Quantization &gt; CMSIS Quantization</i>):   <a href="cmsis_quantization_example.html#ID-d51beea9-ed7e-4308-9659-7832d723f6e3">CMSIS Quantization</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2020-09-21 Mon 00:00<br />
Last updated: 2022-03-08 Tue 20:09</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
