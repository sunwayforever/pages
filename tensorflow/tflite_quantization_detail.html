<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-01-26 Wed 01:15 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>TFLite Quantization Details</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Wei Sun (孙伟)" />
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">TFLite Quantization Details</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org859a656">1. TFLite Quantization Details</a>
<ul>
<li><a href="#org69f6881">1.1. Mul Reference Kernel</a>
<ul>
<li><a href="#org3c8a18e">1.1.1. Overview</a></li>
<li><a href="#org8fb21ee">1.1.2. rounding_doubling_high_mul</a></li>
<li><a href="#orgf43acfb">1.1.3. Prepare</a></li>
<li><a href="#org1fd7e68">1.1.4. EvalQuantized</a></li>
<li><a href="#orgbbb32a3">1.1.5. Reference Kernel</a></li>
</ul>
</li>
<li><a href="#org8e63da7">1.2. FullyConnected Reference Kernel</a>
<ul>
<li><a href="#org72ad764">1.2.1. Quantize</a></li>
<li><a href="#org1c145c8">1.2.2. Prepare</a></li>
<li><a href="#org9dd12e4">1.2.3. EvalQuantized</a></li>
<li><a href="#org89b338d">1.2.4. Reference Kernel</a></li>
</ul>
</li>
<li><a href="#ID-6470583f-2076-4f0e-96e4-aef98fff8a01">1.3. BatchNorm 导致很大的量化误差</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org859a656" class="outline-2">
<h2 id="org859a656"><span class="section-number-2">1</span> TFLite Quantization Details</h2>
<div class="outline-text-2" id="text-1">
<p>

</p>
</div>

<div id="outline-container-org69f6881" class="outline-3">
<h3 id="org69f6881"><span class="section-number-3">1.1</span> Mul Reference Kernel</h3>
<div class="outline-text-3" id="text-1-1">
<p>
以最简单的 Mul 的 reference kernel 为例, 介绍 EvalQuantized 的流程
</p>
</div>

<div id="outline-container-org3c8a18e" class="outline-4">
<h4 id="org3c8a18e"><span class="section-number-4">1.1.1</span> Overview</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
Mul, 即 a*b=c 操作, 量化后实际上需要计算的是:
</p>

<p>
已知 \(S_a, Q_a, Z_a, S_b, Q_b, Z_b, S_c, Z_c\), 根据 \(S_a(Q_a-Z_a)*S_b(Q_b-Z_b)=S_c(Q_c-Z_c)\)  计算出 \(Q_c\)
</p>

<p>
tflite 量化时会保证所有的 \(Z\) 都是整数, 但 \(S\) 是浮点数
</p>
</div>
</div>

<div id="outline-container-org8fb21ee" class="outline-4">
<h4 id="org8fb21ee"><span class="section-number-4">1.1.2</span> rounding_doubling_high_mul</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
rounding_doubling_high_mul 解决的问题是如何用整数运算来计算 int*float
</p>

<div class="org-src-container">
<pre class="src src-C++"><span style="font-weight: bold;">#include</span> <span style="font-style: italic;">&lt;cmath&gt;</span>
<span style="font-weight: bold;">#include</span> <span style="font-style: italic;">&lt;cstdint&gt;</span>
<span style="font-weight: bold;">#include</span> <span style="font-style: italic;">&lt;cstdio&gt;</span>
<span style="font-weight: bold;">#include</span> <span style="font-style: italic;">&lt;limits&gt;</span>

<span style="font-weight: bold;">inline</span> <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold;">SaturatingRoundingDoublingHighMul</span>(<span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">a</span>, <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">b</span>) {
    <span style="font-weight: bold; text-decoration: underline;">bool</span> <span style="font-weight: bold; font-style: italic;">overflow</span> = a == b &amp;&amp; a == <span style="font-weight: bold; text-decoration: underline;">std</span>::<span style="font-weight: bold; text-decoration: underline;">numeric_limits</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int32_t</span>&gt;::min();
    <span style="font-weight: bold; text-decoration: underline;">int64_t</span> <span style="font-weight: bold; font-style: italic;">a_64</span>(a);
    <span style="font-weight: bold; text-decoration: underline;">int64_t</span> <span style="font-weight: bold; font-style: italic;">b_64</span>(b);
    <span style="font-weight: bold; text-decoration: underline;">int64_t</span> <span style="font-weight: bold; font-style: italic;">ab_64</span> = a_64 * b_64;
    <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">nudge</span> = ab_64 &gt;= 0 ? (1 &lt;&lt; 30) : (1 - (1 &lt;&lt; 30));
    <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">ab_x2_high32</span> = <span style="font-weight: bold;">static_cast</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int32_t</span>&gt;((ab_64 + nudge) / (1ll &lt;&lt; 31));
    <span style="font-weight: bold;">return</span> overflow ? <span style="font-weight: bold; text-decoration: underline;">std</span>::<span style="font-weight: bold; text-decoration: underline;">numeric_limits</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int32_t</span>&gt;::max() : ab_x2_high32;
}

<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold;">quantized_mulitply</span>(<span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">a</span>, <span style="font-weight: bold; text-decoration: underline;">float</span> <span style="font-weight: bold; font-style: italic;">b</span>) {
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">prepare</span>
    <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">shift</span> = 0;
    <span style="font-weight: bold; text-decoration: underline;">double</span> <span style="font-weight: bold; font-style: italic;">q</span> = <span style="font-weight: bold; text-decoration: underline;">std</span>::frexp(b, &amp;shift);
    printf(<span style="font-style: italic;">"-- %f %d\n"</span>, q, shift);
    <span style="font-weight: bold;">auto</span> <span style="font-weight: bold; font-style: italic;">q_fixed</span> = <span style="font-weight: bold;">static_cast</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int64_t</span>&gt;(<span style="font-weight: bold; text-decoration: underline;">int</span>(q * (1ll &lt;&lt; 31)));
    printf(<span style="font-style: italic;">"-- %ld\n"</span>, q_fixed);
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">eval</span>
    <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">x</span> = SaturatingRoundingDoublingHighMul(100, (<span style="font-weight: bold; text-decoration: underline;">int32_t</span>)q_fixed);
    printf(<span style="font-style: italic;">"-- %d\n"</span>, x);
    <span style="font-weight: bold;">return</span> x &gt;&gt; (-shift);
}

<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold;">main</span>(<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">argc</span>, <span style="font-weight: bold; text-decoration: underline;">char</span> *<span style="font-weight: bold; font-style: italic;">argv</span>[]) {
    <span style="font-weight: bold; text-decoration: underline;">int32_t</span> <span style="font-weight: bold; font-style: italic;">a</span> = 100;
    <span style="font-weight: bold; text-decoration: underline;">float</span> <span style="font-weight: bold; font-style: italic;">b</span> = 0.12;
    printf(<span style="font-style: italic;">"%d * %f = %d\n"</span>, a, b, quantized_mulitply(a, b));
    <span style="font-weight: bold;">return</span> 0;
}

</pre>
</div>

<p>
&#x2013; 0.768000 -6
&#x2013; 1649267456
&#x2013; 77
100 * 0.012000 = 1
</p>
</div>
</div>

<div id="outline-container-orgf43acfb" class="outline-4">
<h4 id="orgf43acfb"><span class="section-number-4">1.1.3</span> Prepare</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>

</p>

<div class="org-src-container">
<pre class="src src-c++">mul.<span style="font-weight: bold; text-decoration: underline;">cc</span>:<span style="font-weight: bold; text-decoration: underline;">Prepare</span>:
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">S_a(Q_a-Z_a)*S_b(Q_b-Z_b)=S_c(Q_c-Z_c)</span>
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">real_multiplier &#20026; (S_a*S_b)/(S_c)</span>
    <span style="font-weight: bold; text-decoration: underline;">double</span> <span style="font-weight: bold; font-style: italic;">real_multiplier</span> =
        input1-&gt;params.scale * input2-&gt;params.scale / output-&gt;params.scale;

    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">QuantizeMultiplier &#20250;&#25226; real_multiplier &#36716;&#25442;&#20026;&#19968;&#20010;&#25972;&#25968;&#21644;&#19968;&#20010; shift &#30340;&#24418;&#24335;</span>
    QuantizeMultiplier(real_multiplier, &amp;data-&gt;output_multiplier,
                       &amp;data-&gt;output_shift);
</pre>
</div>
</div>

<div id="outline-container-org490d7ad" class="outline-5">
<h5 id="org490d7ad"><span class="section-number-5">1.1.3.1</span> QuantizeMultiplier</h5>
<div class="outline-text-5" id="text-1-1-3-1">
<p>
QuantizeMultiplier 会把浮点的 real_multiplier (即 scale) 变为 int/shift 的形式,
例如, 若 real_multiplier 为 0.012, 则 quantized_multiplier 为 1649267456, shift
为 -6 (参考 <a href="#org8fb21ee">rounding_doubling_high_mul</a>)
</p>

<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold; text-decoration: underline;">void</span> <span style="font-weight: bold;">QuantizeMultiplier</span>(<span style="font-weight: bold; text-decoration: underline;">double</span> <span style="font-weight: bold; font-style: italic;">double_multiplier</span>, <span style="font-weight: bold; text-decoration: underline;">int32_t</span>* <span style="font-weight: bold; font-style: italic;">quantized_multiplier</span>,
                        <span style="font-weight: bold; text-decoration: underline;">int</span>* <span style="font-weight: bold; font-style: italic;">shift</span>) {
  <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">double</span> <span style="font-weight: bold; font-style: italic;">q</span> = <span style="font-weight: bold; text-decoration: underline;">std</span>::frexp(double_multiplier, shift);
  <span style="font-weight: bold;">auto</span> <span style="font-weight: bold; font-style: italic;">q_fixed</span> = <span style="font-weight: bold;">static_cast</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int64_t</span>&gt;(TfLiteRound(q * (1ll &lt;&lt; 31)));
  *quantized_multiplier = <span style="font-weight: bold;">static_cast</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int32_t</span>&gt;(q_fixed);
}
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org1fd7e68" class="outline-4">
<h4 id="org1fd7e68"><span class="section-number-4">1.1.4</span> EvalQuantized</h4>
<div class="outline-text-4" id="text-1-1-4">
<p>

</p>

<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold;">template</span> &lt;<span style="font-weight: bold; text-decoration: underline;">KernelType</span> <span style="font-weight: bold; font-style: italic;">kernel_type</span>&gt;
<span style="font-weight: bold; text-decoration: underline;">TfLiteStatus</span> <span style="font-weight: bold;">EvalQuantized</span>(
    <span style="font-weight: bold; text-decoration: underline;">TfLiteContext</span>* <span style="font-weight: bold; font-style: italic;">context</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteNode</span>* <span style="font-weight: bold; font-style: italic;">node</span>, <span style="font-weight: bold; text-decoration: underline;">TfLiteMulParams</span>* <span style="font-weight: bold; font-style: italic;">params</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">OpData</span>* <span style="font-weight: bold; font-style: italic;">data</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">input1</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">input2</span>,
    <span style="font-weight: bold; text-decoration: underline;">TfLiteTensor</span>* <span style="font-weight: bold; font-style: italic;">output</span>) {

    <span style="font-weight: bold; text-decoration: underline;">tflite</span>::<span style="font-weight: bold; text-decoration: underline;">ArithmeticParams</span> <span style="font-weight: bold; font-style: italic;">op_params</span>;
    op_params.input1_offset = -input1-&gt;params.zero_point;
    op_params.input2_offset = -input2-&gt;params.zero_point;
    op_params.output_offset = output-&gt;params.zero_point;
    op_params.output_multiplier = data-&gt;output_multiplier;
    op_params.output_shift = data-&gt;output_shift;

<span style="font-weight: bold;">#define</span> <span style="font-weight: bold;">TF_LITE_MUL</span>(<span style="font-weight: bold; font-style: italic;">type</span>, <span style="font-weight: bold; font-style: italic;">opname</span>, <span style="font-weight: bold; font-style: italic;">dtype</span>)                                 \
    <span style="font-weight: bold; text-decoration: underline;">type</span>::opname(                                                        \
        op_params, GetTensorShape(input1), GetTensorData&lt;dtype&gt;(input1), \
        GetTensorShape(input2), GetTensorData&lt;dtype&gt;(input2),            \
        GetTensorShape(output), GetTensorData&lt;dtype&gt;(output))

    <span style="font-weight: bold;">if</span> (input1-&gt;type == kTfLiteInt8) {
        TF_LITE_MUL(reference_integer_ops, Mul, int8_t);
    }
}
</pre>
</div>

<ul class="org-ul">
<li>reference kernel 比较低效: 它会针对每个元素计算乘积, 实际上在 x86 上的 mul
optimized kernel 同样使用 Elementwise Mul.</li>

<li><p>
tflite 的 optimized kernel 只对 fully_connected, conv 等使用 来做 gemm
</p>

<p>

</p></li>
</ul>
</div>
</div>

<div id="outline-container-orgbbb32a3" class="outline-4">
<h4 id="orgbbb32a3"><span class="section-number-4">1.1.5</span> Reference Kernel</h4>
<div class="outline-text-4" id="text-1-1-5">
<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold;">template</span> &lt;<span style="font-weight: bold;">typename</span> <span style="font-weight: bold; text-decoration: underline;">T</span>&gt;
<span style="font-weight: bold;">inline</span> <span style="font-weight: bold; text-decoration: underline;">void</span> <span style="font-weight: bold;">MulElementwise</span>(
    <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">size</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">ArithmeticParams</span>&amp; <span style="font-weight: bold; font-style: italic;">params</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">T</span>* <span style="font-weight: bold; font-style: italic;">input1_data</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">T</span>* <span style="font-weight: bold; font-style: italic;">input2_data</span>, <span style="font-weight: bold; text-decoration: underline;">T</span>* <span style="font-weight: bold; font-style: italic;">output_data</span>) {
    <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">i</span> = 0; i &lt; size; ++i) {
        <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Q_a-Z_a</span>
        <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">input1_val</span> = params.input1_offset + input1_data[i];
        <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Q_b-Z_b</span>
        <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">input2_val</span> = params.input2_offset + input2_data[i];
        <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Q_c=Z_c+real_multiplier*((Q_a-Z_a)*(Q_b-Z_b))</span>
        <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">output</span> = params.output_offset +
                             MultiplyByQuantizedMultiplier(
                                 input1_val * input2_val,
                                 params.output_multiplier, params.output_shift);
        output_data[i] = <span style="font-weight: bold;">static_cast</span>&lt;<span style="font-weight: bold; text-decoration: underline;">T</span>&gt;(output);
    }
}
</pre>
</div>

<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold;">inline</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold;">MultiplyByQuantizedMultiplier</span>(
    <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">x</span>, <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">quantized_multiplier</span>, <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">shift</span>) {
    <span style="font-weight: bold;">using</span> <span style="font-weight: bold; text-decoration: underline;">gemmlowp</span>::<span style="font-weight: bold; text-decoration: underline;">RoundingDivideByPOT</span>;
    <span style="font-weight: bold;">using</span> <span style="font-weight: bold; text-decoration: underline;">gemmlowp</span>::<span style="font-weight: bold; text-decoration: underline;">SaturatingRoundingDoublingHighMul</span>;
    <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">right_shift</span> = -shift;
    <span style="font-weight: bold;">return</span> RoundingDivideByPOT(
        SaturatingRoundingDoublingHighMul(x, quantized_multiplier),
        right_shift);
}
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org8e63da7" class="outline-3">
<h3 id="org8e63da7"><span class="section-number-3">1.2</span> FullyConnected Reference Kernel</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org72ad764" class="outline-4">
<h4 id="org72ad764"><span class="section-number-4">1.2.1</span> Quantize</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>

</p>

<p>
针对 FullyConnected 进行 quantize 时, 先强制要求 bias 的 scale == input_scale *
weight_scale, 以便后面 \(Q_w*Q_x+Q_b\) 可以在相同的 scale 下进行计算
</p>

<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold;">if</span> (is_bias_vector) {
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">Quantization of bias vector.</span>
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">We need both of the mandatory inputs (input activations and weights) to</span>
    <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">have been already quantized.</span>
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold;">auto</span>&amp; <span style="font-weight: bold; font-style: italic;">input_activations</span> =
        model-&gt;GetArray(op.inputs[activations_input_index]);
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold;">auto</span>&amp; <span style="font-weight: bold; font-style: italic;">input_weights</span> = model-&gt;GetArray(op.inputs[weights_input_index]);

    <span style="font-weight: bold;">const</span> <span style="font-weight: bold;">auto</span> <span style="font-weight: bold; font-style: italic;">input_activations_scale</span> =
        input_activations.quantization_params-&gt;scale;
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold;">auto</span> <span style="font-weight: bold; font-style: italic;">input_weights_scale</span> = input_weights.quantization_params-&gt;scale;
    quantization_params-&gt;scale = input_activations_scale * input_weights_scale;
    quantization_params-&gt;zero_point = 0;
    *quantized_data_type = GetQuantizedDataType(array, <span style="font-weight: bold; text-decoration: underline;">ArrayDataType</span>::kInt32);
    <span style="font-weight: bold;">return</span> <span style="font-weight: bold; text-decoration: underline;">true</span>;
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org1c145c8" class="outline-4">
<h4 id="org1c145c8"><span class="section-number-4">1.2.2</span> Prepare</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>

Prepare 与 Mul 的 Prepare 基本相同: 它也会提前计算 real_multiplier =
input_multiplier * weight_multiplier, 以及 QuantizeMultiplier. 需要注意的是 bias
的 scale 不需要考虑, 因为 quantize_model 时保证了它与 real_multiplier 是相同的
</p>
</div>
</div>

<div id="outline-container-org9dd12e4" class="outline-4">
<h4 id="org9dd12e4"><span class="section-number-4">1.2.3</span> EvalQuantized</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>

</p>

<p>
EvalQuantized 与 Mul 的 EvalQuantized 也是基本相同
</p>
</div>
</div>

<div id="outline-container-org89b338d" class="outline-4">
<h4 id="org89b338d"><span class="section-number-4">1.2.4</span> Reference Kernel</h4>
<div class="outline-text-4" id="text-1-2-4">
<div class="org-src-container">
<pre class="src src-c++"><span style="font-weight: bold;">inline</span> <span style="font-weight: bold; text-decoration: underline;">void</span> <span style="font-weight: bold;">FullyConnected</span>(
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">FullyConnectedParams</span>&amp; <span style="font-weight: bold; font-style: italic;">params</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">input_shape</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">input_data</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">filter_shape</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">filter_data</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">bias_shape</span>,
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span>* <span style="font-weight: bold; font-style: italic;">bias_data</span>, <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">RuntimeShape</span>&amp; <span style="font-weight: bold; font-style: italic;">output_shape</span>,
    <span style="font-weight: bold; text-decoration: underline;">int8_t</span>* <span style="font-weight: bold; font-style: italic;">output_data</span>) {
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">input_offset</span> = params.input_offset;
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">filter_offset</span> = params.weights_offset;
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">output_offset</span> = params.output_offset;
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">output_multiplier</span> = params.output_multiplier;
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">output_shift</span> = params.output_shift;

    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">filter_dim_count</span> = filter_shape.DimensionsCount();
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">batches</span> = output_shape.Dims(0);
    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">output_depth</span> = output_shape.Dims(1);

    <span style="font-weight: bold;">const</span> <span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">accum_depth</span> = filter_shape.Dims(filter_dim_count - 1);
    <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">b</span> = 0; b &lt; batches; ++b) {
        <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">out_c</span> = 0; out_c &lt; output_depth; ++out_c) {
            <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">acc</span> = 0;
            <span style="font-weight: bold;">for</span> (<span style="font-weight: bold; text-decoration: underline;">int</span> <span style="font-weight: bold; font-style: italic;">d</span> = 0; d &lt; accum_depth; ++d) {
                <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">input_val</span> = input_data[b * accum_depth + d];
                <span style="font-weight: bold; text-decoration: underline;">int32</span> <span style="font-weight: bold; font-style: italic;">filter_val</span> = filter_data[out_c * accum_depth + d];
                acc +=
                    (filter_val + filter_offset) * (input_val + input_offset);
            }
            <span style="font-weight: bold;">if</span> (bias_data) {
                <span style="font-weight: bold; font-style: italic;">// </span><span style="font-weight: bold; font-style: italic;">&#36825;&#37324; bias &#21487;&#20197;&#30452;&#25509;&#30456;&#21152;, &#22240;&#20026; bias &#19982; w*x &#30340; scale &#30456;&#21516;</span>
                acc += bias_data[out_c];
            }
            acc = MultiplyByQuantizedMultiplier(
                acc, output_multiplier, output_shift);
            acc += output_offset;
            output_data[out_c + output_depth * b] = <span style="font-weight: bold;">static_cast</span>&lt;<span style="font-weight: bold; text-decoration: underline;">int8_t</span>&gt;(acc);
        }
    }
}
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-ID-6470583f-2076-4f0e-96e4-aef98fff8a01" class="outline-3">
<h3 id="ID-6470583f-2076-4f0e-96e4-aef98fff8a01"><span class="section-number-3">1.3</span> BatchNorm 导致很大的量化误差</h3>
<div class="outline-text-3" id="text-1-3">
<p>
当训练很多个 epoch 后, 会发现量化误差很大, 通过观察 tflite 量化的数据,发现原因是
batchnorm 对应的 mul 操作的 scale 的最大值很大, 导致很大的量化误差.
</p>

<p>
根据 batchnorm 的公式, scale = gamma / (np.sqrt(var + eps)), 通过 log 可以看到,
随着训练 epoch 的增加, min(var) 和 min(mean) 都变得很小 (例如 1e-3&#x2026;), 导致
scale 变大.
</p>

<p>
var 和 mean 很接近 0, 说明 hidden layer 输出有零， 有两种可能的原因:
</p>

<ol class="org-ol">
<li><p>
hidden layer 中对应的权重接近于零
</p>

<p>
\(\left\{\begin{array}{c}w*x_1+b=0\\w*x_2+b=0\\x_1 \ne x_2\end{array} \implies
   w=0\)
</p></li>

<li>或者 hidden layer 输出因为 relu 变为零 (Gradient Starvation)</li>
</ol>

<p>
解决方法:
</p>

<ol class="org-ol">
<li>减少 batchnorm 前面 layer 的规模, 避免出现接近零的权重</li>
<li>使用 leaky relu 等 relu 变种，避免 relu 导致的神经元死亡的情况.</li>
<li>relu 放在 batchnorm 之后而不是之前</li>
</ol>

<p>
实际上在这个例子中，出现问题的原因是 relu 导致 dense 输出的某些点针对所有样本都
为零, 即有些神经元已经死亡.
</p>

<p>
通过下面的脚本可以观察网络中 batchnorm 的 scale 的情况.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">#</span><span style="font-weight: bold; font-style: italic;">!/usr/bin/env python3</span>
<span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">-*- coding: utf-8 -*-</span>
<span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">2021-08-13 09:58</span>
<span style="font-weight: bold;">import</span> numpy <span style="font-weight: bold;">as</span> np

<span style="font-weight: bold;">from</span> models <span style="font-weight: bold;">import</span> deep_cnn
<span style="font-weight: bold;">import</span> config


<span style="font-weight: bold;">def</span> <span style="font-weight: bold;">check_model</span>(path):
    <span style="font-weight: bold;">print</span>(f<span style="font-style: italic;">"------{path}------"</span>)
    <span style="font-weight: bold; font-style: italic;">model</span> = deep_cnn()
    model.load_weights(path)
    <span style="font-weight: bold; font-style: italic;">bn</span> = [x <span style="font-weight: bold;">for</span> x <span style="font-weight: bold;">in</span> model.layers <span style="font-weight: bold;">if</span> x.name.startswith(<span style="font-style: italic;">"batch"</span>)]
    <span style="font-weight: bold;">for</span> layer <span style="font-weight: bold;">in</span> bn:
        <span style="font-weight: bold;">print</span>(layer.name)
        <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">y=gamma * (x - mean) / sqrt(var+eps) + beta.</span>
        <span style="font-weight: bold; font-style: italic;">gamma</span>, <span style="font-weight: bold; font-style: italic;">beta</span>, <span style="font-weight: bold; font-style: italic;">mean</span>, <span style="font-weight: bold; font-style: italic;">var</span> = layer.get_weights()
        <span style="font-weight: bold; font-style: italic;">eps</span> = 0.001
        <span style="font-weight: bold; font-style: italic;">scale</span> = gamma / (np.sqrt(var + eps))
        <span style="font-weight: bold; font-style: italic;">bias</span> = beta - gamma * mean
        <span style="font-weight: bold;">print</span>(f<span style="font-style: italic;">"---{layer.name}---"</span>)
        <span style="font-weight: bold;">print</span>(np.<span style="font-weight: bold;">min</span>(scale), np.<span style="font-weight: bold;">max</span>(scale))
        <span style="font-weight: bold;">print</span>(np.<span style="font-weight: bold;">min</span>(bias), np.<span style="font-weight: bold;">max</span>(bias))

        <span style="font-weight: bold; font-style: italic;">index</span> = np.argmax(scale)
        <span style="font-weight: bold;">print</span>(index, gamma[index], var[index], mean[index])


check_model(config.SAVED_MODEL_PATH)
</pre>
</div>
</div>


<div id="outline-container-orgbfea5c9" class="outline-4 references">
<h4 id="orgbfea5c9">Backlinks</h4>
<div class="outline-text-4" id="text-orgbfea5c9">
<p>
<a href="../machine_learning/batchnorm.html#ID-ffa885c6-f5a3-4939-8e61-4ebd2bbbe836">Batch Normalization</a>
(<i>Batch Normalization &gt; batchnorm-&gt;relu vs. relu-&gt;batchnorm &gt; batchnorm-&gt;relu 的优点</i>):  另一方面, relu 放在 batchnorm 之前可能会出来 <a href="#ID-6470583f-2076-4f0e-96e4-aef98fff8a01">BatchNorm 导致很大的量化误差</a> 的问题
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2021-07-21 Wed 00:00<br />
Last updated: 2022-01-25 Tue 21:28</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
