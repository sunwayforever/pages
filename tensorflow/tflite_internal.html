<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>Tensorflow Lite Internal</title>

<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Tensorflow Lite Internal</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0000067">1. TFLite Internal</a>
<ul>
<li><a href="#org0000027">1.1. Overview</a>
<ul>
<li><a href="#org0000000">1.1.1. BuiltinOpResolver</a></li>
<li><a href="#org0000009">1.1.2. InterpreterBuilder</a></li>
<li><a href="#org0000021">1.1.3. AllocateTensors</a></li>
<li><a href="#org0000024">1.1.4. Interpreter.Invoke</a></li>
</ul>
</li>
<li><a href="#org000005e">1.2. TFLite Delegate</a>
<ul>
<li><a href="#org000002a">1.2.1. A Simple Model</a></li>
<li><a href="#org000002d">1.2.2. MyDelegate</a></li>
<li><a href="#org0000030">1.2.3. ModifyGraphWithDelegate</a></li>
<li><a href="#org0000034">1.2.4. ReplaceNodeSubsetsWithDelegateKernels</a></li>
<li><a href="#org0000037">1.2.5. PartitionGraphIntoIndependentNodeSubsets</a></li>
<li><a href="#org000003d">1.2.6. Delegate 与 Custom Op 的区别</a></li>
<li><a href="#org000005c">1.2.7. Flex Delegate</a></li>
</ul>
</li>
<li><a href="#org0000061">1.3. TFLite Format</a></li>
<li><a href="#org0000064">1.4. TFLite Quantization Details</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000067" class="outline-2">
<h2 id="org0000067"><span class="section-number-2">1</span> TFLite Internal</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org0000027" class="outline-3">
<h3 id="org0000027"><span class="section-number-3">1.1</span> Overview</h3>
<div class="outline-text-3" id="text-1-1">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">int</span> <span class="org-function-name">main</span>(<span class="org-type">int</span> <span class="org-variable-name">argc</span>, <span class="org-type">char</span>* <span class="org-variable-name">argv</span>[]) {
    <span class="org-keyword">if</span> (argc != 2) {
        fprintf(stderr, <span class="org-string">"square &lt;tflite model&gt;\n"</span>);
        <span class="org-keyword">return</span> 1;
    }
    <span class="org-keyword">const</span> <span class="org-type">char</span>* <span class="org-variable-name">filename</span> = argv[1];

    <span class="org-constant">std</span>::<span class="org-type">unique_ptr</span>&lt;<span class="org-constant">tflite</span>::FlatBufferModel&gt; <span class="org-variable-name">model</span> =
            <span class="org-constant">tflite</span>::<span class="org-constant">FlatBufferModel</span>::BuildFromFile(filename);

    <span class="org-constant">tflite</span>::<span class="org-constant">ops</span>::<span class="org-constant">builtin</span>::<span class="org-type">BuiltinOpResolver</span> <span class="org-variable-name">resolver</span>;
    <span class="org-type">InterpreterBuilder</span> <span class="org-variable-name">builder</span>(*model, resolver);
    <span class="org-constant">std</span>::<span class="org-type">unique_ptr</span>&lt;Interpreter&gt; <span class="org-variable-name">interpreter</span>;
    builder(&amp;interpreter);

    interpreter-&gt;AllocateTensors();
    <span class="org-type">float</span>* <span class="org-variable-name">input</span> = interpreter-&gt;typed_input_tensor&lt;<span class="org-type">float</span>&gt;(0);
    input[0] = 10;
    interpreter-&gt;Invoke();
    <span class="org-type">float</span>* <span class="org-variable-name">output</span> = interpreter-&gt;typed_output_tensor&lt;<span class="org-type">float</span>&gt;(0);
    printf(<span class="org-string">"%f\n"</span>, output[0]);

    <span class="org-keyword">return</span> 0;
}
</pre>
</div>
</div>

<div id="outline-container-org0000000" class="outline-4">
<h4 id="org0000000"><span class="section-number-4">1.1.1</span> BuiltinOpResolver</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
注册各个 op 对应的 Invoke 函数, 例如 abs 最终会对应 AbsEval, 后者最终会调用 std::abs
</p>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-constant">BuiltinOpResolver</span>::<span class="org-function-name">BuiltinOpResolver</span>() {
    AddBuiltin(BuiltinOperator_ABS, Register_ABS());
    AddBuiltin(BuiltinOperator_RELU, Register_RELU(), 1, 2);
    <span class="org-comment-delimiter">// </span><span class="org-comment">...</span>
    AddBuiltin(BuiltinOperator_MAX_POOL_2D, Register_MAX_POOL_2D(), 1, 3);
    AddBuiltin(BuiltinOperator_L2_POOL_2D, Register_L2_POOL_2D());
    AddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D(), 1, 5);
    <span class="org-comment-delimiter">// </span><span class="org-comment">....</span>
    AddBuiltin(BuiltinOperator_FULLY_CONNECTED, Register_FULLY_CONNECTED(), 1,
               9);
    <span class="org-comment-delimiter">// </span><span class="org-comment">...</span>
}

<span class="org-type">void</span> <span class="org-constant">MutableOpResolver</span>::<span class="org-function-name">AddBuiltin</span>(<span class="org-constant">tflite</span>::<span class="org-type">BuiltinOperator</span> <span class="org-variable-name">op</span>,
                                   <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span>,
                                   <span class="org-type">int</span> <span class="org-variable-name">version</span>) {
    <span class="org-type">TfLiteRegistration</span> <span class="org-variable-name">new_registration</span> = *registration;
    new_registration.custom_name = <span class="org-constant">nullptr</span>;
    new_registration.builtin_code = op;
    new_registration.version = version;
    <span class="org-keyword">auto</span> <span class="org-variable-name">op_key</span> = <span class="org-constant">std</span>::make_pair(op, version);
    builtins_[op_key] = new_registration;
}

<span class="org-type">TfLiteRegistration</span>* <span class="org-function-name">Register_ABS</span>() {
    <span class="org-keyword">static</span> <span class="org-type">TfLiteRegistration</span> <span class="org-variable-name">r</span> = {
        <span class="org-comment-delimiter">// </span><span class="org-comment">init</span>
        <span class="org-constant">nullptr</span>,
        <span class="org-comment-delimiter">// </span><span class="org-comment">free</span>
        <span class="org-constant">nullptr</span>,
        <span class="org-comment-delimiter">// </span><span class="org-comment">prepare</span>
        <span class="org-constant">elementwise</span>::<span class="org-type">GenericPrepare</span>&lt;<span class="org-constant">elementwise</span>::IsNumericSupportedType,
                                    <span class="org-constant">elementwise</span>::kAbsName&gt;,
        <span class="org-comment-delimiter">// </span><span class="org-comment">invoke</span>
        <span class="org-constant">elementwise</span>::AbsEval};
    <span class="org-keyword">return</span> &amp;r;
}

<span class="org-type">TfLiteStatus</span> <span class="org-function-name">AbsEval</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>) {
    <span class="org-keyword">return</span> EvalNumeric(context, node, <span class="org-constant">std</span>::abs);
}

<span class="org-keyword">inline</span> <span class="org-type">TfLiteStatus</span> <span class="org-function-name">EvalNumeric</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>,
                                <span class="org-type">float</span> <span class="org-function-name">float_func</span>(<span class="org-type">float</span>)) {
    <span class="org-keyword">return</span> EvalImpl&lt;<span class="org-type">float</span>&gt;(context, node, float_func, kTfLiteFloat32);
}

<span class="org-keyword">template</span> &lt;<span class="org-keyword">typename</span> <span class="org-type">T</span>&gt;
<span class="org-keyword">inline</span> <span class="org-type">TfLiteStatus</span> <span class="org-function-name">EvalImpl</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>,
                             <span class="org-type">T</span> <span class="org-function-name">func</span>(<span class="org-type">T</span>), <span class="org-type">TfLiteType</span> <span class="org-variable-name">expected_type</span>) {
    <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">input</span> = GetInput(context, node, 0);
    <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">output</span> = GetOutput(context, node, 0);
    TF_LITE_ENSURE_TYPES_EQ(context, input-&gt;type, expected_type);
    <span class="org-keyword">const</span> <span class="org-type">int64_t</span> <span class="org-variable-name">num_elements</span> = NumElements(input);
    <span class="org-keyword">const</span> <span class="org-type">T</span>* <span class="org-variable-name">in_data</span> = GetTensorData&lt;<span class="org-type">T</span>&gt;(input);
    <span class="org-type">T</span>* <span class="org-variable-name">out_data</span> = GetTensorData&lt;<span class="org-type">T</span>&gt;(output);
    <span class="org-keyword">for</span> (<span class="org-type">int64_t</span> <span class="org-variable-name">i</span> = 0; i &lt; num_elements; ++i) {
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! out_data[i] = std::abs(in_data[i])</span>
        out_data[i] = func(in_data[i]);
    }
    <span class="org-keyword">return</span> kTfLiteOk;
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000009" class="outline-4">
<h4 id="org0000009"><span class="section-number-4">1.1.2</span> InterpreterBuilder</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
生成 interpreter, 主要是根据 model 中的 operator 及 resolver 中的 registration
生成 graph 及其中的 node 以便执行. 另外会用 delegate 把 graph 分割为不同的
subgraph 以分别执行.
</p>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">InterpreterBuilder</span>::<span class="org-keyword">operator</span><span class="org-function-name">()</span>(
    <span class="org-constant">std</span>::<span class="org-type">unique_ptr</span>&lt;Interpreter&gt;* <span class="org-variable-name">interpreter</span>, <span class="org-type">int</span> <span class="org-variable-name">num_threads</span>) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#26597;&#25214; resolver &#20013;&#35760;&#24405;&#30340; registration</span>
    BuildLocalIndexToRegistrationMapping();

    <span class="org-keyword">auto</span>* <span class="org-variable-name">subgraphs</span> = model_-&gt;subgraphs();
    <span class="org-keyword">auto</span>* <span class="org-variable-name">buffers</span> = model_-&gt;buffers();

    <span class="org-keyword">if</span> (subgraphs-&gt;size() &gt; 1) {
        (*interpreter)-&gt;AddSubgraphs(subgraphs-&gt;size() - 1);
    }

    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">subgraph_index</span> = 0; subgraph_index &lt; subgraphs-&gt;size();
         ++subgraph_index) {
        <span class="org-keyword">const</span> <span class="org-constant">tflite</span>::<span class="org-type">SubGraph</span>* <span class="org-variable-name">subgraph</span> = (*subgraphs)[subgraph_index];
        <span class="org-constant">tflite</span>::<span class="org-type">Subgraph</span>* <span class="org-variable-name">modified_subgraph</span> =
            (*interpreter)-&gt;subgraph(subgraph_index);
        <span class="org-keyword">auto</span> <span class="org-variable-name">operators</span> = subgraph-&gt;operators();
        <span class="org-keyword">auto</span> <span class="org-variable-name">tensors</span> = subgraph-&gt;tensors();

        modified_subgraph-&gt;AddTensors(tensors-&gt;size());

        modified_subgraph-&gt;SetInputs(
            FlatBufferIntArrayToVector(subgraph-&gt;inputs()));
        modified_subgraph-&gt;SetOutputs(
            FlatBufferIntArrayToVector(subgraph-&gt;outputs()));

        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#26681;&#25454; operator &#29983;&#25104; node &#21450; execution_plan</span>
        ParseNodes(operators, modified_subgraph);
        ParseTensors(buffers, tensors, modified_subgraph);

        <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt; <span class="org-variable-name">variables</span>;
        <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">i</span> = 0; i &lt; modified_subgraph-&gt;tensors_size(); ++i) {
            <span class="org-keyword">auto</span>* <span class="org-variable-name">tensor</span> = modified_subgraph-&gt;tensor(i);
            <span class="org-keyword">if</span> (tensor-&gt;is_variable) {
                variables.push_back(i);
            }
        }
        modified_subgraph-&gt;SetVariables(<span class="org-constant">std</span>::move(variables));
    }

    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#26159;&#21542;&#20351;&#29992; flex delegate &#25903;&#25345; tensorflow op (&#32780;&#19981;&#26159; tflite builtin op)</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">https://www.tensorflow.org/lite/guide/ops_select?hl=zh-cn</span>
    ApplyDelegates(interpreter-&gt;get(), num_threads)
}
</pre>
</div>
</div>

<div id="outline-container-org0000003" class="outline-5">
<h5 id="org0000003"><span class="section-number-5">1.1.2.1</span> BuildLocalIndexToRegistrationMapping</h5>
<div class="outline-text-5" id="text-1-1-2-1">
<p>
查找之前 BuiltinOpResolver 注册的 registration
</p>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">InterpreterBuilder</span>::<span class="org-function-name">BuildLocalIndexToRegistrationMapping</span>() {
    unresolved_custom_ops_.clear();

    <span class="org-keyword">auto</span> <span class="org-variable-name">opcodes</span> = model_-&gt;operator_codes();

    <span class="org-type">int</span> <span class="org-variable-name">num_custom_ops</span> = 0;

    <span class="org-comment-delimiter">// </span><span class="org-comment">builtin_code &#38500;&#20102;&#27491;&#24120;&#30340;&#22914; BuiltinOperator_ABS &#20043;&#31867;&#30340;, &#36824;&#21253;&#21547;&#20004;&#31181;&#29305;&#27530;&#30340;&#20540;:</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">BuiltinOperator\_CUSTOM</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">BuiltinOperator\_DELEGATE</span>
    <span class="org-comment-delimiter">//</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#20854;&#20013;&#23545;&#20110; BuiltinOperator_CUSTOM, OperatorCode.custom_code (&#19968;&#20010; string)</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#29992;&#26469;&#21306;&#21035;&#36825;&#20010; custom op &#20855;&#20307;&#26159;&#20160;&#20040;.</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#23545;&#20110; custom op, BuiltinOpResolver &#21487;&#20197;&#36890;&#36807; AddCustom &#28155;&#21152;&#23545;&#23427;&#30340;&#25903;&#25345;,</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#25110;&#32773; delegate &#20063;&#21487;&#20197;&#25903;&#25345;&#23427;, &#20294; delegate &#30340;&#25903;&#25345;&#24182;&#19981;&#20250;&#22312; resolver &#20013;&#20307;&#29616;,</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#25152;&#20197;&#19979;&#38754;&#30340;&#20195;&#30721;&#20250;&#26377; unresolved_custom_ops_</span>

    <span class="org-keyword">for</span> (<span class="org-keyword">const</span> <span class="org-type">OperatorCode</span>* <span class="org-variable-name">opcode</span> : *opcodes) {
        <span class="org-keyword">if</span> (opcode-&gt;builtin_code() == BuiltinOperator_CUSTOM) {
            num_custom_ops++;
        }
    }
    unresolved_custom_ops_.reserve(num_custom_ops);
    <span class="org-keyword">for</span> (<span class="org-keyword">const</span> <span class="org-type">OperatorCode</span>* <span class="org-variable-name">opcode</span> : *opcodes) {
        <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span> = <span class="org-constant">nullptr</span>;
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#26597;&#25214; builtin_code &#21644; custom_code</span>
        status = GetRegistrationFromOpCode(opcode, op_resolver_, error_reporter_,
                                           &amp;registration);
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! op &#22312; resolver &#20013;&#25214;&#19981;&#21040; registration, &#20132;&#32473; delegate</span>
        <span class="org-keyword">if</span> (status != kTfLiteOk) {
            <span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">op_name</span> = opcode-&gt;custom_code()-&gt;c_str();
            unresolved_custom_ops_.push_back(CreateUnresolvedCustomOp(op_name));
            registration = &amp;unresolved_custom_ops_.back();
            has_flex_op_ |= IsFlexOp(op_name);
            status = kTfLiteOk;
        }
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! registration &#25353;&#39034;&#24207;&#35760;&#24405;&#19979;&#26469;</span>
        flatbuffer_op_index_to_registration_.push_back(registration);
    }
    <span class="org-keyword">return</span> status;
}

<span class="org-constant">GetRegistrationFromOpCode</span>:
    *registration = op_resolver.FindOp(builtin_code, version);
        <span class="org-keyword">return</span> builtins_.find(<span class="org-constant">std</span>::make_pair(op, version));
    <span class="org-keyword">if</span> (not_found_in_builtins):
        <span class="org-keyword">const</span> <span class="org-type">char</span>* <span class="org-variable-name">name</span> = opcode-&gt;custom_code()-&gt;c_str();
        *registration = op_resolver.FindOp(name, version);
        <span class="org-keyword">return</span> custom_ops_.find(<span class="org-constant">std</span>::make_pair(op, version));
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000006" class="outline-5">
<h5 id="org0000006"><span class="section-number-5">1.1.2.2</span> ParseNode</h5>
<div class="outline-text-5" id="text-1-1-2-2">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">InterpreterBuilder</span>::<span class="org-function-name">ParseNodes</span>(
    <span class="org-keyword">const</span> <span class="org-constant">flatbuffers</span>::<span class="org-type">Vector</span>&lt;<span class="org-constant">flatbuffers</span>::<span class="org-type">Offset</span>&lt;Operator&gt;&gt;* <span class="org-variable-name">operators</span>,
    <span class="org-type">Subgraph</span>* <span class="org-variable-name">subgraph</span>) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">Reduce the number of redundant allocations</span>
    subgraph-&gt;ReserveNodes(operators-&gt;size());

    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">i</span> = 0; i &lt; operators-&gt;size(); ++i) {
        <span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">op</span> = operators-&gt;Get(i);
        <span class="org-type">int</span> <span class="org-variable-name">index</span> = op-&gt;opcode_index();

        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#25214;&#21040; registration</span>
        <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span> =
            flatbuffer_op_index_to_registration_[index];

        <span class="org-type">BuiltinOperator</span> <span class="org-variable-name">op_type</span> =
            <span class="org-keyword">static_cast</span>&lt;<span class="org-type">BuiltinOperator</span>&gt;(registration-&gt;builtin_code);

        <span class="org-keyword">if</span> (op_type == BuiltinOperator_CUSTOM) {
            subgraph-&gt;AddNodeWithParameters(
                FlatBufferIntArrayToVector(op-&gt;inputs()),
                FlatBufferIntArrayToVector(op-&gt;outputs()),
                FlatBufferIntArrayToVector(op-&gt;intermediates()), <span class="org-constant">nullptr</span>, 0,
                <span class="org-constant">nullptr</span>, registration);

        } <span class="org-keyword">else</span> {
            <span class="org-type">void</span>* <span class="org-variable-name">builtin_data</span> = <span class="org-constant">nullptr</span>;
            <span class="org-type">MallocDataAllocator</span> <span class="org-variable-name">malloc_allocator</span>;
            TF_LITE_ENSURE_STATUS(ParseOpData(op, op_type, error_reporter_,
                                              &amp;malloc_allocator,
                                              &amp;builtin_data));
            subgraph-&gt;AddNodeWithParameters(
                FlatBufferIntArrayToVector(op-&gt;inputs()),
                FlatBufferIntArrayToVector(op-&gt;outputs()),
                FlatBufferIntArrayToVector(op-&gt;intermediates()), <span class="org-constant">nullptr</span>, 0,
                builtin_data, registration);
        }
    }

    <span class="org-keyword">return</span> status;
}

<span class="org-type">TfLiteStatus</span> <span class="org-constant">Subgraph</span>::<span class="org-function-name">AddNodeWithParameters</span>(
    <span class="org-keyword">const</span> <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt;&amp; <span class="org-variable-name">inputs</span>, <span class="org-keyword">const</span> <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt;&amp; <span class="org-variable-name">outputs</span>,
    <span class="org-keyword">const</span> <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt;&amp; <span class="org-variable-name">intermediates</span>, <span class="org-keyword">const</span> <span class="org-type">char</span>* <span class="org-variable-name">init_data</span>,
    <span class="org-type">size_t</span> <span class="org-variable-name">init_data_size</span>, <span class="org-type">void</span>* <span class="org-variable-name">builtin_data</span>,
    <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span>, <span class="org-type">int</span>* <span class="org-variable-name">node_index</span>) {
    <span class="org-constant">std</span>::<span class="org-type">unique_ptr</span>&lt;<span class="org-type">void</span>, <span class="org-keyword">decltype</span>(free)*&gt; <span class="org-variable-name">builtin_data_deleter</span>(builtin_data,
                                                                free);

    <span class="org-type">int</span> <span class="org-variable-name">new_node_index</span> = nodes_and_registration_.size();
    <span class="org-keyword">if</span> (node_index) *node_index = new_node_index;
    nodes_and_registration_.resize(nodes_and_registration_.size() + 1);
    <span class="org-keyword">auto</span>&amp; <span class="org-variable-name">node_and_reg</span> = nodes_and_registration_.back();
    <span class="org-type">TfLiteNode</span>&amp; <span class="org-variable-name">node</span> = node_and_reg.first;
    <span class="org-keyword">if</span> (node.inputs) TfLiteIntArrayFree(node.inputs);
    <span class="org-keyword">if</span> (node.outputs) TfLiteIntArrayFree(node.outputs);
    <span class="org-keyword">if</span> (node.intermediates) TfLiteIntArrayFree(node.intermediates);
    <span class="org-keyword">if</span> (node.temporaries) TfLiteIntArrayFree(node.temporaries);

    node.inputs = ConvertVectorToTfLiteIntArray(inputs);
    node.outputs = ConvertVectorToTfLiteIntArray(outputs);
    node.intermediates = ConvertVectorToTfLiteIntArray(intermediates);
    node.temporaries = TfLiteIntArrayCreate(0);
    <span class="org-keyword">if</span> (init_data) {
        node.user_data = OpInit(*registration, init_data, init_data_size);
    } <span class="org-keyword">else</span> {
        node.user_data = OpInit(
            *registration, <span class="org-keyword">static_cast</span>&lt;<span class="org-keyword">const</span> <span class="org-type">char</span>*&gt;(builtin_data_deleter.get()), 0);
    }

    node.builtin_data = builtin_data_deleter.release();

    <span class="org-keyword">if</span> (registration-&gt;builtin_code == BuiltinOperator_CUSTOM) {
        <span class="org-comment-delimiter">// </span><span class="org-comment">When it's a CUSTOM op, the `custom_options` field in the Flatbuffer</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">`Operator` table is passed in.</span>
        node.custom_initial_data = init_data;
        node.custom_initial_data_size = init_data_size;
    } <span class="org-keyword">else</span> {
        node.custom_initial_data = <span class="org-constant">nullptr</span>;
        node.custom_initial_data_size = 0;
    }

    node.delegate = <span class="org-constant">nullptr</span>;
    <span class="org-comment-delimiter">// </span><span class="org-comment">Copying of registration is required to support unresolved custom ops.</span>
    node_and_reg.second = *registration;
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! execution_plan_ &#34920;&#31034; subgraph invoke &#26102;&#21508;&#20010; node (operator) &#25191;&#34892;&#30340;&#39034;</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#24207;, &#23454;&#38469;&#19978; tflite &#27169;&#22411;&#20013;&#30340; operator &#24050;&#32463;&#26159;&#25299;&#25169;&#25490;&#24207;&#30340;&#20102;, &#25152;&#20197;</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">execution_plan_ &#22522;&#26412;&#19978;&#21644; operator &#39034;&#24207;&#30456;&#21516;, &#38500;&#38750;&#28041;&#21450;&#21040; delegate</span>
    execution_plan_.push_back(new_node_index);
    <span class="org-keyword">return</span> kTfLiteOk;
}
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org0000021" class="outline-4">
<h4 id="org0000021"><span class="section-number-4">1.1.3</span> AllocateTensors</h4>
<div class="outline-text-4" id="text-1-1-3">
</div>
<div id="outline-container-org000000c" class="outline-5">
<h5 id="org000000c"><span class="section-number-5">1.1.3.1</span> constant allocation</h5>
<div class="outline-text-5" id="text-1-1-3-1">
<p>
constant 直接把 flatbuffer mmap 进来使用
</p>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">InterpreterBuilder</span>::<span class="org-function-name">ParseTensors</span>(
    <span class="org-keyword">const</span> <span class="org-constant">flatbuffers</span>::<span class="org-type">Vector</span>&lt;<span class="org-constant">flatbuffers</span>::<span class="org-type">Offset</span>&lt;Buffer&gt;&gt;* <span class="org-variable-name">buffers</span>,
    <span class="org-keyword">const</span> <span class="org-constant">flatbuffers</span>::<span class="org-type">Vector</span>&lt;<span class="org-constant">flatbuffers</span>::<span class="org-type">Offset</span>&lt;Tensor&gt;&gt;* <span class="org-variable-name">tensors</span>,
    <span class="org-type">Subgraph</span>* <span class="org-variable-name">subgraph</span>) {

    <span class="org-keyword">auto</span> <span class="org-variable-name">get_readonly_data</span> = [&amp;](<span class="org-keyword">const</span> <span class="org-type">char</span>** <span class="org-variable-name">buffer_data</span>,
                                 <span class="org-type">size_t</span>* <span class="org-variable-name">buffer_size</span>) {
        *buffer_data = <span class="org-constant">nullptr</span>;
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#22914;&#26524;&#26159; constant tensor, &#21017; tensor-&gt;buffer() &#25351;&#21521; floatbuffer &#20013;</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">constant tensor &#30340;&#25968;&#25454;, &#36825;&#20010;&#25968;&#25454;&#26159;&#30452;&#25509;&#36890;&#36807; mmap &#26144;&#23556;&#36827;&#26469; (flatbuffer</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">&#30456;&#27604; protocalbuffer &#30340;&#20248;&#21183;)</span>
        <span class="org-keyword">if</span> (tensor-&gt;buffer() == 0) <span class="org-keyword">return</span> kTfLiteOk;
        <span class="org-keyword">if</span> (<span class="org-keyword">auto</span>* <span class="org-variable-name">buffer</span> = (*buffers)[tensor-&gt;buffer()]) {
            <span class="org-keyword">if</span> (<span class="org-keyword">auto</span>* <span class="org-variable-name">array</span> = buffer-&gt;data()) {
                <span class="org-keyword">if</span> (<span class="org-type">size_t</span> <span class="org-variable-name">size</span> = array-&gt;size()) {
                    *buffer_size = size;
                    *buffer_data = <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-keyword">const</span> <span class="org-type">char</span>*&gt;(array-&gt;data());
                    <span class="org-keyword">return</span> kTfLiteOk;
                }
            }
        }
        <span class="org-keyword">return</span> kTfLiteOk;
    };

    get_readonly_data(&amp;buffer_ptr, &amp;buffer_size);

    <span class="org-keyword">if</span> (buffer_ptr) {
        subgraph-&gt;SetTensorParametersReadOnly(
            i, type, get_name(tensor), dims, quantization, buffer_ptr,
            buffer_size, allocation_, sparsity);

            tensor.data.raw = <span class="org-keyword">const_cast</span>&lt;<span class="org-type">char</span>*&gt;(buffer);
    } <span class="org-keyword">else</span> {
        subgraph-&gt;SetTensorParametersReadWrite(
            i, type, get_name(tensor), dims, quantization, is_variable,
            dims_signature_rank, dims_signature_data);
            <span class="org-comment-delimiter">// </span><span class="org-comment">!!! kTfLiteArenaRw &#19982; kTfLiteArenaRwPersistent</span>
            <span class="org-comment-delimiter">// </span><span class="org-comment">&#26368;&#32456;&#20250;&#20998;&#37197;&#21040;&#19981;&#21516;&#30340; buffer</span>
            <span class="org-type">TfLiteAllocationType</span> <span class="org-variable-name">allocation_type</span> = kTfLiteArenaRw;
            <span class="org-keyword">if</span> (is_variable) {
                allocation_type = kTfLiteArenaRwPersistent;
            }
            tensor.data.raw = 0;
            tensor.allocation_type = allocation_type;
            tensor.bytes = required_bytes;
            <span class="org-comment-delimiter">// </span><span class="org-comment">...</span>
    }
</pre>
</div>
</div>
</div>

<div id="outline-container-org000001e" class="outline-5">
<h5 id="org000001e"><span class="section-number-5">1.1.3.2</span> tensor allocation</h5>
<div class="outline-text-5" id="text-1-1-3-2">
<p>
tensor, 包括:
</p>

<ol class="org-ol">
<li>variable (可训练的参数) tensor</li>
<li>intermediate tensor</li>
<li>temporary tensor</li>
</ol>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">Subgraph</span>::<span class="org-function-name">AllocateTensors</span>(){PrepareOpsAndTensors()}

<span class="org-function-name">PrepareOpsAndTensors</span>() {
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! preserve_inputs &#40664;&#35748;&#20026; true, &#25152;&#20197;&#22810;&#27425;&#36816;&#34892;&#26102;&#19981;&#38656;&#35201;&#37325;&#22797;&#32473; input tensor</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#36171;&#20540;</span>
    <span class="org-comment-delimiter">//</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">preserve_intermediates &#20026; false, &#25152;&#20197;&#26080;&#27861;&#26597;&#35810;&#20013;&#38388;&#32467;&#26524;</span>
    memory_planner_.reset(<span class="org-keyword">new</span> <span class="org-type">ArenaPlanner</span>(
        &amp;context_, <span class="org-constant">std</span>::unique_ptr&lt;GraphInfo&gt;(<span class="org-keyword">new</span> <span class="org-type">InterpreterInfo</span>(<span class="org-keyword">this</span>)),
        <span class="org-comment-delimiter">/*</span><span class="org-comment">preserve_inputs=</span><span class="org-comment-delimiter">*/</span><span class="org-constant">true</span>, <span class="org-comment-delimiter">/*</span><span class="org-comment">preserve_intermediates</span><span class="org-comment-delimiter">*/</span> <span class="org-constant">false</span>,
        kDefaultTensorAlignment));
    memory_planner_-&gt;PlanAllocations();
    memory_planner_-&gt;ExecuteAllocations(
        next_execution_plan_index_to_plan_allocation_,
        last_exec_plan_index_prepared));
}
</pre>
</div>
</div>

<div id="outline-container-org000000f" class="outline-6">
<h6 id="org000000f"><span class="section-number-6">1.1.3.2.1</span> PlanAllocations</h6>
<div class="outline-text-6" id="text-1-1-3-2-1">
<ol class="org-ol">
<li>标记只些 tensor 不能被覆盖 (通过 refcount)</li>
<li>记录 tensor 的 start_node 和 finish_node, 即 tensor 的生命期, 生命期不重叠的
tensor 可以共用内存</li>
</ol>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">ArenaPlanner</span>::<span class="org-function-name">PlanAllocations</span>() {
    alloc_node_.assign(graph_info_-&gt;num_tensors(), kNodeNotAssigned);
    dealloc_node_.assign(graph_info_-&gt;num_tensors(), kNodeNotAssigned);

    <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt; <span class="org-variable-name">refcounts</span>(graph_info_-&gt;num_tensors(), 0);

    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! alloc_node_ &#21644; dealloc_node_ &#29992;&#26469;&#35760;&#24405; tensor &#30340; start_node &#21644;</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">finish_node</span>
    <span class="org-keyword">auto</span> <span class="org-variable-name">allocate</span> = [<span class="org-keyword">this</span>](<span class="org-type">int</span> <span class="org-variable-name">node</span>, <span class="org-type">int</span> <span class="org-variable-name">tensor</span>) -&gt; TfLiteStatus {
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! alloc_nodes_ &#38656;&#35201;&#35760;&#24405;`&#31532;&#19968;&#20010;`&#20351;&#29992;&#36825;&#20010; tensor &#30340; node, &#25152;&#20197;&#38656;&#35201;&#36825;</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">&#20010;&#21028;&#26029;</span>
        <span class="org-keyword">if</span> (alloc_node_[tensor] != kNodeNotAssigned) {
            <span class="org-comment-delimiter">// </span><span class="org-comment">!!! Tensor has already been allocated.</span>
            <span class="org-keyword">return</span> kTfLiteOk;
        }
        alloc_node_[tensor] = node;
    };

    <span class="org-keyword">auto</span> <span class="org-variable-name">deallocate</span> = [<span class="org-keyword">this</span>](<span class="org-type">int</span> <span class="org-variable-name">node</span>, <span class="org-type">int</span> <span class="org-variable-name">tensor</span>) -&gt; TfLiteStatus {
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! dealloc_node_ &#38656;&#35201;&#35760;&#24405;`&#26368;&#21518;&#19968;&#20010;`&#20351;&#29992;&#36825;&#20010; tensor &#30340; node, &#25152;&#20197;&#19981;&#38656;</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">&#35201;&#20687; alloc_node_ &#37027;&#26679;&#21028;&#26029;</span>
        dealloc_node_[tensor] = node;
    };
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! -----------------------------</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! We must make sure the output tensors are never overwritten. We do</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">that by artificially adding one to their ref-counts so they are never</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">selected for deallocation.</span>
    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> : graph_info_-&gt;outputs()) {
        refcounts[tensor_index]++;
    }

    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! Variable tensors also should be ensured to be never overwritten and</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">need to be alive all the time.</span>
    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> : graph_info_-&gt;variables()) {
        refcounts[tensor_index]++;
    }

    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! Queue all graph inputs for allocation. If preserve_inputs_ is true,</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">make sure they never be overwritten.</span>
    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> : graph_info_-&gt;inputs()) {
        <span class="org-keyword">if</span> (preserve_inputs_) {
            refcounts[tensor_index]++;
        }
        <span class="org-comment-delimiter">// </span><span class="org-comment">graph inputs &#30340; start_node &#24517;&#28982;&#26159; node[0]</span>
        allocate(0, tensor_index);
    }

    <span class="org-comment-delimiter">// </span><span class="org-comment">Queue all graph variable tensors for allocation.</span>
    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> : graph_info_-&gt;variables()) {
        <span class="org-comment-delimiter">// </span><span class="org-comment">Increase the reference count for input tensors by one, so it will</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">never be deallocated.</span>
        allocate(0, tensor_index);
    }

    <span class="org-comment-delimiter">// </span><span class="org-comment">Queue all graph inputs for allocation.</span>
    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> : graph_info_-&gt;inputs()) {
        <span class="org-keyword">if</span> (tensor_index != kTfLiteOptionalTensor) {
            allocate(0, tensor_index);
        }
    }
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! -----------------------------</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">Count references to node input tensors.</span>
    <span class="org-keyword">for</span> (<span class="org-type">size_t</span> <span class="org-variable-name">i</span> = 0; i &lt; graph_info_-&gt;num_nodes(); ++i) {
        <span class="org-keyword">const</span> <span class="org-type">TfLiteNode</span>&amp; <span class="org-variable-name">node</span> = graph_info_-&gt;node(i);
        <span class="org-type">TfLiteIntArray</span>* <span class="org-variable-name">node_inputs</span> = node.inputs;
        <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">j</span> = 0; j &lt; node_inputs-&gt;size; ++j) {
            <span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> = node_inputs-&gt;data[j];
            refcounts[tensor_index]++;
        }
    }
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! -----------------------------</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">Go through the graph in execution order.</span>
    <span class="org-keyword">for</span> (<span class="org-type">size_t</span> <span class="org-variable-name">i</span> = 0; i &lt; graph_info_-&gt;num_nodes(); ++i) {
        <span class="org-keyword">const</span> <span class="org-type">TfLiteNode</span>&amp; <span class="org-variable-name">node</span> = graph_info_-&gt;node(i);

        <span class="org-comment-delimiter">// </span><span class="org-comment">First queue output tensors for allocation.</span>
        <span class="org-type">TfLiteIntArray</span>* <span class="org-variable-name">node_outputs</span> = node.outputs;
        <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">j</span> = 0; j &lt; node_outputs-&gt;size; ++j) {
            <span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> = node_outputs-&gt;data[j];
            allocate(i, tensor_index);
        }

        <span class="org-comment-delimiter">// </span><span class="org-comment">Then update the ref-counts of the node's inputs, and if necessary</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">queue them for deallocation.</span>
        <span class="org-keyword">if</span> (<span class="org-negation-char">!</span>preserve_intermediates_) {
            <span class="org-type">TfLiteIntArray</span>* <span class="org-variable-name">node_inputs</span> = node.inputs;
            <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">j</span> = 0; j &lt; node_inputs-&gt;size; ++j) {
                <span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> = node_inputs-&gt;data[j];
                refcounts[tensor_index]--;
                <span class="org-keyword">if</span> (refcounts[tensor_index] == 0) {
                    deallocate(i, tensor_index);
                }
            }
        }
    }
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org000001b" class="outline-6">
<h6 id="org000001b"><span class="section-number-6">1.1.3.2.2</span> ExecuteAllocations</h6>
<div class="outline-text-6" id="text-1-1-3-2-2">
<ol class="org-ol">
<li><p>
CalculateAllocations
</p>

<p>
根据 [start_node, finish_node] 找到所有有重叠 (冲突) 的 alloc, 然后根据 bestfit
分配一个 alloc
</p></li>

<li><p>
Commit
</p>

<p>
CalculateAllocations 分配 alloc 同时会维护 high_water_mark_ 记录最大需要的内存, Commit 会 malloc 这一段 underlying_buffer
</p></li>

<li><p>
ResolveTensorAllocation
</p>

<p>
underlying_buffer 做为 base address, 根据各个 alloc 中记录的 offset 更新最终的 tensor-&gt;data 地址
</p></li>
</ol>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">ArenaPlanner</span>::<span class="org-function-name">ExecuteAllocations</span>(<span class="org-type">int</span> <span class="org-variable-name">first_node</span>, <span class="org-type">int</span> <span class="org-variable-name">last_node</span>) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">Grow the size of `allocs_` if necessary. This allows allocating temporary</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">tensors in op's `prepare` function.</span>
    alloc_node_.resize(graph_info_-&gt;num_tensors(), kNodeNotAssigned);
    dealloc_node_.resize(graph_info_-&gt;num_tensors(), kNodeNotAssigned);
    allocs_.resize(graph_info_-&gt;num_tensors());
    <span class="org-comment-delimiter">// </span><span class="org-comment">Set allocation and deallocation for temporary tensors.</span>
    <span class="org-keyword">for</span> (<span class="org-type">size_t</span> <span class="org-variable-name">i</span> = first_node;
         i &lt;= <span class="org-keyword">static_cast</span>&lt;<span class="org-type">size_t</span>&gt;(last_node) &amp;&amp; i &lt; graph_info_-&gt;num_nodes();
         ++i) {
        <span class="org-keyword">const</span> <span class="org-type">TfLiteNode</span>&amp; <span class="org-variable-name">node</span> = graph_info_-&gt;node(i);
        <span class="org-type">TfLiteIntArray</span>* <span class="org-variable-name">node_temporaries</span> = node.temporaries;
        <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">j</span> = 0; j &lt; node_temporaries-&gt;size; ++j) {
            <span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> = node_temporaries-&gt;data[j];
            alloc_node_[tensor_index] = i;
            dealloc_node_[tensor_index] = i;
        }
    }

    CalculateAllocations(first_node, last_node);
    Commit();

    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">i</span> = 0; i &lt; <span class="org-keyword">static_cast</span>&lt;<span class="org-type">int</span>&gt;(graph_info_-&gt;num_tensors()); ++i) {
        ResolveTensorAllocation(i);
    }
}
</pre>
</div>
</div>

<ol class="org-ol">
<li><a id="org0000012"></a>CalculateAllocations<br />
<div class="outline-text-7" id="text-1-1-3-2-2-1">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">ArenaPlanner</span>::<span class="org-function-name">CalculateAllocations</span>(<span class="org-type">int</span> <span class="org-variable-name">first_node</span>, <span class="org-type">int</span> <span class="org-variable-name">last_node</span>) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">Indices of tensors in order their allocation offsets will be calculated.</span>
    <span class="org-keyword">const</span> <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int32_t</span>&gt; <span class="org-variable-name">tensor_order</span> =
        CreateTensorAllocationVector(first_node, last_node);

    <span class="org-keyword">for</span> (<span class="org-keyword">const</span> <span class="org-keyword">auto</span>&amp; <span class="org-variable-name">tensor_index</span> : tensor_order) {
        <span class="org-type">TfLiteTensor</span>&amp; <span class="org-variable-name">tensor</span> = *graph_info_-&gt;tensor(tensor_index);
        <span class="org-keyword">if</span> (tensor.allocation_type == kTfLiteArenaRw) {
            arena_.Allocate(context_, tensor_alignment_, tensor.bytes,
                            tensor_index, alloc_node_[tensor_index],
                            dealloc_node_[tensor_index],
                            &amp;allocs_[tensor_index]);
        }
        <span class="org-keyword">if</span> (tensor.allocation_type == kTfLiteArenaRwPersistent) {
            persistent_arena_.Allocate(
                context_, tensor_alignment_, tensor.bytes, tensor_index,
                <span class="org-comment-delimiter">/*</span><span class="org-comment">first_node=</span><span class="org-comment-delimiter">*/</span>alloc_node_[tensor_index],
                <span class="org-comment-delimiter">/*</span><span class="org-comment">last_node=</span><span class="org-comment-delimiter">*/</span><span class="org-constant">std</span>::<span class="org-constant">numeric_limits</span>&lt;<span class="org-type">int32_t</span>&gt;::max(),
                &amp;allocs_[tensor_index]);
        }
    }
}

<span class="org-type">TfLiteStatus</span> <span class="org-constant">SimpleMemoryArena</span>::<span class="org-function-name">Allocate</span>(
    <span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">size_t</span> <span class="org-variable-name">alignment</span>, <span class="org-type">size_t</span> <span class="org-variable-name">size</span>, <span class="org-type">int32_t</span> <span class="org-variable-name">tensor</span>,
    <span class="org-type">int32_t</span> <span class="org-variable-name">first_node</span>, <span class="org-type">int32_t</span> <span class="org-variable-name">last_node</span>,
    <span class="org-type">ArenaAllocWithUsageInterval</span>* <span class="org-variable-name">new_alloc</span>) {
    new_alloc-&gt;tensor = tensor;
    new_alloc-&gt;first_node = first_node;
    new_alloc-&gt;last_node = last_node;
    new_alloc-&gt;size = size;

    <span class="org-comment-delimiter">// </span><span class="org-comment">If we don't find a better gap just allocate at the end of the buffer.</span>
    <span class="org-keyword">const</span> <span class="org-type">size_t</span> <span class="org-variable-name">kOffsetNotAssigned</span> = <span class="org-constant">std</span>::<span class="org-constant">numeric_limits</span>&lt;<span class="org-type">size_t</span>&gt;::max();
    <span class="org-type">size_t</span> <span class="org-variable-name">best_offset</span> = kOffsetNotAssigned;
    <span class="org-type">size_t</span> <span class="org-variable-name">best_offset_fit</span> = kOffsetNotAssigned;

    <span class="org-comment-delimiter">// </span><span class="org-comment">Go through the sorted allocs and look at the gaps between them.</span>
    <span class="org-type">size_t</span> <span class="org-variable-name">current_offset</span> = 0;
    <span class="org-keyword">for</span> (<span class="org-keyword">const</span> <span class="org-keyword">auto</span>&amp; <span class="org-variable-name">alloc</span> : ordered_allocs_) {
        <span class="org-keyword">if</span> (alloc.<span class="org-type">last_node</span> &lt; first_node || alloc.first_node &gt; last_node) {
            <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#27809;&#26377;&#37325;&#21472;&#30340; alloc &#30456;&#24403;&#20110;&#31354;&#38386;&#30340; buffer</span>
            <span class="org-keyword">continue</span>;
        }
        <span class="org-comment-delimiter">// </span><span class="org-comment">If we found a gap larger than required size, and smaller than previous</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">best fit, take it.</span>
        <span class="org-keyword">if</span> (current_offset + size &lt;= alloc.offset &amp;&amp;
            alloc.offset - current_offset &lt; best_offset_fit) {
            best_offset = current_offset;
            best_offset_fit = alloc.offset - current_offset;
        }
        current_offset = <span class="org-constant">std</span>::max(current_offset, alloc.offset + alloc.size);
    }
    <span class="org-keyword">if</span> (best_offset == kOffsetNotAssigned) {
        best_offset = current_offset;
    }

    <span class="org-comment-delimiter">// </span><span class="org-comment">Update the required buffer size.</span>
    high_water_mark_ = <span class="org-constant">std</span>::max(high_water_mark_, best_offset + size);
    new_alloc-&gt;offset = best_offset;

    <span class="org-keyword">auto</span> <span class="org-variable-name">insertion_it</span> = ordered_allocs_.begin();
    <span class="org-keyword">while</span> (insertion_it != ordered_allocs_.end() &amp;&amp; *insertion_it &lt; *new_alloc) {
        ++insertion_it;
    }
    ordered_allocs_.insert(insertion_it, *new_alloc);
}
</pre>
</div>
</div>
</li>

<li><a id="org0000015"></a>Commit<br />
<div class="outline-text-7" id="text-1-1-3-2-2-2">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">SimpleMemoryArena</span>::<span class="org-function-name">Commit</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>) {
    <span class="org-type">size_t</span> <span class="org-variable-name">required_size</span> = RequiredBufferSize();

    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! malloc</span>
    <span class="org-type">char</span>* <span class="org-variable-name">new_alloc</span> = <span class="org-keyword">new</span> <span class="org-type">char</span>[required_size];
    <span class="org-type">char</span>* <span class="org-variable-name">new_underlying_buffer_aligned_ptr</span> = <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-type">char</span>*&gt;(
        AlignTo(arena_alignment_, <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-type">intptr_t</span>&gt;(new_alloc)));

    underlying_buffer_.reset(new_alloc);
    underlying_buffer_size_ = required_size;
    underlying_buffer_aligned_ptr_ = new_underlying_buffer_aligned_ptr;
}
</pre>
</div>
</div>
</li>

<li><a id="org0000018"></a>ResolveTensorAllocation<br />
<div class="outline-text-7" id="text-1-1-3-2-2-3">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">ArenaPlanner</span>::<span class="org-function-name">ResolveTensorAllocation</span>(<span class="org-type">int</span> <span class="org-variable-name">tensor_index</span>) {
    <span class="org-type">TfLiteTensor</span>&amp; <span class="org-variable-name">tensor</span> = *graph_info_-&gt;tensor(tensor_index);
    <span class="org-keyword">if</span> (tensor.allocation_type == kTfLiteArenaRw) {
        <span class="org-comment-delimiter">// </span><span class="org-comment">Skip resolution if the size of the tensor is zero, leaving it as a</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">nullptr.</span>
        arena_.ResolveAlloc(context_, allocs_[tensor_index], &amp;tensor.data.raw);
    }
    <span class="org-keyword">if</span> (tensor.allocation_type == kTfLiteArenaRwPersistent) {
        persistent_arena_.ResolveAlloc(context_, allocs_[tensor_index],
                                       &amp;tensor.data.raw);
    }
}

<span class="org-type">TfLiteStatus</span> <span class="org-constant">SimpleMemoryArena</span>::<span class="org-function-name">ResolveAlloc</span>(
    <span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-keyword">const</span> <span class="org-type">ArenaAllocWithUsageInterval</span>&amp; <span class="org-variable-name">alloc</span>,
    <span class="org-type">char</span>** <span class="org-variable-name">output_ptr</span>) {
    <span class="org-keyword">if</span> (alloc.size == 0) {
        *output_ptr = <span class="org-constant">nullptr</span>;
    } <span class="org-keyword">else</span> {
        *output_ptr = underlying_buffer_aligned_ptr_ + alloc.offset;
    }
}
</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org0000024" class="outline-4">
<h4 id="org0000024"><span class="section-number-4">1.1.4</span> Interpreter.Invoke</h4>
<div class="outline-text-4" id="text-1-1-4">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-constant">Interpreter</span>::Invoke:
    primary_subgraph().Invoke()
        <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">execution_plan_index</span> = 0; execution_plan_index &lt; execution_plan_.size(); execution_plan_index++):
            <span class="org-type">int</span> <span class="org-variable-name">node_index</span> = execution_plan_[execution_plan_index];
            <span class="org-type">TfLiteNode</span>&amp; <span class="org-variable-name">node</span> = nodes_and_registration_[node_index].first;
            <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>&amp; <span class="org-variable-name">registration</span> = nodes_and_registration_[node_index].second;
            OpInvoke(registration, &amp;node)
                <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#35843;&#29992;&#21040; resolver &#20013;&#27880;&#20876;&#30340; registration &#20013;&#30340; .invoke, &#20363;&#22914; AbsEval</span>
                registration.invoke(node)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org000005e" class="outline-3">
<h3 id="org000005e"><span class="section-number-3">1.2</span> TFLite Delegate</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org000002a" class="outline-4">
<h4 id="org000002a"><span class="section-number-4">1.2.1</span> A Simple Model</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
\(f(x)=sin(x)+x+sin(x*2)\)
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> tensorflow <span class="org-keyword">as</span> tf
<span class="org-keyword">from</span> tensorflow.keras <span class="org-keyword">import</span> layers, Model

<span class="org-builtin">input</span>=layers.Input(shape=(1, ))
<span class="org-variable-name">output</span>=layers.Lambda(<span class="org-keyword">lambda</span> x: tf.sin(x)+x+tf.sin(x*2))(<span class="org-builtin">input</span>)
<span class="org-variable-name">model</span>=Model(inputs=<span class="org-builtin">input</span>,outputs=output)
model.summary()
<span class="org-keyword">print</span>(model.predict([2.]))
model.save(<span class="org-string">"/tmp/sin"</span>)
</pre>
</div>

<p>
Model: "model"
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
Layer (type)                 Output Shape              Param #   
<code>===============================================================</code>
input_1 (InputLayer)         [(None, 1)]               0         
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
lambda (Lambda)              (None, 1)                 0         
<code>===============================================================</code>
Total params: 0
Trainable params: 0
Non-trainable params: 0
<span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline"><span class="underline">_</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
2.152495
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> tensorflow <span class="org-keyword">as</span> tf

<span class="org-variable-name">converter</span> = tf.lite.TFLiteConverter.from_saved_model(<span class="org-string">"/tmp/sin"</span>)
<span class="org-variable-name">tflite</span> = converter.convert()
<span class="org-keyword">with</span> <span class="org-builtin">open</span> (<span class="org-string">"/tmp/sin.tflite"</span>,<span class="org-string">"wb"</span>) <span class="org-keyword">as</span> f:
    f.write(tflite)
    <span class="org-keyword">print</span>(<span class="org-string">"size of sin.tflite:"</span>, <span class="org-builtin">len</span>(tflite))
</pre>
</div>

<p>
size of sin.tflite: 1240
</p>
</div>
</div>

<div id="outline-container-org000002d" class="outline-4">
<h4 id="org000002d"><span class="section-number-4">1.2.2</span> MyDelegate</h4>
<div class="outline-text-4" id="text-1-2-2">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-preprocessor">#include</span> <span class="org-string">&lt;cstdio&gt;</span>

<span class="org-preprocessor">#include</span> <span class="org-string">"tensorflow/lite/builtin_ops.h"</span>
<span class="org-preprocessor">#include</span> <span class="org-string">"tensorflow/lite/interpreter.h"</span>
<span class="org-preprocessor">#include</span> <span class="org-string">"tensorflow/lite/kernels/kernel_util.h"</span>
<span class="org-preprocessor">#include</span> <span class="org-string">"tensorflow/lite/kernels/register.h"</span>
<span class="org-preprocessor">#include</span> <span class="org-string">"tensorflow/lite/model.h"</span>
<span class="org-preprocessor">#include</span> <span class="org-string">"tensorflow/lite/optional_debug_tools.h"</span>
<span class="org-preprocessor">#include</span> <span class="org-string">"tensorflow/lite/util.h"</span>

<span class="org-keyword">using</span> <span class="org-keyword">namespace</span> <span class="org-constant">tflite</span>;

<span class="org-keyword">class</span> <span class="org-type">MyDelegate</span> {
  <span class="org-keyword">public</span>:
    <span class="org-keyword">static</span> <span class="org-type">bool</span> <span class="org-function-name">SupportedOp</span>(<span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span>) {
        <span class="org-keyword">return</span> registration-&gt;builtin_code == kTfLiteBuiltinSin;
    }

    <span class="org-type">bool</span> <span class="org-function-name">Invoke</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>) {
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#36825;&#37324; invoke &#30340;&#23454;&#29616;&#26159;&#26377;&#38382;&#39064;&#30340;, &#23427;&#20551;&#35774;&#20102; subset &#37324;&#21482;&#26377;&#19968;&#20010; sin, &#23454;</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">&#38469;&#19978;&#22810;&#20010;&#36830;&#32493;&#30340; sin &#20363;&#22914; tf.sin(tf.sin(x)) &#20250;&#29983;&#25104;&#22810;&#20010; sin node, &#32780;&#23545;&#19968;</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">&#20010; subset &#21482;&#20250;&#29983;&#25104;&#19968;&#20010; delegate node...</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">&#27491;&#30830;&#30340;&#20570;&#27861;&#26159;&#20174; TfLiteDelegateParams &#20013;&#33719;&#24471;&#25152;&#26377;&#30340; node &#20449;&#24687;&#20294;&#20381;&#27425;&#25191;&#34892;,</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">&#20363;&#22914; flex::Eval &#30340;&#20570;&#27861;:</span>
        <span class="org-comment-delimiter">//</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">TfLiteStatus DelegateKernel::Eval(TfLiteContext* context, TfLiteNode* node) {</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">// Execute the TensorFlow Ops sequentially.</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">for (auto&amp; node_data : op_data_-&gt;nodes) {</span>
        <span class="org-comment-delimiter">//   </span><span class="org-comment">auto status = ExecuteFlexOp(context, buffer_map, node_data.get());</span>
        <span class="org-comment-delimiter">//   </span><span class="org-comment">TF_LITE_ENSURE_OK(context, ConvertStatus(context, status));</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">}</span>
        <span class="org-comment-delimiter">//</span>

        printf(<span class="org-string">"sunway : invoke\n"</span>);
        <span class="org-keyword">const</span> <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">input</span> = GetInput(context, node, 0);
        <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">output</span> = GetOutput(context, node, 0);

        <span class="org-type">float</span>* <span class="org-variable-name">input_data</span> = input-&gt;data.f;
        <span class="org-type">float</span>* <span class="org-variable-name">output_data</span> = output-&gt;data.f;

        <span class="org-keyword">const</span> <span class="org-type">int</span> <span class="org-variable-name">M</span> = input-&gt;dims-&gt;size;
        <span class="org-keyword">const</span> <span class="org-type">int</span> <span class="org-variable-name">N</span> = input-&gt;dims-&gt;data[0];
        <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">i</span> = 0; i &lt; M; i++) {
            <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">j</span> = 0; j &lt; N; ++j) {
                output_data[i * N + j] = sin(<span class="org-type">input_data</span>[i * N + j]);
            }
        }

        <span class="org-keyword">return</span> kTfLiteOk;
    }
};

<span class="org-type">TfLiteRegistration</span> <span class="org-function-name">GetMyDelegateNodeRegistration</span>() {
    <span class="org-type">TfLiteRegistration</span> <span class="org-variable-name">kernel_registration</span>;
    kernel_registration.builtin_code = kTfLiteBuiltinDelegate;
    kernel_registration.custom_name = <span class="org-string">"MyDelegate"</span>;
    kernel_registration.free = <span class="org-constant">NULL</span>;
    kernel_registration.init = [](<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-keyword">const</span> <span class="org-type">char</span>* <span class="org-variable-name">buffer</span>,
                                  <span class="org-type">size_t</span>) -&gt; <span class="org-type">void</span>* {
        <span class="org-keyword">const</span> <span class="org-type">TfLiteDelegateParams</span>* <span class="org-variable-name">delegate_params</span> =
                <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-keyword">const</span> <span class="org-type">TfLiteDelegateParams</span>*&gt;(buffer);
        <span class="org-type">MyDelegate</span>* <span class="org-variable-name">my_delegate</span> = <span class="org-keyword">new</span> <span class="org-type">MyDelegate</span>;
        <span class="org-keyword">return</span> my_delegate;
    };
    kernel_registration.invoke = [](<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>,
                                    <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>) -&gt; TfLiteStatus {
        printf(<span class="org-string">"kerenl_invoke\n"</span>);
        <span class="org-type">MyDelegate</span>* <span class="org-variable-name">kernel</span> = <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-type">MyDelegate</span>*&gt;(node-&gt;user_data);
        kernel-&gt;Invoke(context, node);
        <span class="org-keyword">return</span> kTfLiteOk;
    };
    kernel_registration.prepare = <span class="org-constant">NULL</span>;

    <span class="org-keyword">return</span> kernel_registration;
}

<span class="org-type">TfLiteStatus</span> <span class="org-function-name">MyDelegatePrepare</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>,
                               <span class="org-type">TfLiteDelegate</span>* <span class="org-variable-name">delegate</span>) {
    <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt; <span class="org-variable-name">supported_nodes</span>;
    <span class="org-type">TfLiteIntArray</span>* <span class="org-variable-name">plan</span>;
    TF_LITE_ENSURE_STATUS(context-&gt;GetExecutionPlan(context, &amp;plan));
    <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>;
    <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span>;
    <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">i</span> = 0; i &lt; plan-&gt;size; i++) {
        <span class="org-type">int</span> <span class="org-variable-name">node_index</span> = plan-&gt;data[i];
        TF_LITE_ENSURE_STATUS(context-&gt;GetNodeAndRegistration(
            context, node_index, &amp;node, &amp;registration));
        <span class="org-keyword">if</span> (<span class="org-constant">MyDelegate</span>::SupportedOp(registration)) {
            supported_nodes.push_back(node_index);
        }
    }
    <span class="org-type">TfLiteRegistration</span> <span class="org-variable-name">my_delegate_kernel_registration</span> =
            GetMyDelegateNodeRegistration();

    <span class="org-type">TfLiteIntArray</span>* <span class="org-variable-name">supported_nodes_int_array</span> =
            ::<span class="org-constant">tflite</span>::ConvertVectorToTfLiteIntArray(supported_nodes);
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! replace node with new delegate registration</span>
    <span class="org-keyword">auto</span> <span class="org-variable-name">status</span> = context-&gt;ReplaceNodeSubsetsWithDelegateKernels(
        context, my_delegate_kernel_registration, supported_nodes_int_array,
        delegate);
    TfLiteIntArrayFree(supported_nodes_int_array);
    <span class="org-keyword">return</span> status;
}

<span class="org-type">TfLiteDelegate</span>* <span class="org-function-name">CreateMyDelegate</span>() {
    <span class="org-type">TfLiteDelegate</span>* <span class="org-variable-name">delegate</span> = <span class="org-keyword">new</span> <span class="org-type">TfLiteDelegate</span>;

    delegate-&gt;data_ = <span class="org-constant">nullptr</span>;
    delegate-&gt;flags = kTfLiteDelegateFlagsNone;
    delegate-&gt;Prepare = &amp;MyDelegatePrepare;
    delegate-&gt;CopyFromBufferHandle = <span class="org-constant">NULL</span>;
    delegate-&gt;CopyToBufferHandle = <span class="org-constant">NULL</span>;
    delegate-&gt;FreeBufferHandle = <span class="org-constant">NULL</span>;

    <span class="org-keyword">return</span> delegate;
}

<span class="org-type">int</span> <span class="org-function-name">main</span>(<span class="org-type">int</span> <span class="org-variable-name">argc</span>, <span class="org-type">char</span>* <span class="org-variable-name">argv</span>[]) {
    <span class="org-keyword">const</span> <span class="org-type">char</span>* <span class="org-variable-name">filename</span> = <span class="org-string">"/tmp/sin.tflite"</span>;

    <span class="org-constant">std</span>::<span class="org-type">unique_ptr</span>&lt;<span class="org-constant">tflite</span>::FlatBufferModel&gt; <span class="org-variable-name">model</span> =
            <span class="org-constant">tflite</span>::<span class="org-constant">FlatBufferModel</span>::BuildFromFile(filename);

    <span class="org-constant">tflite</span>::<span class="org-constant">ops</span>::<span class="org-constant">builtin</span>::<span class="org-type">BuiltinOpResolver</span> <span class="org-variable-name">resolver</span>;
    <span class="org-type">InterpreterBuilder</span> <span class="org-variable-name">builder</span>(*model, resolver);
    <span class="org-constant">std</span>::<span class="org-type">unique_ptr</span>&lt;Interpreter&gt; <span class="org-variable-name">interpreter</span>;
    builder(&amp;interpreter);

    <span class="org-keyword">auto</span>* <span class="org-variable-name">my_delegate</span> = CreateMyDelegate();
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! ModifyGraphWithDelegate</span>
    <span class="org-keyword">if</span> (interpreter-&gt;ModifyGraphWithDelegate(my_delegate) != kTfLiteOk) {
        printf(<span class="org-string">"sunway:ModifyGraphWithDelegate failed\n"</span>);
    }

    interpreter-&gt;AllocateTensors();
    <span class="org-type">float</span>* <span class="org-variable-name">input</span> = interpreter-&gt;typed_input_tensor&lt;<span class="org-type">float</span>&gt;(0);
    input[0] = 2.0;
    interpreter-&gt;Invoke();
    <span class="org-type">float</span>* <span class="org-variable-name">output</span> = interpreter-&gt;typed_output_tensor&lt;<span class="org-type">float</span>&gt;(0);
    printf(<span class="org-string">"%f\n"</span>, output[0]);

    <span class="org-keyword">return</span> 0;
}

</pre>
</div>
</div>
</div>

<div id="outline-container-org0000030" class="outline-4">
<h4 id="org0000030"><span class="section-number-4">1.2.3</span> ModifyGraphWithDelegate</h4>
<div class="outline-text-4" id="text-1-2-3">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">Subgraph</span>::<span class="org-function-name">ModifyGraphWithDelegate</span>(<span class="org-type">TfLiteDelegate</span>* <span class="org-variable-name">delegate</span>):
    <span class="org-type">TfLiteStatus</span> <span class="org-variable-name">status</span> = delegate-&gt;Prepare(&amp;context_, delegate);
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! Prepare &#22914;&#21069;&#38754;&#30340; MyDelegatePrepare, &#36127;&#36131;&#25195;&#25551;&#25152;&#26377; node, &#25214;&#21040;&#33021;&#22788;&#29702;&#30340;</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">node, &#28982;&#21518;&#35843;&#29992; ReplaceNodeSubsetsWithDelegateKernels &#26469;&#26367;&#25442; node &#21644;</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">execution plan</span>

</pre>
</div>
</div>
</div>

<div id="outline-container-org0000034" class="outline-4">
<h4 id="org0000034"><span class="section-number-4">1.2.4</span> ReplaceNodeSubsetsWithDelegateKernels</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
ReplaceNodeSubsetsWithDelegateKernels 的作用是把所有 node 拆成不同的
node_subset, 例如前面的 \(f(x)=sin(x)+x+sin(x*2)\), 其结构为:
</p>

<div class="org-src-container">
<pre class="src src-dot"><span class="org-keyword">digraph</span> <span class="org-function-name">G</span> {
    SIN1 [<span class="org-variable-name">color=</span><span class="org-string">red</span>]
    SIN2 [<span class="org-variable-name">color=</span><span class="org-string">red</span>]
    MULTIPLY [<span class="org-variable-name">color=</span><span class="org-string">green</span>]
    ADD1 [<span class="org-variable-name">color=</span><span class="org-string">green</span>]
    ADD2 [<span class="org-variable-name">color=</span><span class="org-string">green</span>]
    X-&gt;SIN1-&gt;ADD1-&gt;ADD2
    X-&gt;ADD1
    X-&gt;MULTIPLY
    2-&gt;MULTIPLY-&gt;SIN2-&gt;ADD2-&gt;Y
}
</pre>
</div>


<div id="org0000033" class="figure">
<p><img src="../extra/tflite_delegate.png" alt="tflite_delegate.png" />
</p>
</div>

<p>
一个五个 node 划分为四个按顺排列的 subset:
</p>

<ol class="org-ol">
<li>SIN1</li>
<li>ADD1, MULTIPLY</li>
<li>SIN2</li>
<li>ADD2</li>
</ol>

<p>
划分的原则是:
</p>

<ol class="org-ol">
<li>属于不同 delegate 的 node 需要分开</li>
<li>在满足 input, output 依赖的前提下, 属于同一个 delegate 的 node 划分在一起, 如上面的 (ADD1, MULTIPLY)</li>
<li>各个 subset 要按 topo 排序, 因为 ReplaceNodeSubsetsWithDelegateKernels 时会线性的遍历 subset 构造了一个线性的 execution_plan</li>
</ol>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">Subgraph</span>::<span class="org-function-name">ReplaceNodeSubsetsWithDelegateKernels</span>(
    <span class="org-type">TfLiteRegistration</span> <span class="org-variable-name">registration</span>, <span class="org-keyword">const</span> <span class="org-type">TfLiteIntArray</span>* <span class="org-variable-name">nodes_to_replace</span>,
    <span class="org-type">TfLiteDelegate</span>* <span class="org-variable-name">delegate</span>) {
    registration.builtin_code = BuiltinOperator_DELEGATE;

    <span class="org-comment-delimiter">// </span><span class="org-comment">Analyze the graph to find all independent node_subsets that are either</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">fully not\-this\-delegate or this\-delegate computation.</span>
    <span class="org-type">InterpreterInfo</span> <span class="org-variable-name">info</span>(<span class="org-keyword">this</span>);
    <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;NodeSubset&gt; <span class="org-variable-name">node_subsets</span>;
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#20998;&#20026;&#22810;&#20010; subset</span>
    PartitionGraphIntoIndependentNodeSubsets(&amp;info, nodes_to_replace,
                                             &amp;node_subsets);

    execution_plan_.clear();

    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#25353;&#39034;&#24207;&#36941;&#21382; subset, &#22240;&#20026;&#21508;&#20010; subset &#20043;&#38388;&#24050;&#32463;&#26159; topo &#26377;&#24207;&#30340;</span>
    <span class="org-keyword">for</span> (<span class="org-keyword">auto</span>&amp; <span class="org-variable-name">node_subset</span> : node_subsets) {
        <span class="org-keyword">switch</span> (node_subset.type) {
            <span class="org-comment-delimiter">// </span><span class="org-comment">!!! node &#19981;&#23646;&#20110; delegate, &#19981;&#38656;&#35201;&#26367;&#25442;, &#30452;&#25509;&#36861;&#21152;&#21040; execution_plan_</span>
            <span class="org-keyword">case</span> <span class="org-constant">NodeSubset</span>::kTfNonPartition:
                <span class="org-keyword">for</span> (<span class="org-keyword">auto</span> <span class="org-variable-name">it</span> = node_subset.nodes.begin(); it != node_subset.nodes.end();
                     ++it) {
                    execution_plan_.push_back(*it);
                }
                <span class="org-keyword">break</span>;
            <span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#23545;&#20110; delegate, &#38656;&#35201;&#29983;&#25104;&#19968;&#20010;&#26032;&#30340; node &#20195;&#26367;subset &#20013;&#30340; node(&#21487;</span>
            <span class="org-comment-delimiter">// </span><span class="org-comment">&#33021;&#20026;&#22810;&#20010; node, delegate &#30340; TfLiteDelegateParams &#33021;&#25343;&#21040;&#21738;&#20123; node</span>
            <span class="org-comment-delimiter">// </span><span class="org-comment">&#34987;&#26367;&#25442;), &#28982;&#21518;&#36861;&#21152;&#21040; execution\_plan\_, &#26032;&#30340; node &#20250;&#20351;&#29992;delegate &#30340;</span>
            <span class="org-comment-delimiter">// </span><span class="org-comment">registration</span>
            <span class="org-keyword">case</span> <span class="org-constant">NodeSubset</span>::kTfPartition: {
                <span class="org-type">int</span> <span class="org-variable-name">node_index</span>;

                <span class="org-type">TfLiteDelegateParams</span>* <span class="org-variable-name">params</span> =
                        CreateDelegateParams(delegate, node_subset);
                AddNodeWithParameters(
                    node_subset.input_tensors, node_subset.output_tensors, {}, <span class="org-constant">nullptr</span>,
                    0, params, &amp;registration, &amp;node_index)

                <span class="org-comment-delimiter">// </span><span class="org-comment">Initialize the output tensors's delegate-related fields.</span>
                <span class="org-keyword">for</span> (<span class="org-type">int</span> <span class="org-variable-name">tensor_index</span> : node_subset.output_tensors) {
                    <span class="org-type">TfLiteTensor</span>* <span class="org-variable-name">tensor</span> = &amp;tensors_[tensor_index];
                    TF_LITE_ENSURE(&amp;context_, tensor-&gt;delegate == <span class="org-constant">nullptr</span> ||
                                   tensor-&gt;delegate == delegate);
                    tensor-&gt;delegate = delegate;
                }

                <span class="org-comment-delimiter">// </span><span class="org-comment">Associate the node with the delegate.</span>
                <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span> = &amp;nodes_and_registration_[node_index].first;
                node-&gt;delegate = delegate;
            } <span class="org-keyword">break</span>;
        }
    }
}

</pre>
</div>
</div>
</div>

<div id="outline-container-org0000037" class="outline-4">
<h4 id="org0000037"><span class="section-number-4">1.2.5</span> PartitionGraphIntoIndependentNodeSubsets</h4>
<div class="outline-text-4" id="text-1-2-5">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-keyword">while</span> (changed):
    subset = <span class="org-keyword">new</span> <span class="org-type">array</span>()
    changed = <span class="org-constant">false</span>
    is_delegate = nil

    <span class="org-keyword">for</span> node in nodes:
        skip <span class="org-keyword">if</span> node.input is <span class="org-keyword">not</span> ready
        skip <span class="org-keyword">if</span> node.visited
        <span class="org-keyword">if</span> is_delegate is nil:
            is_delegate = node.is_delegate
        skip <span class="org-keyword">if</span> node.is_delegate != is_delegate
        subset.push(node)
        node.visited = <span class="org-constant">true</span>
        node.output.ready = <span class="org-constant">true</span>
    <span class="org-keyword">if</span> subset is <span class="org-keyword">not</span> empty:
        subsets.push(subset)
        changed = <span class="org-constant">true</span>

</pre>
</div>
</div>
</div>

<div id="outline-container-org000003d" class="outline-4">
<h4 id="org000003d"><span class="section-number-4">1.2.6</span> Delegate 与 Custom Op 的区别</h4>
<div class="outline-text-4" id="text-1-2-6">
<p>
Delegate 实际上利用了 Custom Op 的机制, 例如 Delegate Op 也是一种特殊的 Custom
Op, 它们都会给 node 注册了一个 registration, 使得执行该 node 时会执行到自定义的
Invoke
</p>

<p>
但 delegate 比 Custom Op 多了一个 partition 的操作, 即它会尽量的把 delegate op
放在同一个 node 里, 例如:
</p>

<pre class="example" id="org000003a">
X-&gt;A1-&gt;A2-&gt;D1-&gt;D2-&gt;D3-Y
</pre>

<p>
假设用 Custom Op 实现 D1, D2, D3 (用 CD1 表示 D1 使用 AddCustom 指定的
registration), 则变为:
</p>

<pre class="example" id="org000003b">
X-&gt;A1-&gt;A2-&gt;CD1-&gt;CD2-&gt;CD3-Y
</pre>

<p>
用 delegate 实现 D1, D2, D3 则变为:
</p>

<pre class="example" id="org000003c">
X-&gt;A1-&gt;A2-&gt;CD-&gt;Y
</pre>

<p>
其中 CD 对应 delegate 对 D1, D2, D3 的实现, 这样做的好处是:
</p>

<blockquote>
<p>
D1, D2 的输出变成了 delegate 设备内部的中间结果, 不必传递给主设备 (CPU)
</p>
</blockquote>
</div>
</div>

<div id="outline-container-org000005c" class="outline-4">
<h4 id="org000005c"><span class="section-number-4">1.2.7</span> Flex Delegate</h4>
<div class="outline-text-4" id="text-1-2-7">
<p>
<a href="https://www.tensorflow.org/lite/guide/ops_select">https://www.tensorflow.org/lite/guide/ops_select</a>
</p>
</div>

<div id="outline-container-org0000046" class="outline-5">
<h5 id="org0000046"><span class="section-number-5">1.2.7.1</span> Tflite Converter</h5>
<div class="outline-text-5" id="text-1-2-7-1">
</div>
<div id="outline-container-org0000040" class="outline-6">
<h6 id="org0000040"><span class="section-number-6">1.2.7.1.1</span> target ops</h6>
<div class="outline-text-6" id="text-1-2-7-1-1">
<div class="org-src-container">
<pre class="src src-python"><span class="org-variable-name">converter.target_spec.supported_ops</span> = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]

</pre>
</div>

<p>
通过设置 converter 的 supported_ops, 可以影响生成 tflite 的过程
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">if</span> target_ops:
    <span class="org-keyword">if</span> <span class="org-builtin">set</span>(target_ops) == <span class="org-builtin">set</span>([OpsSet.TFLITE_BUILTINS, OpsSet.SELECT_TF_OPS]):
      <span class="org-variable-name">toco.enable_select_tf_ops</span> = <span class="org-constant">True</span>
    <span class="org-keyword">elif</span> <span class="org-builtin">set</span>(target_ops) == <span class="org-builtin">set</span>([OpsSet.SELECT_TF_OPS]):
      <span class="org-variable-name">toco.enable_select_tf_ops</span> = <span class="org-constant">True</span>
      <span class="org-variable-name">toco.force_select_tf_ops</span> = <span class="org-constant">True</span>
</pre>
</div>

<p>
通过 supported_ops, 可以控制是否 enable_select_tf_ops 或 force_select_tf_ops:
</p>

<ol class="org-ol">
<li>若 force_select_tf_ops, 即 toco (Tensorflow Optimized COnverter) 会把所有 op
都转换为 tf_op (即 flex delegate op)</li>
<li>若 enable_select_tf_ops (而非 force_select_tf_ops), 则 builtin_op 之外的
op 会转换为 tf_op</li>
</ol>
</div>
</div>

<div id="outline-container-org0000043" class="outline-6">
<h6 id="org0000043"><span class="section-number-6">1.2.7.1.2</span> export</h6>
<div class="outline-text-6" id="text-1-2-7-1-2">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-comment-delimiter">// </span><span class="org-comment">!!! &#24403;&#21069; flex op &#26377;&#19968;&#20010; allowlist, &#34920;&#31034;&#21738;&#20123; tf op &#21487;&#20197;&#25903;&#25345;</span>
<span class="org-keyword">if</span> (enabled_op_types_.contains(<span class="org-constant">OpType</span>::kSelectTf) &amp;&amp;
    IsAllowlistedFlexOp(node_def-&gt;op())) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! kFlexOpNamePrefix = "Flex"</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">flex op &#20363;&#22914; Abs &#20250;&#34987;&#20462;&#25913;&#20026;&#21517;&#20026; FlexAbs &#30340; custom_op</span>
    op_name = <span class="org-constant">std</span>::string(kFlexOpNamePrefix) + node_def-&gt;op();
    <span class="org-comment-delimiter">// </span><span class="org-comment">!!! node_def-&gt;op() (&#21363; op name, &#20363;&#22914; Abs) &#22312; CreateFlexOpCustomOptions &#26102;</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#20250;&#20889;&#22312; custom options, flex delegate &#20250;&#20174; custom options &#20013;&#35835;&#21040; op name,</span>
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#20877;&#21435;&#25191;&#34892;, &#32780;&#19981;&#26159;&#30452;&#25509;&#29992; custom name &#21435;&#25481; "Flex" &#21069;&#32512;</span>
    <span class="org-keyword">if</span> (<span class="org-keyword">auto</span> <span class="org-variable-name">options</span> = CreateFlexOpCustomOptions(*node_def, inst-&gt;getLoc())) {

        custom_options = *options;
    } <span class="org-keyword">else</span> {
        <span class="org-keyword">return</span> <span class="org-constant">llvm</span>::None;
    }
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-org0000055" class="outline-5">
<h5 id="org0000055"><span class="section-number-5">1.2.7.2</span> Flex Delegate Impl</h5>
<div class="outline-text-5" id="text-1-2-7-2">
</div>
<div id="outline-container-org0000049" class="outline-6">
<h6 id="org0000049"><span class="section-number-6">1.2.7.2.1</span> ApplyDelegates</h6>
<div class="outline-text-6" id="text-1-2-7-2-1">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">InterpreterBuilder</span>::<span class="org-function-name">ApplyDelegates</span>(<span class="org-type">Interpreter</span>* <span class="org-variable-name">interpreter</span>,
                                                <span class="org-type">int</span> <span class="org-variable-name">num_threads</span>) {
    <span class="org-keyword">if</span> (has_flex_op_) {
        <span class="org-keyword">if</span> (<span class="org-keyword">auto</span> <span class="org-variable-name">flex_delegate</span> = AcquireFlexDelegate()) {
            <span class="org-keyword">return</span> interpreter-&gt;ModifyGraphWithDelegate(<span class="org-constant">std</span>::move(flex_delegate));
        }
    }

    <span class="org-keyword">return</span> kTfLiteOk;
}

<span class="org-type">TfLiteStatus</span> <span class="org-constant">InterpreterBuilder</span>::<span class="org-function-name">BuildLocalIndexToRegistrationMapping</span>() {
    <span class="org-keyword">for</span> (<span class="org-keyword">const</span> <span class="org-type">OperatorCode</span>* <span class="org-variable-name">opcode</span> : *opcodes) {
        <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span> = <span class="org-constant">nullptr</span>;
        status = GetRegistrationFromOpCode(opcode, op_resolver_, error_reporter_,
                                           &amp;registration);
        <span class="org-keyword">if</span> (status != kTfLiteOk) {
            <span class="org-comment-delimiter">// </span><span class="org-comment">!!! flex op &#39318;&#20808;&#26159; custom_op</span>
            <span class="org-keyword">if</span> (opcode-&gt;builtin_code() != BuiltinOperator_CUSTOM) {
                <span class="org-keyword">return</span> status;
            }
            <span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">op_name</span> = opcode-&gt;custom_code()-&gt;c_str();
            <span class="org-comment-delimiter">// </span><span class="org-comment">!!! op_name &#26159;&#21542;&#26377; "Flex" &#21069;&#32512;</span>
            has_flex_op_ |= IsFlexOp(op_name);
        }
    }
    <span class="org-keyword">return</span> status;
}

<span class="org-type">bool</span> <span class="org-function-name">IsFlexOp</span>(<span class="org-keyword">const</span> <span class="org-type">char</span>* <span class="org-variable-name">custom_name</span>) {
    <span class="org-keyword">return</span> custom_name &amp;&amp; strncmp(custom_name, kFlexCustomCodePrefix,
                                 strlen(kFlexCustomCodePrefix)) == 0;
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org000005b" class="outline-6">
<h6 id="org000005b"><span class="section-number-6">1.2.7.2.2</span> Flex Delegate</h6>
<div class="outline-text-6" id="text-1-2-7-2-2">
</div>
<ol class="org-ol">
<li><a id="org000004c"></a>IsNodeSupportedByDelegate<br />
<div class="outline-text-7" id="text-1-2-7-2-2-1">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">bool</span> <span class="org-constant">FlexDelegate</span>::<span class="org-function-name">IsNodeSupportedByDelegate</span>(
    <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span>, <span class="org-keyword">const</span> <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>,
    <span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>) <span class="org-keyword">const</span> {
    <span class="org-keyword">return</span> IsFlexOp(registration-&gt;custom_name);
}
</pre>
</div>
</div>
</li>


<li><a id="org000004f"></a>Eval<br />
<div class="outline-text-7" id="text-1-2-7-2-2-2">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">TfLiteStatus</span> <span class="org-constant">DelegateKernel</span>::<span class="org-function-name">Eval</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>, <span class="org-type">TfLiteNode</span>* <span class="org-variable-name">node</span>) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">Execute the TensorFlow Ops sequentially.</span>
    <span class="org-keyword">for</span> (<span class="org-keyword">auto</span>&amp; <span class="org-variable-name">node_data</span> : op_data_-&gt;nodes) {
        TFLITE_SCOPED_DELEGATE_OPERATOR_PROFILE(
            <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-type">Profiler</span>*&gt;(context-&gt;profiler),
            node_data-&gt;name().c_str(), node_data-&gt;index());

        <span class="org-comment-delimiter">// </span><span class="org-comment">node_data-&gt;name() &#26159;&#31867;&#20284;&#20110; Abs &#36825;&#26679;&#30340; string</span>
        <span class="org-keyword">auto</span> <span class="org-variable-name">status</span> = ExecuteFlexOp(context, buffer_map, node_data.get());
        TF_LITE_ENSURE_OK(context, ConvertStatus(context, status));
    }
}

<span class="org-constant">tensorflow</span>::<span class="org-type">Status</span> <span class="org-function-name">InitializeNodeDef</span>(<span class="org-keyword">const</span> <span class="org-type">void</span>* <span class="org-variable-name">custom_initial_data</span>,
                                     <span class="org-type">int</span> <span class="org-variable-name">custom_initial_data_size</span>) {
    <span class="org-keyword">const</span> <span class="org-constant">flexbuffers</span>::<span class="org-type">Vector</span>&amp; <span class="org-variable-name">v</span> =
            <span class="org-constant">flexbuffers</span>::GetRoot(
                <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-keyword">const</span> <span class="org-type">uint8_t</span>*&gt;(custom_initial_data),
                custom_initial_data_size)
            .AsVector();

    name_ = v[0].AsString().str();
}

<span class="org-type">TfLiteStatus</span> <span class="org-constant">DelegateKernel</span>::<span class="org-function-name">Init</span>(<span class="org-type">TfLiteContext</span>* <span class="org-variable-name">context</span>,
                                  <span class="org-keyword">const</span> <span class="org-type">TfLiteDelegateParams</span>* <span class="org-variable-name">params</span>) {

    <span class="org-keyword">for</span> (<span class="org-keyword">auto</span> <span class="org-variable-name">node_index</span> : TfLiteIntArrayView(params-&gt;nodes_to_replace)) {
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! custom_initial_data</span>
        status = node_data.InitializeNodeDef(node-&gt;custom_initial_data,
                                             node-&gt;custom_initial_data_size);
    }
}

<span class="org-type">TfLiteStatus</span> <span class="org-constant">Subgraph</span>::<span class="org-function-name">AddNodeWithParameters</span>(
    <span class="org-keyword">const</span> <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt;&amp; <span class="org-variable-name">inputs</span>, <span class="org-keyword">const</span> <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt;&amp; <span class="org-variable-name">outputs</span>,
    <span class="org-keyword">const</span> <span class="org-constant">std</span>::<span class="org-type">vector</span>&lt;<span class="org-type">int</span>&gt;&amp; <span class="org-variable-name">intermediates</span>, <span class="org-keyword">const</span> <span class="org-type">char</span>* <span class="org-variable-name">init_data</span>,
    <span class="org-type">size_t</span> <span class="org-variable-name">init_data_size</span>, <span class="org-type">void</span>* <span class="org-variable-name">builtin_data</span>,
    <span class="org-keyword">const</span> <span class="org-type">TfLiteRegistration</span>* <span class="org-variable-name">registration</span>, <span class="org-type">int</span>* <span class="org-variable-name">node_index</span>) {
    <span class="org-keyword">if</span> (registration-&gt;builtin_code == BuiltinOperator_CUSTOM) {
        <span class="org-comment-delimiter">// </span><span class="org-comment">When it's a CUSTOM op, the `custom_options` field in the Flatbuffer</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">`Operator` table is passed in.</span>
        <span class="org-comment-delimiter">// </span><span class="org-comment">!!! init_data</span>
        node.custom_initial_data = init_data;
        node.custom_initial_data_size = init_data_size;
    } <span class="org-keyword">else</span> {
        node.custom_initial_data = <span class="org-constant">nullptr</span>;
        node.custom_initial_data_size = 0;
    }
}

<span class="org-type">TfLiteStatus</span> <span class="org-constant">InterpreterBuilder</span>::<span class="org-function-name">ParseNodes</span>(
    <span class="org-keyword">const</span> <span class="org-constant">flatbuffers</span>::<span class="org-type">Vector</span>&lt;<span class="org-constant">flatbuffers</span>::<span class="org-type">Offset</span>&lt;Operator&gt;&gt;* <span class="org-variable-name">operators</span>,
    <span class="org-type">Subgraph</span>* <span class="org-variable-name">subgraph</span>) {
    <span class="org-keyword">if</span> (op_type == BuiltinOperator_CUSTOM) {
        <span class="org-keyword">if</span> (op-&gt;custom_options()) {
            subgraph-&gt;AddNodeWithParameters(
                FlatBufferIntArrayToVector(op-&gt;inputs()),
                FlatBufferIntArrayToVector(op-&gt;outputs()),
                FlatBufferIntArrayToVector(op-&gt;intermediates()),
                <span class="org-comment-delimiter">// </span><span class="org-comment">!!! custom_options()-&gt;data</span>
                <span class="org-keyword">reinterpret_cast</span>&lt;<span class="org-keyword">const</span> <span class="org-type">char</span>*&gt;(op-&gt;custom_options()-&gt;data()),
                op-&gt;custom_options()-&gt;size(), <span class="org-constant">nullptr</span>, registration);
        }
}
</pre>
</div>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org0000058" class="outline-5">
<h5 id="org0000058"><span class="section-number-5">1.2.7.3</span> edge tpu</h5>
<div class="outline-text-5" id="text-1-2-7-3">
<p>
edge tpu 的支持并不是通过 delegate, 而是需要用 edgetpu_compiler 把最初的 tflite
文件转换一下, 把其中 edge tpu 支持的操作封装到一个 custom op (edgetpu-custom-op)
中, 并输出另一个 tflite 文件
</p>

<p>
运行时反 libedgetpu 链接进来, 同时通过 AddCustom 注册 edgetpu 使用的 custom op:
</p>

<div class="org-src-container">
<pre class="src src-c++">resolver.AddCustom(<span class="org-constant">edgetpu</span>::kCustomOp, <span class="org-constant">edgetpu</span>::RegisterCustomOp());                                                                          
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-org0000061" class="outline-3">
<h3 id="org0000061"><span class="section-number-3">1.3</span> </h3>
</div>

<div id="outline-container-org0000064" class="outline-3">
<h3 id="org0000064"><span class="section-number-3">1.4</span> <a href="tflite_quantization_detail.html#org0000027">TFLite Quantization Details</a></h3>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2020-07-28 Tue 00:00<br />
Last updated: 2022-04-02 Sat 16:43</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
