<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>GNN</title>


           <link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
           <link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
           <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
           <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
           <script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
           <script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
           <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
           <link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
           <link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
           <link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
           <link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">GNN</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0000058">1. GNN</a>
<ul>
<li><a href="#org0000000">1.1. Overview</a></li>
<li><a href="#org000002f">1.2. Dataset</a>
<ul>
<li><a href="#org0000003">1.2.1. Overview</a></li>
<li><a href="#org0000024">1.2.2. TUDataset</a></li>
<li><a href="#org0000028">1.2.3. Cora Dataset</a></li>
<li><a href="#org000002c">1.2.4. pyg dataset api</a></li>
</ul>
</li>
<li><a href="#org000003b">1.3. GCN Example</a>
<ul>
<li><a href="#org0000032">1.3.1. Model</a></li>
<li><a href="#org0000035">1.3.2. Train</a></li>
<li><a href="#org0000038">1.3.3. GCN for Classification</a></li>
</ul>
</li>
<li><a href="#org0000045">1.4. GCN Details</a>
<ul>
<li><a href="#org000003f">1.4.1. GCN Layer</a></li>
<li><a href="#org0000042">1.4.2. MessagePassing</a></li>
</ul>
</li>
<li><a href="#org000004c">1.5. Graph Sampling</a>
<ul>
<li><a href="#org0000049">1.5.1. GraphSage</a></li>
</ul>
</li>
<li><a href="#org0000055">1.6. Embedding</a>
<ul>
<li><a href="#org000004f">1.6.1. DeepWalk</a></li>
<li><a href="#org0000052">1.6.2. Graph2Vec</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000058" class="outline-2">
<h2 id="org0000058"><span class="section-number-2">1.</span> GNN</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="https://arxiv.org/pdf/1609.02907.pdf">https://arxiv.org/pdf/1609.02907.pdf</a> 2017/2
</p>

<p>
<a href="https://distill.pub/2021/gnn-intro/">https://distill.pub/2021/gnn-intro/</a>
</p>

<p>
<a href="https://pytorch-geometric.readthedocs.io/en/latest/">https://pytorch-geometric.readthedocs.io/en/latest/</a>
</p>
</div>

<div id="outline-container-org0000000" class="outline-3">
<h3 id="org0000000"><span class="section-number-3">1.1.</span> Overview</h3>
<div class="outline-text-3" id="text-1-1">
<p>
相比于 vector 和 matrix, graph 是更一般化的数据结构, 例如用 graph 可以表示
matrix 但反过来不行.
</p>

<p>
图虽然可以用邻接矩阵 (adjacency matrix) 表示, 但不表示 graph 与矩阵是等价的, 因为邻接矩阵并不像普通的矩阵 (例如图像) 那样存在空间结构. 因为图本身是无序的, 对于
n 个 node 的图, 通过修改 node 在邻接矩阵中的索引, 可以构造成 \(n!\) 个邻接矩阵.
</p>

<p>
所以适用于图像的 conv2d 并不能直接应用于 graph, 需要有新的方法.
</p>

<p>
GNN 适用的领域主要包括:
</p>

<ol class="org-ol">
<li>蛋白质结构</li>
<li>社交网络</li>
<li>推荐系统</li>
<li>&#x2026;</li>
</ol>
</div>
</div>

<div id="outline-container-org000002f" class="outline-3">
<h3 id="org000002f"><span class="section-number-3">1.2.</span> Dataset</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org0000003" class="outline-4">
<h4 id="org0000003"><span class="section-number-4">1.2.1.</span> Overview</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
dataset 会包含如下信息:
</p>

<ol class="org-ol">
<li>node 信息 (feature, label)</li>

<li>edge 信息 (feature, label)</li>

<li>graph 信息 (feature, label)</li>

<li>connectivity 信息</li>
</ol>

<p>
以上信息中, connectivity 是必需的, 其它数据可能会缺少. 例如:
</p>

<p>
TUDataset 的 ENZYMES 数据集: 没有 edge 相关的信息, 也没有 graph 的 feature
(attribute) 信息, 因为 ENZYMES 数据集主要是通过 node 和 connectivity 信息对
graph 的 label 进行预测
</p>
</div>
</div>

<div id="outline-container-org0000024" class="outline-4">
<h4 id="org0000024"><span class="section-number-4">1.2.2.</span> TUDataset</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
以 TUDataset 的 ENZYMES 数据集为例:
</p>

<p>
<a href="http://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip">http://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip</a>
</p>

<ol class="org-ol">
<li>ENZYMES 是一个 `graph focused` 的数据集, 即它是为了对 graph 进行分类. 除此以外,还有 `node focused` (对 node 进行分类)</li>

<li>一个有 600 个 graph, 记为 N</li>

<li>graph 分为 6 类, 表示 6 种不同类型的酶 (如裂解酶, 转移酶, 连接酶&#x2026;)</li>

<li>一共 19580 个 node, 记为 n, node 的 label 表示它是酶的某种组成部分 (可能指的是氨基, 羧基, 羟基等)</li>

<li>一共 74564 条边, 记为 m, 因为每条边用了两条有向边表示, 所以实际是 74564/2 条无向边,</li>
</ol>

<pre class="example" id="org0000006">
├── ENZYMES_A.txt
├── ENZYMES_graph_indicator.txt
├── ENZYMES_graph_labels.txt
├── ENZYMES_node_attributes.txt
├── ENZYMES_node_labels.txt
</pre>
</div>

<div id="outline-container-org0000008" class="outline-5">
<h5 id="org0000008"><span class="section-number-5">1.2.2.1.</span> A.txt</h5>
<div class="outline-text-5" id="text-1-2-2-1">
<p>
用邻接表 (Adjacency List) 形式保存的各个 node 的连接信息, 共 m 行
</p>

<pre class="example" id="org0000007">
2, 1
3, 1
4, 1
1, 2
...
</pre>
</div>
</div>

<div id="outline-container-org000000c" class="outline-5">
<h5 id="org000000c"><span class="section-number-5">1.2.2.2.</span> graph_indicator.txt</h5>
<div class="outline-text-5" id="text-1-2-2-2">
<p>
每个 node 所属的 graph, 共 n 行
</p>

<pre class="example" id="org000000b">
1
1
...
2
2
...
</pre>
</div>
</div>

<div id="outline-container-org0000010" class="outline-5">
<h5 id="org0000010"><span class="section-number-5">1.2.2.3.</span> graph_labels.txt</h5>
<div class="outline-text-5" id="text-1-2-2-3">
<p>
每个 graph 所属的 labe, 共 N 行, 有 1,2,3,4,5,6 共 6 种值, 表示不同功能的酶.
</p>

<pre class="example" id="org000000f">
6
6
6
...
</pre>
</div>
</div>

<div id="outline-container-org0000014" class="outline-5">
<h5 id="org0000014"><span class="section-number-5">1.2.2.4.</span> node_attributes.txt</h5>
<div class="outline-text-5" id="text-1-2-2-4">
<p>
每个 node 的属性, 共 n 行, 每行为 18 个值, 不清楚具体是什么意义.
</p>

<pre class="example" id="org0000013">
11.000000, 15.887014, 37.780000, -0.510000,  1.701000, 93.900000,  4.000000,  5.000000,  2.000000,  4.000000,  4.000000,  3.000000,  3.000000,  4.000000,  4.000000,  3.000000,  6.000000,  2.000000
11.000000, 16.362935, 40.380000, -2.030000,  1.777000,102.600000,  2.000000,  7.000000,  2.000000,  6.000000,  2.000000,  3.000000,  3.000000,  2.000000,  6.000000,  1.000000,  8.000000,  2.000000
16.000000, 21.395072, 63.350000,  2.040000,  2.981000,136.000000,  2.000000,  7.000000,  7.000000,  6.000000,  4.000000,  6.000000,  6.000000,  2.000000,  8.000000,  2.000000,  7.000000,  7.000000
...
</pre>
</div>
</div>

<div id="outline-container-org0000018" class="outline-5">
<h5 id="org0000018"><span class="section-number-5">1.2.2.5.</span> node_labels.txt</h5>
<div class="outline-text-5" id="text-1-2-2-5">
<p>
每个 node 的 labe, 共 n 行, 有 1, 2, 3 共 3 种值, 表示 3 种不同的官能团?
</p>

<pre class="example" id="org0000017">
1
1
1
...
</pre>
</div>
</div>

<div id="outline-container-org000001b" class="outline-5">
<h5 id="org000001b"><span class="section-number-5">1.2.2.6.</span> edge_labels.txt</h5>
<div class="outline-text-5" id="text-1-2-2-6">
<p>
n 行, 表示 edge 的 label. ENZYMES dataset 不包含这一项
</p>
</div>
</div>

<div id="outline-container-org000001e" class="outline-5">
<h5 id="org000001e"><span class="section-number-5">1.2.2.7.</span> edge_attributes.txt</h5>
<div class="outline-text-5" id="text-1-2-2-7">
<p>
n 行, 表示 edge 的 attribute. ENZYMES dataset 不包含这一项
</p>
</div>
</div>

<div id="outline-container-org0000021" class="outline-5">
<h5 id="org0000021"><span class="section-number-5">1.2.2.8.</span> graph_attributes.txt</h5>
<div class="outline-text-5" id="text-1-2-2-8">
<p>
N 行, 表示 graph 的 attribute. ENZYMES dataset 不包含这一项
</p>
</div>
</div>
</div>

<div id="outline-container-org0000028" class="outline-4">
<h4 id="org0000028"><span class="section-number-4">1.2.3.</span> Cora Dataset</h4>
<div class="outline-text-4" id="text-1-2-3">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">from</span> torch_geometric.datasets <span class="org-keyword">import</span> Planetoid

<span class="org-variable-name">dataset</span> = Planetoid(root=<span class="org-string">'/tmp/Cora'</span>, name=<span class="org-string">'Cora'</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{<span class="org-builtin">len</span>(dataset)}<span class="org-string"> graph"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{dataset.num_classes}<span class="org-string"> classes"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{dataset.num_node_features}<span class="org-string"> node features"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{dataset.num_edge_features}<span class="org-string"> edge features"</span>)
<span class="org-builtin">print</span>(<span class="org-string">"--- graph[0] ---"</span>)
<span class="org-variable-name">data</span> = dataset[0]
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{data.num_nodes}<span class="org-string"> nodes"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{data.num_edges}<span class="org-string"> edges"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"x: </span>{data.x.shape}<span class="org-string"> "</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"y: </span>{data.y.shape}<span class="org-string"> "</span>)

</pre>
</div>

<pre class="example" id="org0000027">
1 graph
7 classes
1433 node features
0 edge features
--- graph[0] ---
2708 nodes
10556 edges
x: torch.Size([2708, 1433]) 
y: torch.Size([2708]) 
</pre>

<p>
cora 是 `node focused` (对 node 进行分类)
</p>

<ol class="org-ol">
<li>包含一个 graph</li>
<li>2708 个 node 代表 2708 篇论文</li>
<li>node 的 feature[i] 代表是论文是否包含 keywords[i], keywords 一共 1433 个</li>
<li>node 的 label 代表论文属于 7 个 class 中哪一个:

<ol class="org-ol">
<li>Case_Based</li>
<li>Genetic_Algorithms</li>
<li>Neural_Networks</li>
<li>Probabilistic_Methods</li>
<li>Reinforcement_Learning</li>
<li>Rule_Learning</li>
<li>Theory</li>
</ol></li>
</ol>
</div>
</div>


<div id="outline-container-org000002c" class="outline-4">
<h4 id="org000002c"><span class="section-number-4">1.2.4.</span> pyg dataset api</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
pytorch-geometric 通过 Data 来封装 graph
</p>

<ul class="org-ul">
<li>data.x 表示 node 的 feature, [num_nodes, num_node_features]</li>
<li>data.edge_index, 表示邻接表 [2, num_edges]</li>
<li>data.edge_attr, 表示 edge feature, [num_edges, num_edge_features]</li>
<li>data.y 表示 graph label, [1, *] (即 graph focused) 或 node label, [num_nodes,
*] (即 node focused)</li>
</ul>

<p>
例如:
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> torch
<span class="org-keyword">from</span> torch_geometric.data <span class="org-keyword">import</span> Data

<span class="org-variable-name">edge_index</span> = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.<span class="org-builtin">long</span>)

<span class="org-variable-name">x</span> = torch.tensor([[-1], [0], [1]], dtype=torch.<span class="org-builtin">float</span>)
<span class="org-variable-name">data</span> = Data(x=x, edge_index=edge_index)
</pre>
</div>

<p>
使用 TUDataset 解析 tudataset:
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">from</span> torch_geometric.datasets <span class="org-keyword">import</span> TUDataset
<span class="org-variable-name">dataset</span> = TUDataset(root=<span class="org-string">'/tmp/ENZYMES'</span>, name=<span class="org-string">'ENZYMES'</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{<span class="org-builtin">len</span>(dataset)}<span class="org-string"> graph"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{dataset.num_classes}<span class="org-string"> classes"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{dataset.num_node_features}<span class="org-string"> node features"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"  </span>{dataset.num_node_labels}<span class="org-string"> node labels"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"  </span>{dataset.num_node_attributes}<span class="org-string"> node attributes"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{dataset.num_edge_features}<span class="org-string"> edge features"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"  </span>{dataset.num_edge_labels}<span class="org-string"> edge labels"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"  </span>{dataset.num_edge_attributes}<span class="org-string"> edge attributes"</span>)
<span class="org-builtin">print</span>(<span class="org-string">"--- graph[0] ---"</span>)
<span class="org-variable-name">data</span> = dataset[0]
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{data.num_nodes}<span class="org-string"> nodes"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{data.num_edges}<span class="org-string"> edges"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"first 5 edges: </span><span class="org-constant">\n</span>{data.edge_index[:,:5]}<span class="org-string"> "</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">data.x &#30340; shape &#20026; [:,3], &#23427;&#26159; ndoe label &#30340; one-hot &#32534;&#30721;</span>
<span class="org-builtin">print</span>(f<span class="org-string">"first 5 x:</span><span class="org-constant">\n</span>{data.x[:5,:]}<span class="org-string"> "</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"y:</span><span class="org-constant">\n</span>{data.y}<span class="org-string">"</span>)

<span class="org-comment-delimiter"># </span><span class="org-comment">TUDataset &#30340;&#26500;&#36896;&#20989;&#25968;&#25509;&#21463;&#19968;&#20010; use_node_attr/use_edge_attr &#21442;&#25968;, data.x &#26159;&#21542;&#21253;&#21547;</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">{node,edge}_attributes.txt &#25968;&#25454;</span>
<span class="org-variable-name">dataset</span> = TUDataset(root=<span class="org-string">'/tmp/ENZYMES'</span>, name=<span class="org-string">'ENZYMES'</span>, use_node_attr = <span class="org-constant">True</span>)
<span class="org-builtin">print</span>(<span class="org-string">"---use_node_attr---"</span>)
<span class="org-builtin">print</span>(f<span class="org-string">"</span>{dataset.num_node_attributes}<span class="org-string"> node attributes"</span>)
<span class="org-variable-name">data</span> = dataset[0]
<span class="org-builtin">print</span>(f<span class="org-string">"data.x shape: </span>{data.x.shape[1]}<span class="org-string">=</span>{dataset.num_node_attributes}<span class="org-string">+3"</span>)
</pre>
</div>

<pre class="example" id="org000002b">
600 graph
6 classes
3 node features
  3 node labels
  0 node attributes
0 edge features
  0 edge labels
  0 edge attributes
--- graph[0] ---
37 nodes
168 edges
first 5 edges: 
tensor([[0, 0, 0, 1, 1],
        [1, 2, 3, 0, 2]]) 
first 5 x:
tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]]) 
y:
tensor([5])
---use_node_attr---
18 node attributes
data.x shape: 21=18+3
</pre>

<p>
根据 pyg 的 tu_dataset.py 的代码 (torch_geometric/datasets/tu_dataset.py),
data.x 实际上是 node label 的 one-hot 编码 (如果使用了 use_node_attr, 还会有
node attribute), data.y 是 graph label. 因为 ENZYMES 数据集主要是根据 node label
(氨基,羧基,羟基?) 及其连接关系对 graph 进行分类 (裂解酶, 转移酶, 连接酶&#x2026;)
</p>
</div>
</div>
</div>


<div id="outline-container-org000003b" class="outline-3">
<h3 id="org000003b"><span class="section-number-3">1.3.</span> GCN Example</h3>
<div class="outline-text-3" id="text-1-3">
<p>
gcn 是 gnn 的一种方法, 另外还有 gat, deepwalk, graph_sage 等, 这些算法都有些类似,不同点主要在于如何去做 aggregation: 例如
</p>

<ol class="org-ol">
<li>gcn 以 node degree 做权重进行 sum aggregation</li>

<li>gat 会使用 attention score 做权重</li>
</ol>
</div>

<div id="outline-container-org0000032" class="outline-4">
<h4 id="org0000032"><span class="section-number-4">1.3.1.</span> Model</h4>
<div class="outline-text-4" id="text-1-3-1">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> torch
<span class="org-keyword">import</span> torch.nn.functional <span class="org-keyword">as</span> F
<span class="org-keyword">from</span> torch_geometric.nn <span class="org-keyword">import</span> GCNConv

<span class="org-keyword">class</span> <span class="org-type">Net</span>(torch.nn.Module):
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>):
        <span class="org-builtin">super</span>(Net, <span class="org-keyword">self</span>).__init__()
        <span class="org-keyword">self</span>.<span class="org-variable-name">conv1</span> = GCNConv(dataset.num_node_features, 16)
        <span class="org-keyword">self</span>.<span class="org-variable-name">conv2</span> = GCNConv(16, dataset.num_classes)

    <span class="org-keyword">def</span> <span class="org-function-name">forward</span>(<span class="org-keyword">self</span>, data):
        <span class="org-variable-name">x</span>, <span class="org-variable-name">edge_index</span> = data.x, data.edge_index

        <span class="org-variable-name">x</span> = <span class="org-keyword">self</span>.conv1(x, edge_index)
        <span class="org-variable-name">x</span> = F.relu(x)
        <span class="org-variable-name">x</span> = F.dropout(x, training=<span class="org-keyword">self</span>.training)
        <span class="org-variable-name">x</span> = <span class="org-keyword">self</span>.conv2(x, edge_index)

        <span class="org-keyword">return</span> F.log_softmax(x, dim=1)
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000035" class="outline-4">
<h4 id="org0000035"><span class="section-number-4">1.3.2.</span> Train</h4>
<div class="outline-text-4" id="text-1-3-2">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">model</span> = Net()
<span class="org-variable-name">data</span> = dataset[0]
<span class="org-variable-name">optimizer</span> = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

model.train()
<span class="org-keyword">for</span> epoch <span class="org-keyword">in</span> <span class="org-builtin">range</span>(50):
    optimizer.zero_grad()
    <span class="org-variable-name">out</span> = model(data)
    <span class="org-variable-name">loss</span> = F.nll_loss(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()

model.<span class="org-builtin">eval</span>()
<span class="org-variable-name">_</span>, <span class="org-variable-name">pred</span> = model(data).<span class="org-builtin">max</span>(dim=1)
<span class="org-variable-name">correct</span> = <span class="org-builtin">float</span>(pred[data.test_mask].eq(data.y[data.test_mask]).<span class="org-builtin">sum</span>().item())
<span class="org-variable-name">acc</span> = correct / data.test_mask.<span class="org-builtin">sum</span>().item()
<span class="org-builtin">print</span>(<span class="org-string">'Accuracy: {:.4f}'</span>.<span class="org-builtin">format</span>(acc))

</pre>
</div>

<p>
Accuracy: 0.7970
</p>
</div>
</div>

<div id="outline-container-org0000038" class="outline-4">
<h4 id="org0000038"><span class="section-number-4">1.3.3.</span> GCN for Classification</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
如上面的例子所示, gcn 总是针对 node 做 feature 的变换, 它不会改变图的结构. 那如何让它处理 ENZYMES 数据集, 即能输出一个和 node 无关的 global classification?
</p>

<p>
一种方法是加入一个 global node, 这个 node 和所有 node 相连, 训练时只针对这个
node 计算 loss
</p>

<p>
另一种方法是用 global pooling, 类似于图片上的 <a href="dynamic_shaped_network.html#ID-f70d117b-3974-43d2-b082-a08c58cc87f5">global average pooling</a>, 即把所有的
node 的值平均
</p>
</div>
</div>
</div>

<div id="outline-container-org0000045" class="outline-3">
<h3 id="org0000045"><span class="section-number-3">1.4.</span> GCN Details</h3>
<div class="outline-text-3" id="text-1-4">
<p>
gcn (Graph Conv) 从 api 上看有以下的特点:
</p>

<ol class="org-ol">
<li>gcn 不会修改 node 的连接关系 (edge_index)</li>

<li>gcn 不会修改 node 的个数</li>

<li>gcn 只会更新每个 node 的 feature, 所以 node feature 类似于 conv channel.</li>
</ol>

<p>
所以 gcn 工作时如下图所示, 每一层输出的图的形状是不变的.
</p>


<div id="org000003e" class="figure">
<p><img src="../extra/gcn.png" alt="gcn.png" />
</p>
</div>

<p>
实际上 gcn 做的和 conv 类似: 把 node a 和它的 neighbour node (b, c, d) 的数据汇聚 (aggregation) 在一起加以计算,做为 a 的输出.
</p>
</div>

<div id="outline-container-org000003f" class="outline-4">
<h4 id="org000003f"><span class="section-number-4">1.4.1.</span> GCN Layer</h4>
<div class="outline-text-4" id="text-1-4-1">
<p>
GCN Layer (<a href="https://arxiv.org/pdf/1609.02907.pdf">https://arxiv.org/pdf/1609.02907.pdf</a>) 定义了一种简单的 aggregation 的方法
</p>

<p>
\(\mathbf{x}_{i}^{(k)}=\sum_{j \in \mathcal{N}(i) \cup\{i\}} \frac{1}{\sqrt{\operatorname{deg}(i)} \cdot \sqrt{\operatorname{deg}(j)}} \cdot\left(\mathbf{\Theta}^{\top} \cdot \mathbf{x}_{j}^{(k-1)}\right)\)
</p>

<ul class="org-ul">
<li>\(\mathbf{x}_{i}^{(k)}\), 表示 node \(i\) 经过第 \(k\) 次 conv 的结果</li>

<li>\(j \in \mathcal{N}(i) \cup\{i\}\), 表示 \(i\) 和 \(i\) 的所有 neighbour node</li>

<li>\(\mathbf{\Theta}^{\top} \cdot \mathbf{x}_{j}^{(k-1)}\), \(j\) 先和一个矩阵相乘</li>

<li>\(\frac{1}{\sqrt{\operatorname{deg}(i)} \cdot \sqrt{\operatorname{deg}(j)}}\),
结果用 \(i\), \(j\) 的 degree 进行 normalize, degree 是指 node 的边数</li>

<li>\(\sum_{j \in \mathcal{N}(i) \cup\{i\}}\), 最后求和 (或者 max, average)</li>
</ul>
</div>
</div>

<div id="outline-container-org0000042" class="outline-4">
<h4 id="org0000042"><span class="section-number-4">1.4.2.</span> MessagePassing</h4>
<div class="outline-text-4" id="text-1-4-2">
<p>
gcn 在做 aggregation 时可以抽象为以下几步:
</p>

<ol class="org-ol">
<li>前面的 \(\mathbf{\Theta}^{\top} \cdot \mathbf{x}_{j}^{(k-1)}\), 以及计算
degree. 这些处理不需要查找 \(\mathcal{N}(i)\)</li>

<li>查找 \(j \in \mathcal{N}(i)\)</li>

<li>使用 \(x_i^{k-1}\), \(x_j^{k-1}\) 的信息进行计算得到 \(t_i^{k-1}\)</li>

<li>使用 max/sum/average 等针对 \(t_i^{k-1}\) 进行聚合得于 \(x_i^k\)</li>
</ol>

<p>
pyg 通过 MessagePassing 类对上面四步进行了抽象, 使得用户可以把精力放在 1, 3 两步上, 例如 gcn 可以写成:
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">class</span> <span class="org-type">GCNConv</span>(MessagePassing):
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>, in_channels, out_channels):
        <span class="org-builtin">super</span>().__init__(aggr=<span class="org-string">'add'</span>)  <span class="org-comment-delimiter"># </span><span class="org-comment">"Add" aggregation (Step 5).</span>
        <span class="org-keyword">self</span>.<span class="org-variable-name">lin</span> = torch.nn.Linear(in_channels, out_channels)

    <span class="org-keyword">def</span> <span class="org-function-name">forward</span>(<span class="org-keyword">self</span>, x, edge_index):
        <span class="org-comment-delimiter"># </span><span class="org-comment">x has shape [N, in_channels]</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">edge_index has shape [2, E]</span>

        <span class="org-comment-delimiter"># </span><span class="org-comment">Step 1: Add self-loops to the adjacency matrix.</span>
        <span class="org-variable-name">edge_index</span>, <span class="org-variable-name">_</span> = add_self_loops(edge_index, num_nodes=x.size(0))

        <span class="org-comment-delimiter"># </span><span class="org-comment">Step 2: Linearly transform node feature matrix.</span>
        <span class="org-variable-name">x</span> = <span class="org-keyword">self</span>.lin(x)

        <span class="org-comment-delimiter"># </span><span class="org-comment">Step 3: Compute normalization.</span>
        <span class="org-variable-name">row</span>, <span class="org-variable-name">col</span> = edge_index
        <span class="org-variable-name">deg</span> = degree(col, x.size(0), dtype=x.dtype)
        <span class="org-variable-name">deg_inv_sqrt</span> = deg.<span class="org-builtin">pow</span>(-0.5)
        <span class="org-variable-name">deg_inv_sqrt</span>[deg_inv_sqrt == <span class="org-builtin">float</span>(<span class="org-string">'inf'</span>)] = 0
        <span class="org-variable-name">norm</span> = deg_inv_sqrt[row] * deg_inv_sqrt[col]

        <span class="org-comment-delimiter"># </span><span class="org-comment">Step 4-5: Start propagating messages.</span>
        <span class="org-keyword">return</span> <span class="org-keyword">self</span>.propagate(edge_index, x=x, norm=norm)

    <span class="org-keyword">def</span> <span class="org-function-name">message</span>(<span class="org-keyword">self</span>, x_j, norm):
        <span class="org-comment-delimiter"># </span><span class="org-comment">x_j has shape [E, out_channels]</span>

        <span class="org-comment-delimiter"># </span><span class="org-comment">Step 4: Normalize node features.</span>
        <span class="org-keyword">return</span> norm.view(-1, 1) * x_j
</pre>
</div>

<p>
当用户主动调用 propagate 时, pyg 会自动做类似的动作:
</p>

<div class="org-src-container">
<pre class="src src-python">propagate()
  <span class="org-variable-name">j</span> = neighbour(i)
  <span class="org-variable-name">temp</span>[j] = message(x[j], ...)
  <span class="org-variable-name">x</span>[i] = <span class="org-builtin">max</span>(temp[j])
</pre>
</div>

<p>
forward () 和 message() 相当于需要用户实现的 1, 3 步.
</p>
</div>
</div>
</div>

<div id="outline-container-org000004c" class="outline-3">
<h3 id="org000004c"><span class="section-number-3">1.5.</span> Graph Sampling</h3>
<div class="outline-text-3" id="text-1-5">
<p>
以前面的 Cora 数据集上的 gcn 为例, 每次训练需要把整个 graph 都处理一遍, 相当于一个 epoch 需要处理所有的样本. 当 graph 中 node 很多时, 参数会更新的很慢且有可能内存不够.
</p>

<p>
graph sampling 是指通过对 node 采样降低网络规模
</p>
</div>

<div id="outline-container-org0000049" class="outline-4">
<h4 id="org0000049"><span class="section-number-4">1.5.1.</span> GraphSage</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
gcn 工作时以整个 graph 为输入 (它甚至包含没有 label 的 node), 并计算每个 node 的特征.
</p>

<p>
graphsage (Graph SAmple and aggreGatE) 工作时:
</p>

<ol class="org-ol">
<li>sample, 以单个 node A 为中心, 通过 k step 采样出固定个数的 node</li>

<li>aggregate k 次, 每次用不同的 aggregator.</li>

<li>predict 得到 A 的特征</li>
</ol>

<p>
整个过程和 mini-batch SGD 有些类似.
</p>


<div id="org0000048" class="figure">
<p><img src="../extra/graph_sage.png" alt="graph_sage.png" />
</p>
</div>

<p>
另外, GraphSage 被称为 inductive, 是指在 sample 时会忽略那些没有 label 的
neighbour, 这些 node 的特征和连接关系并不会参与到训练过程.
</p>

<p>
当 graph 加入一个新的 node 时, 以这个 node 为中心执行一次 graphsage 算法就可以得到 node 的特征. 而 gcn 需要针对新的 graph 重新训练才可以.
</p>
</div>
</div>
</div>

<div id="outline-container-org0000055" class="outline-3">
<h3 id="org0000055"><span class="section-number-3">1.6.</span> Embedding</h3>
<div class="outline-text-3" id="text-1-6">
<p>
embedding 是用无监督的方法获得低维的向量表示, 例如 <a href="word2vec.html#ID-164e18f2-14b2-486b-8e39-8c69d9f09bc1">Word2vec</a>
</p>

<p>
graph 上的 embedding 有两种:
</p>

<ol class="org-ol">
<li>node embedding, 即把单个 node 变成低维向量</li>

<li>graph embedding, 即把整个 graph 变成低维向量</li>
</ol>
</div>

<div id="outline-container-org000004f" class="outline-4">
<h4 id="org000004f"><span class="section-number-4">1.6.1.</span> DeepWalk</h4>
<div class="outline-text-4" id="text-1-6-1">
<p>
<a href="https://arxiv.org/pdf/1403.6652.pdf">https://arxiv.org/pdf/1403.6652.pdf</a> 2014/6
</p>

<p>
deepwalk 是一种 node embedding 算法
</p>

<ol class="org-ol">
<li>在 graph 上随机 walk, 得到一个 node 序列</li>

<li>在 node 序列上使用 <a href="word2vec.html#ID-9f70d896-fc3e-4135-a4f6-03fe25d36cfc">skip-gram</a> 得到 embedding</li>
</ol>
</div>
</div>

<div id="outline-container-org0000052" class="outline-4">
<h4 id="org0000052"><span class="section-number-4">1.6.2.</span> Graph2Vec</h4>
<div class="outline-text-4" id="text-1-6-2">
<p>
<a href="https://arxiv.org/pdf/1707.05005.pdf">https://arxiv.org/pdf/1707.05005.pdf</a> 2017/6
</p>

<p>
graph2vec 是一种 graph embedding 算法
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway@dogdog.run<br />
Date: 2022-01-29 Sat 13:49<br />
Last updated: 2022-07-17 Sun 11:39</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
