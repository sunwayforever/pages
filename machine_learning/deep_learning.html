<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-01-25 二 15:53 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Deep Learning</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Wei Sun (孙伟)" />
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Deep Learning</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org4d51d34">1. Deep Learning</a>
<ul>
<li><a href="#orgd1a3514">1.1. linear regression</a>
<ul>
<li><a href="#org662357a">1.1.1. training set</a></li>
<li><a href="#org664e0b4">1.1.2. feature &amp; label</a></li>
<li><a href="#org93fc025">1.1.3. regression</a></li>
<li><a href="#org7beae77">1.1.4. hypothesis function</a></li>
<li><a href="#org7858784">1.1.5. cost function</a></li>
<li><a href="#orgbdfb176">1.1.6. mean square errno</a></li>
<li><a href="#orga6db070">1.1.7. gradient decent</a></li>
<li><a href="#org5b93533">1.1.8. partial derivative</a></li>
<li><a href="#org6bf1459">1.1.9. simple linear regression example</a></li>
<li><a href="#org17cd8da">1.1.10. gradient checking</a></li>
<li><a href="#org234bd42">1.1.11. learning rate</a></li>
<li><a href="#org072b0c5">1.1.12. feature scaling</a></li>
</ul>
</li>
<li><a href="#org6ac8c60">1.2. multi-feature linear regression</a>
<ul>
<li><a href="#org986b523">1.2.1. feature &amp; label</a></li>
<li><a href="#org28a2899">1.2.2. learning rate</a></li>
</ul>
</li>
<li><a href="#org29d7e36">1.3. logistic regression</a>
<ul>
<li><a href="#org3170b85">1.3.1. feature &amp; label</a></li>
<li><a href="#org50abcee">1.3.2. regression</a></li>
<li><a href="#orgfa6945c">1.3.3. hypothesis function</a></li>
<li><a href="#org40f99e2">1.3.4. sigmoid</a></li>
<li><a href="#org03fe3d3">1.3.5. cost function</a></li>
<li><a href="#org079c337">1.3.6. cross entropy</a></li>
<li><a href="#org6034eab">1.3.7. partial derivative</a></li>
</ul>
</li>
<li><a href="#org7c80543">1.4. $\frac{\partial}{&part;{W}}J(W,B)</a>
<ul>
<li><a href="#orgac7cd42">1.4.1. logistic regression example</a></li>
<li><a href="#org9d410a8">1.4.2. polynormial features</a></li>
<li><a href="#org29dee04">1.4.3. underfitting &amp; overfitting</a></li>
<li><a href="#orgc1b04eb">1.4.4. regularization</a></li>
</ul>
</li>
<li><a href="#orgb40856e">1.5. multi-class logistic regression</a>
<ul>
<li><a href="#orgf6f26b8">1.5.1. training set</a></li>
<li><a href="#org586e501">1.5.2. one\_hot</a></li>
<li><a href="#org51f3b38">1.5.3. softmax</a></li>
<li><a href="#orgeefc0b5">1.5.4. partial derivative</a></li>
<li><a href="#orgd2b7b5e">1.5.5. load\_digits logistic regression example</a></li>
</ul>
</li>
<li><a href="#orgf733ade">1.6. artificial neural networks</a>
<ul>
<li><a href="#orgf584438">1.6.1. activation function</a></li>
<li><a href="#orge4e857f">1.6.2. relu</a></li>
<li><a href="#orgdf9bd18">1.6.3. forward propergation</a></li>
<li><a href="#orgd384c36">1.6.4. backward propergation</a></li>
<li><a href="#orgef3cd05">1.6.5. make\_moon ANN example</a></li>
<li><a href="#orga0b9876">1.6.6. gradient checking</a></li>
<li><a href="#orgeb0519c">1.6.7. ANN underfitting</a></li>
<li><a href="#org5b92140">1.6.8. ANN overfitting</a></li>
<li><a href="#org60a7195">1.6.9. load\_digits ANN example</a></li>
</ul>
</li>
<li><a href="#org9f5e089">1.7. What's Next</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org4d51d34" class="outline-2">
<h2 id="org4d51d34"><span class="section-number-2">1</span> Deep Learning</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-orgd1a3514" class="outline-3">
<h3 id="orgd1a3514"><span class="section-number-3">1.1</span> linear regression</h3>
<div class="outline-text-3" id="text-1-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">import</span> matplotlib.pyplot <span style="color: #859900;">as</span> plt
<span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np

<span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = 0<span style="color: #757575;">,</span> 0
<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> X<span style="color: #757575;">,</span>Y
    <span style="color: #268bd2;">data</span> = np.loadtxt<span style="color: #757575;">(</span><span style="color: #2aa198;">"../extra/data.txt"</span><span style="color: #757575;">,</span> delimiter=<span style="color: #2aa198;">","</span><span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = data[:<span style="color: #757575;">,</span> 0].reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = data[:<span style="color: #757575;">,</span> 1].reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>

get_training_set<span style="color: #757575;">()</span>
plt.scatter<span style="color: #757575;">(</span>x=X[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> y=Y[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">)</span>
plt.show<span style="color: #757575;">()</span>
</pre>
</div>


<div id="org3b7dddd" class="figure">
<p><img src="machine_learning_files/machine_learning_1_0.png" alt="machine_learning_1_0.png" />
</p>
<p><span class="figure-number">Figure 1: </span>png</p>
</div>
</div>

<div id="outline-container-org662357a" class="outline-4">
<h4 id="org662357a"><span class="section-number-4">1.1.1</span> training set</h4>
<div class="outline-text-4" id="text-1-1-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"X:"</span><span style="color: #757575;">,</span>X[:10]<span style="color: #757575;">)</span>
<span style="color: #859900;">print</span><span style="color: #757575;">()</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"Y:"</span><span style="color: #757575;">,</span>Y[:10]<span style="color: #757575;">)</span>
</pre>
</div>

<pre class="example" id="org7270ad0">
X: [[6.1101]
 [5.5277]
 [8.5186]
 [7.0032]
 [5.8598]
 [8.3829]
 [7.4764]
 [8.5781]
 [6.4862]
 [5.0546]]

Y: [[17.592 ]
 [ 9.1302]
 [13.662 ]
 [11.854 ]
 [ 6.8233]
 [11.886 ]
 [ 4.3483]
 [12.    ]
 [ 6.5987]
 [ 3.8166]]
</pre>
</div>
</div>

<div id="outline-container-org664e0b4" class="outline-4">
<h4 id="org664e0b4"><span class="section-number-4">1.1.2</span> feature &amp; label</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
X is a matrix of <code>features</code>
</p>

<p>
Y is a matrix of <code>labels</code>
</p>
</div>
</div>

<div id="outline-container-org93fc025" class="outline-4">
<h4 id="org93fc025"><span class="section-number-4">1.1.3</span> regression</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
给定一个 training set 中不存在的 x, 例如 <code>5.2</code>, 如何预测它对应的 y?
</p>
</div>
</div>

<div id="outline-container-org7beae77" class="outline-4">
<h4 id="org7beae77"><span class="section-number-4">1.1.4</span> hypothesis function</h4>
<div class="outline-text-4" id="text-1-1-4">
<p>
\(\hat{y}=h(x)=Wx+B\)
</p>

<p>
W ~ <code>weights</code>
</p>

<p>
B ~ <code>Bias</code>
</p>

<div class="org-src-container">
<pre class="src src-python">get_training_set<span style="color: #757575;">()</span>
plt.scatter<span style="color: #757575;">(</span>x=X[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> y=Y[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">)</span>
<span style="color: #268bd2;">W</span>=0.2
<span style="color: #268bd2;">B</span>=8
<span style="color: #268bd2;">x</span>=np.arange<span style="color: #757575;">(</span>5<span style="color: #757575;">,</span>22.5<span style="color: #757575;">,</span>0.1<span style="color: #757575;">)</span>
plt.plot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span> np.dot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span>W<span style="color: #757575;">)</span>+B<span style="color: #757575;">,</span>label=<span style="color: #2aa198;">"bad"</span><span style="color: #757575;">,</span> <span style="color: #757575;">)</span>
<span style="color: #268bd2;">W</span>=1.18
<span style="color: #268bd2;">B</span>=-3.79
plt.plot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span> np.dot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span>W<span style="color: #757575;">)</span>+B<span style="color: #757575;">,</span>label=<span style="color: #2aa198;">"good"</span><span style="color: #757575;">)</span>
plt.legend<span style="color: #757575;">()</span>
plt.show<span style="color: #757575;">()</span>
</pre>
</div>


<div id="org9f3081a" class="figure">
<p><img src="machine_learning_files/machine_learning_10_0.png" alt="machine_learning_10_0.png" />
</p>
<p><span class="figure-number">Figure 2: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org7858784" class="outline-4">
<h4 id="org7858784"><span class="section-number-4">1.1.5</span> cost function</h4>
<div class="outline-text-4" id="text-1-1-5">
<p>
使用 cost function 来衡量 hypothesis function 是否足够好, cost function
值越小， hypothesis function 越好
</p>
</div>
</div>

<div id="outline-container-orgbdfb176" class="outline-4">
<h4 id="orgbdfb176"><span class="section-number-4">1.1.6</span> mean square errno</h4>
<div class="outline-text-4" id="text-1-1-6">
<p>
\(J(W,B)=\frac{1}{2m}\sum\limits_{i=1}^{m}(\hat{y^i}-y^i)^2\)
</p>
</div>
</div>

<div id="outline-container-orga6db070" class="outline-4">
<h4 id="orga6db070"><span class="section-number-4">1.1.7</span> gradient decent</h4>
<div class="outline-text-4" id="text-1-1-7">
<p>
gradient decent
</p>

<p>
$ W &rarr; W-&alpha;\frac{\partial}{&part;{W}}J(W,B) $
</p>

<p>
$ B &rarr; B-&alpha;\frac{\partial}{&part;{B}}J(W,B) $
</p>


<div id="orgb556c4f" class="figure">
<p><img src="../extra/gradient_decent.png" alt="gradient_decent.png" />
</p>
<p><span class="figure-number">Figure 3: </span>gradient</p>
</div>
</div>
</div>

<div id="outline-container-org5b93533" class="outline-4">
<h4 id="org5b93533"><span class="section-number-4">1.1.8</span> partial derivative</h4>
<div class="outline-text-4" id="text-1-1-8">
<p>
\(\frac{\partial}{\partial{W}}J(W,B) =
\frac{1}{2m}\sum2/(\hat{y}-y)/\frac{\partial}{\partial{W}}{\hat{y^i}} = \frac{1}{m}\sum(\hat{y}-y)*{x^j}\)
</p>

<p>
\(\frac{\partial}{\partial{B}}J(W,B) =
\frac{1}{2m}\sum2/(\hat{y}-y)/\frac{\partial}{\partial{B}}{\hat{y^i}} = \frac{1}{m}\sum(\hat{y}-y)\)
</p>
</div>
</div>

<div id="outline-container-org6bf1459" class="outline-4">
<h4 id="org6bf1459"><span class="section-number-4">1.1.9</span> simple linear regression example</h4>
<div class="outline-text-4" id="text-1-1-9">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">from</span> sklearn <span style="color: #859900;">import</span> preprocessing
<span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> load_boston
<span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">import</span> matplotlib.pyplot <span style="color: #859900;">as</span> plt
<span style="color: #859900;">from</span> matplotlib.colors <span style="color: #859900;">import</span> ListedColormap
<span style="color: #859900;">from</span> PIL <span style="color: #859900;">import</span> Image
<span style="color: #859900;">import</span> sys

<span style="color: #268bd2;">EPOCH</span> = 50
<span style="color: #268bd2;">LEARNING_RATE</span> = 0.1
<span style="color: #268bd2;">WITH_FEATURE_SCALING</span>=<span style="color: #268bd2; font-weight: bold;">True</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">mse</span><span style="color: #757575;">(</span>A<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> np.square<span style="color: #757575;">(</span>np.subtract<span style="color: #757575;">(</span>A<span style="color: #757575;">,</span> B<span style="color: #757575;">))</span>.mean<span style="color: #757575;">()</span>/2

<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> X<span style="color: #757575;">,</span> Y
    <span style="color: #268bd2;">data</span> = np.loadtxt<span style="color: #757575;">(</span><span style="color: #2aa198;">"../extra/data.txt"</span><span style="color: #757575;">,</span> delimiter=<span style="color: #2aa198;">","</span><span style="color: #757575;">)</span>

    <span style="color: #268bd2;">X</span> = data[:<span style="color: #757575;">,</span> 0].reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = data[:<span style="color: #757575;">,</span> 1].reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #859900;">if</span> WITH_FEATURE_SCALING:
        <span style="color: #268bd2;">X</span> = preprocessing.scale<span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">Y</span> = preprocessing.scale<span style="color: #757575;">(</span>Y<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cost_function</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">m</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">J</span> = 0.
    <span style="color: #268bd2;">dw</span> = np.zeros_like<span style="color: #757575;">(</span>W<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db</span> = np.zeros_like<span style="color: #757575;">(</span>B<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">y_hat</span> = np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B
    <span style="color: #268bd2;">J</span> = mse<span style="color: #757575;">(</span>y_hat<span style="color: #757575;">,</span> Y<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">dw</span> = np.matmul<span style="color: #757575;">(</span>np.transpose<span style="color: #757575;">(</span>X<span style="color: #757575;">),</span> y_hat - Y<span style="color: #757575;">)</span>/m
    <span style="color: #268bd2;">db</span> = <span style="color: #757575;">(</span>y_hat - Y<span style="color: #757575;">)</span>.mean<span style="color: #757575;">()</span>
    <span style="color: #859900;">return</span> J<span style="color: #757575;">,</span> dw<span style="color: #757575;">,</span> db

<span style="color: #859900;">def</span> <span style="color: #268bd2;">gradient_decent</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">alpha</span> = LEARNING_RATE
    <span style="color: #859900;">for</span> epoch <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>EPOCH<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db</span> = cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>
        <span style="color: #859900;">if</span> epoch % <span style="color: #757575;">(</span>EPOCH//10<span style="color: #757575;">)</span> == 0:
            <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"training: #"</span><span style="color: #757575;">,</span> epoch<span style="color: #757575;">,</span> cost <span style="color: #757575;">,</span>W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">W</span> = W - alpha * dw
        <span style="color: #268bd2;">B</span> = B - alpha * db
    <span style="color: #859900;">return</span> W<span style="color: #757575;">,</span> B

<span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = 0<span style="color: #757575;">,</span> 0
<span style="color: #268bd2;">W</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B</span> = 0<span style="color: #757575;">,</span> 0

<span style="color: #859900;">def</span> <span style="color: #268bd2;">train</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B
    <span style="color: #268bd2;">W</span> = np.random.randn<span style="color: #757575;">(</span>X.shape[1]<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B</span> = gradient_decent<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">predict</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">,</span> X<span style="color: #757575;">,</span> Y
    plt.scatter<span style="color: #757575;">(</span>x=X[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> y=Y[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">)</span>
    plt.plot<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B<span style="color: #757575;">,</span> <span style="color: #2aa198;">'g'</span><span style="color: #757575;">)</span>
    plt.show<span style="color: #757575;">()</span>

get_training_set<span style="color: #757575;">()</span>
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="org00de2ed">
training: # 0 0.44911036737309545 [[1.57832978]] [[0.22798332]]
training: # 5 0.2536317389235355 [[1.27510542]] [[0.13462187]]
training: # 10 0.1854725556828555 [[1.09605446]] [[0.07949287]]
training: # 15 0.16170691799200512 [[0.99032667]] [[0.04693974]]
training: # 20 0.15342035251397768 [[0.92789546]] [[0.02771745]]
training: # 25 0.15053100578931256 [[0.89103046]] [[0.01636688]]
training: # 30 0.14952355288044825 [[0.86926204]] [[0.00966448]]
training: # 35 0.14917227577171124 [[0.85640801]] [[0.00570678]]
training: # 40 0.149049793017394 [[0.84881783]] [[0.00336979]]
training: # 45 0.14900708592167952 [[0.84433591]] [[0.00198983]]
</pre>


<div id="orgac517e0" class="figure">
<p><img src="machine_learning_files/machine_learning_21_1.png" alt="machine_learning_21_1.png" />
</p>
<p><span class="figure-number">Figure 4: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org17cd8da" class="outline-4">
<h4 id="org17cd8da"><span class="section-number-4">1.1.10</span> gradient checking</h4>
<div class="outline-text-4" id="text-1-1-10">
<p>
make sure that:
</p>

<p>
$\frac{\partial}{&part;{W}}J(W,B)
&asymp; lim\<sub>h-&gt;0</sub>\frac{J(W+h,B)-J(W,B)}{h} $
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">check_gradient</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> X<span style="color: #757575;">,</span>Y
    <span style="color: #268bd2;">W</span> = np.random.randn<span style="color: #757575;">(</span>X.shape[1]<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span><span style="color: #268bd2;">dw</span><span style="color: #757575;">,</span><span style="color: #268bd2;">db</span>=cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span>Y<span style="color: #757575;">,</span>W<span style="color: #757575;">,</span>B<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W</span>[0]+=1e-3
    <span style="color: #268bd2;">cost2</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span>=cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span>Y<span style="color: #757575;">,</span>W<span style="color: #757575;">,</span>B<span style="color: #757575;">)</span>
    <span style="color: #859900;">print</span><span style="color: #757575;">((</span>cost2-cost<span style="color: #757575;">)</span>/1e-3<span style="color: #757575;">,</span>dw[0<span style="color: #757575;">,</span>0]<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W</span>[0]-=1e-3
    <span style="color: #268bd2;">B</span>[0]+=1e-3
    <span style="color: #268bd2;">cost2</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span>=cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span>Y<span style="color: #757575;">,</span>W<span style="color: #757575;">,</span>B<span style="color: #757575;">)</span>
    <span style="color: #859900;">print</span><span style="color: #757575;">((</span>cost2-cost<span style="color: #757575;">)</span>/1e-3<span style="color: #757575;">,</span>db<span style="color: #757575;">)</span>

check_gradient<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="org414e74c">
-0.8722622453554152 -0.8727622453556267
-1.5264856192187537 -1.5269856192187428
</pre>
</div>
</div>

<div id="outline-container-org234bd42" class="outline-4">
<h4 id="org234bd42"><span class="section-number-4">1.1.11</span> learning rate</h4>
<div class="outline-text-4" id="text-1-1-11">
<ul class="org-ul">
<li>learning rate 过小会导致 gradient decent 过慢</li>
<li>learning rate 过大会导致 gradient decent 无法收敛

<ul class="org-ul">
<li>在最小值附近反复</li>
<li>变的越来越大</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org072b0c5" class="outline-4">
<h4 id="org072b0c5"><span class="section-number-4">1.1.12</span> feature scaling</h4>
<div class="outline-text-4" id="text-1-1-12">
<p>
通过把 feature scale 到一定固定的范围， 例如 (0,1),
可以更容易的选择合适的 learning rate
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">WITH_FEATURE_SCALING</span>=<span style="color: #268bd2; font-weight: bold;">False</span>

get_training_set<span style="color: #757575;">()</span>
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="org235a9aa">
training: # 0 70.15408361397526 [[-0.40822281]] [[-0.4916959]]
training: # 5 24925634169.17572 [[24500.47499024]] [[2460.57784825]]
training: # 10 9.625926543152364e+18 [[-4.81456725e+08]] [[-48367551.32807031]]
training: # 15 3.717396364137783e+27 [[9.46140039e+12]] [[9.50500295e+11]]
training: # 20 1.4356057742758617e+36 [[-1.85931762e+17]] [[-1.86788622e+16]]
training: # 25 5.544105974322745e+44 [[3.6538587e+21]] [[3.67069739e+20]]
training: # 30 2.1410551284544287e+53 [[-7.18042105e+25]] [[-7.21351179e+24]]
training: # 35 8.268451368556306e+61 [[1.41106843e+30]] [[1.41757129e+29]]
training: # 40 3.193158696643795e+70 [[-2.77297681e+34]] [[-2.78575599e+33]]
training: # 45 1.2331526192107467e+79 [[5.44934622e+38]] [[5.47445936e+37]]
</pre>


<div id="orgb437846" class="figure">
<p><img src="machine_learning_files/machine_learning_29_1.png" alt="machine_learning_29_1.png" />
</p>
<p><span class="figure-number">Figure 5: </span>png</p>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">WITH_FEATURE_SCALING</span>=<span style="color: #268bd2; font-weight: bold;">False</span>
<span style="color: #268bd2;">LEARNING_RATE</span>=0.01

get_training_set<span style="color: #757575;">()</span>
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orgdf99bfa">
training: # 0 103.38177778309628 [[-0.85004288]] [[1.11590542]]
-125.37942448626893 -125.42012645764883
training: # 5 6.86205229028994 [[0.67856153]] [[1.22261939]]
-0.07423379726745338 -0.11493576867876723
training: # 10 6.81940301336375 [[0.68344985]] [[1.1766803]]
-0.05115933051325072 -0.09186130192399862
training: # 15 6.777519309593261 [[0.68802624]] [[1.13112685]]
-0.05033045343871834 -0.09103242485023677
training: # 20 6.736384504793291 [[0.69256148]] [[1.08598248]]
-0.04951293203792062 -0.09021490344897255
training: # 25 6.6959852083221 [[0.69705599]] [[1.04124353]]
-0.048702753118412545 -0.08940472452908702
training: # 30 6.656308268968583 [[0.70151014]] [[0.99690637]]
-0.04789985004727271 -0.08860182145685279
training: # 35 6.617340770671049 [[0.70592429]] [[0.95296738]]
-0.04710415748121477 -0.08780612889108504
training: # 40 6.579070028312648 [[0.7102988]] [[0.90942298]]
-0.04631561066581469 -0.08701758207749494
training: # 45 6.541483583591981 [[0.71463402]] [[0.86626963]]
-0.045534145431957995 -0.08623611684335007
</pre>


<div id="orgeddcde5" class="figure">
<p><img src="machine_learning_files/machine_learning_30_1.png" alt="machine_learning_30_1.png" />
</p>
<p><span class="figure-number">Figure 6: </span>png</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org6ac8c60" class="outline-3">
<h3 id="org6ac8c60"><span class="section-number-3">1.2</span> multi-feature linear regression</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org986b523" class="outline-4">
<h4 id="org986b523"><span class="section-number-4">1.2.1</span> feature &amp; label</h4>
<div class="outline-text-4" id="text-1-2-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span>=0<span style="color: #757575;">,</span>0<span style="color: #757575;">,</span>0<span style="color: #757575;">,</span>0
<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = load_boston<span style="color: #757575;">(</span><span style="color: #268bd2; font-weight: bold;">True</span><span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = preprocessing.scale<span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    [m<span style="color: #757575;">,</span> features] = X.shape
    <span style="color: #586e75;"># </span><span style="color: #586e75;">Z = np.concatenate((X, Y), axis=1)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">np.random.shuffle(Z)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">X = Z[:, :features]</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">Y = Z[:, features:]</span>
    <span style="color: #859900;">global</span> X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> X_test<span style="color: #757575;">,</span> Y_test
    <span style="color: #268bd2;">offset</span> = <span style="color: #839496;">int</span><span style="color: #757575;">(</span>0.8 * m<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span> = X[:offset]<span style="color: #757575;">,</span> Y[:offset]
    <span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span> = X[offset:]<span style="color: #757575;">,</span> Y[offset:]

get_training_set<span style="color: #757575;">()</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>X_train.shape<span style="color: #757575;">)</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>X_train[:5]<span style="color: #757575;">)</span>
<span style="color: #859900;">print</span><span style="color: #757575;">()</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>Y_train[:5]<span style="color: #757575;">)</span>
</pre>
</div>

<pre class="example" id="orgc2ddcdc">
(404, 13)
[[-0.41771335  0.28482986 -1.2879095  -0.27259857 -0.14421743  0.41367189
  -0.12001342  0.1402136  -0.98284286 -0.66660821 -1.45900038  0.44105193
  -1.0755623 ]
 [-0.41526932 -0.48772236 -0.59338101 -0.27259857 -0.74026221  0.19427445
   0.36716642  0.55715988 -0.8678825  -0.98732948 -0.30309415  0.44105193
  -0.49243937]
 [-0.41527165 -0.48772236 -0.59338101 -0.27259857 -0.74026221  1.28271368
  -0.26581176  0.55715988 -0.8678825  -0.98732948 -0.30309415  0.39642699
  -1.2087274 ]
 [-0.41468015 -0.48772236 -1.30687771 -0.27259857 -0.83528384  1.01630251
  -0.80988851  1.07773662 -0.75292215 -1.10611514  0.1130321   0.41616284
  -1.36151682]
 [-0.41040922 -0.48772236 -1.30687771 -0.27259857 -0.83528384  1.22857665
  -0.51117971  1.07773662 -0.75292215 -1.10611514  0.1130321   0.44105193
  -1.02650148]]

[[24. ]
 [21.6]
 [34.7]
 [33.4]
 [36.2]]
</pre>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">from</span> sklearn <span style="color: #859900;">import</span> preprocessing
<span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> load_boston
<span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">import</span> matplotlib.pyplot <span style="color: #859900;">as</span> plt
<span style="color: #859900;">from</span> matplotlib.colors <span style="color: #859900;">import</span> ListedColormap
<span style="color: #859900;">from</span> PIL <span style="color: #859900;">import</span> Image
<span style="color: #859900;">import</span> sys

<span style="color: #268bd2;">EPOCH</span> = 10000
<span style="color: #268bd2;">LEARNING_RATE</span> = 0.001

<span style="color: #859900;">def</span> <span style="color: #268bd2;">MSE</span><span style="color: #757575;">(</span>A<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> np.square<span style="color: #757575;">(</span>np.subtract<span style="color: #757575;">(</span>A<span style="color: #757575;">,</span> B<span style="color: #757575;">))</span>.mean<span style="color: #757575;">()</span>/2

<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = load_boston<span style="color: #757575;">(</span><span style="color: #268bd2; font-weight: bold;">True</span><span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = preprocessing.scale<span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    [m<span style="color: #757575;">,</span> features] = X.shape
    <span style="color: #586e75;"># </span><span style="color: #586e75;">Z = np.concatenate((X, Y), axis=1)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">np.random.shuffle(Z)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">X = Z[:, :features]</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">Y = Z[:, features:]</span>
    <span style="color: #859900;">global</span> X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> X_test<span style="color: #757575;">,</span> Y_test
    <span style="color: #268bd2;">offset</span> = <span style="color: #839496;">int</span><span style="color: #757575;">(</span>0.8 * m<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span> = X[:offset]<span style="color: #757575;">,</span> Y[:offset]
    <span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span> = X[offset:]<span style="color: #757575;">,</span> Y[offset:]

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cost_function</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">m</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">J</span> = 0.
    <span style="color: #268bd2;">dw</span> = np.zeros_like<span style="color: #757575;">(</span>W<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db</span> = np.zeros_like<span style="color: #757575;">(</span>B<span style="color: #757575;">)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">for i in range(m):</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">x = X[i, :].reshape(1, -1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y = Y[i, :].reshape(1, 1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y_hat = np.matmul(x, W) + B</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;"># print(y_hat[0], y[0], MSE(y_hat[0], y[0]))</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">loss = MSE(y_hat, y)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">J += loss</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">dw += np.matmul(np.transpose(x), y_hat - y)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">db += y_hat - y</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">J /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">db /= m</span>
    <span style="color: #268bd2;">y_hat</span> = np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B
    <span style="color: #268bd2;">J</span> = MSE<span style="color: #757575;">(</span>y_hat<span style="color: #757575;">,</span> Y<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">dw</span> = np.matmul<span style="color: #757575;">(</span>np.transpose<span style="color: #757575;">(</span>X<span style="color: #757575;">),</span> y_hat - Y<span style="color: #757575;">)</span> / m
    <span style="color: #268bd2;">db</span> = <span style="color: #757575;">(</span>y_hat - Y<span style="color: #757575;">)</span>.mean<span style="color: #757575;">(</span>axis=0<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> J<span style="color: #757575;">,</span> dw<span style="color: #757575;">,</span> db

<span style="color: #859900;">def</span> <span style="color: #268bd2;">gradient_decent</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">alpha</span> = LEARNING_RATE
    <span style="color: #859900;">for</span> epoch <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>EPOCH<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db</span> = cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">W</span> = W - alpha * dw
        <span style="color: #268bd2;">B</span> = B - alpha * db
        <span style="color: #859900;">if</span> epoch % <span style="color: #757575;">(</span>EPOCH // 20<span style="color: #757575;">)</span> == 0:
            <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"training: #"</span><span style="color: #757575;">,</span> epoch<span style="color: #757575;">,</span> cost<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> W<span style="color: #757575;">,</span> B

<span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span> = 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0
<span style="color: #268bd2;">W</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B</span> = 0<span style="color: #757575;">,</span> 0

<span style="color: #859900;">def</span> <span style="color: #268bd2;">train</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B
    <span style="color: #268bd2;">W</span> = np.random.randn<span style="color: #757575;">(</span>X_train.shape[1]<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B</span> = gradient_decent<span style="color: #757575;">(</span>X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">predict</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W<span style="color: #757575;">,</span> B
    <span style="color: #268bd2;">predicted</span> = np.matmul<span style="color: #757575;">(</span>X_test<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B
    <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"final mse:"</span><span style="color: #757575;">,</span>MSE<span style="color: #757575;">(</span>predicted<span style="color: #757575;">,</span> Y_test<span style="color: #757575;">))</span>

get_training_set<span style="color: #757575;">()</span>
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>W.shape<span style="color: #757575;">,</span>B.shape<span style="color: #757575;">)</span>
</pre>
</div>

<pre class="example" id="orgf90ccde">
training: # 0 394.9508088516925
training: # 500 100.00785133938153
training: # 1000 48.72540414517899
training: # 1500 29.563643302467156
training: # 2000 21.405362653669222
training: # 2500 17.580513440523312
training: # 3000 15.634018864772019
training: # 3500 14.561620691509146
training: # 4000 13.919491179775438
training: # 4500 13.50050685782247
training: # 5000 13.2039753832719
training: # 5500 12.979149491604765
training: # 6000 12.799463170021674
training: # 6500 12.650373482061207
training: # 7000 12.523479650727792
training: # 7500 12.413618800743162
training: # 8000 12.317401683858627
training: # 8500 12.232456842224869
training: # 9000 12.15702919159006
training: # 9500 12.0897592813033
final mse: 11.213129305213641
(13, 1) (1, 1)
</pre>
</div>
</div>

<div id="outline-container-org28a2899" class="outline-4">
<h4 id="org28a2899"><span class="section-number-4">1.2.2</span> learning rate</h4>
<div class="outline-text-4" id="text-1-2-2">
</div>
<div id="outline-container-org31b7f5c" class="outline-5">
<h5 id="org31b7f5c"><span class="section-number-5">1.2.2.1</span> learning rate 偏大</h5>
<div class="outline-text-5" id="text-1-2-2-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">LEARNING_RATE</span> = 0.1
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orgf23fcc5">
training: # 0 323.6508450938955
training: # 500 11.39299545706192
training: # 1000 11.389204091166178
training: # 1500 11.389189815007983
training: # 2000 11.389189761104692
training: # 2500 11.389189760901166
training: # 3000 11.389189760900395
training: # 3500 11.389189760900395
training: # 4000 11.389189760900393
training: # 4500 11.389189760900395
training: # 5000 11.389189760900393
training: # 5500 11.389189760900395
training: # 6000 11.389189760900395
training: # 6500 11.389189760900395
training: # 7000 11.389189760900395
training: # 7500 11.389189760900395
training: # 8000 11.389189760900395
training: # 8500 11.389189760900395
training: # 9000 11.389189760900395
training: # 9500 11.389189760900395
final mse: 16.537813246137475
</pre>
</div>
</div>

<div id="outline-container-org870c5f6" class="outline-5">
<h5 id="org870c5f6"><span class="section-number-5">1.2.2.2</span> learning rate 过大</h5>
<div class="outline-text-5" id="text-1-2-2-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">LEARNING_RATE</span> = 1
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="org5ccbb93">
training: # 0 323.85035063163946
training: # 500 nan
training: # 1000 nan
training: # 1500 nan
training: # 2000 nan
training: # 2500 nan

/usr/lib/python3.6/site-packages/numpy/core/_methods.py:70: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims)
/usr/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in square

training: # 3000 nan
training: # 3500 nan
training: # 4000 nan
training: # 4500 nan
training: # 5000 nan
training: # 5500 nan
training: # 6000 nan
training: # 6500 nan
training: # 7000 nan
training: # 7500 nan
training: # 8000 nan
training: # 8500 nan
training: # 9000 nan
training: # 9500 nan
final mse: nan
</pre>
</div>
</div>

<div id="outline-container-org538c2a9" class="outline-5">
<h5 id="org538c2a9"><span class="section-number-5">1.2.2.3</span> learning rate 过小</h5>
<div class="outline-text-5" id="text-1-2-2-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">LEARNING_RATE</span> = 0.001
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orga83916c">
training: # 0 368.22478200801294
training: # 500 113.60286787202149
training: # 1000 54.16900270646828
training: # 1500 32.30450821323542
training: # 2000 23.043704375375118
training: # 2500 18.67757830837426
training: # 3000 16.42877795251914
training: # 3500 15.169696609178645
training: # 4000 14.40183707813676
training: # 4500 13.891712751211747
training: # 5000 13.52521273665566
training: # 5500 13.244422131600182
training: # 6000 13.018730561961272
training: # 6500 12.83116082771574
training: # 7000 12.671739347524003
training: # 7500 12.534213486546351
training: # 8000 12.414390934896627
training: # 8500 12.30927849859642
training: # 9000 12.216621683323485
training: # 9500 12.134649211355635
final mse: 12.350629498610731
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org29d7e36" class="outline-3">
<h3 id="org29d7e36"><span class="section-number-3">1.3</span> logistic regression</h3>
<div class="outline-text-3" id="text-1-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> make_moons
<span style="color: #859900;">import</span> matplotlib.pyplot <span style="color: #859900;">as</span> plt
<span style="color: #859900;">from</span> matplotlib.colors <span style="color: #859900;">import</span> ListedColormap

<span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = make_moons<span style="color: #757575;">(</span>n_samples=1000<span style="color: #757575;">,</span> noise=0.2<span style="color: #757575;">)</span>
<span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>

<span style="color: #268bd2;">cm</span> = ListedColormap<span style="color: #757575;">(</span>[<span style="color: #2aa198;">'#FF0000'</span><span style="color: #757575;">,</span> <span style="color: #2aa198;">'#0000FF'</span>]<span style="color: #757575;">)</span>
plt.scatter<span style="color: #757575;">(</span>x=X[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> y=X[:<span style="color: #757575;">,</span> 1]<span style="color: #757575;">,</span> c=Y[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> cmap=cm<span style="color: #757575;">)</span>
plt.show<span style="color: #757575;">()</span>
</pre>
</div>


<div id="org7826ca8" class="figure">
<p><img src="machine_learning_files/machine_learning_43_0.png" alt="machine_learning_43_0.png" />
</p>
<p><span class="figure-number">Figure 7: </span>png</p>
</div>
</div>

<div id="outline-container-org3170b85" class="outline-4">
<h4 id="org3170b85"><span class="section-number-4">1.3.1</span> feature &amp; label</h4>
<div class="outline-text-4" id="text-1-3-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"X:"</span><span style="color: #757575;">,</span>X[:10]<span style="color: #757575;">)</span>
<span style="color: #859900;">print</span><span style="color: #757575;">()</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"Y:"</span><span style="color: #757575;">,</span>Y[:10]<span style="color: #757575;">)</span>
</pre>
</div>

<pre class="example" id="org030a708">
X: [[ 0.8525511  -0.39862199]
 [ 0.1632493  -0.34467561]
 [ 1.15179796  0.77013127]
 [ 1.09955561 -0.42176977]
 [ 2.14572763 -0.19269439]
 [-0.04550188  1.2857288 ]
 [ 1.18711691  0.17124724]
 [ 1.82545617  0.84777188]
 [-0.15896536 -0.1438627 ]
 [ 1.04386354  1.06882075]]

Y: [[1]
 [1]
 [0]
 [1]
 [1]
 [0]
 [0]
 [1]
 [1]
 [0]]
</pre>
</div>
</div>

<div id="outline-container-org50abcee" class="outline-4">
<h4 id="org50abcee"><span class="section-number-4">1.3.2</span> regression</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
给定一个 x (x0, x1), 预测它所属的类型 （1 或 0， 蓝或红）
</p>
</div>
</div>

<div id="outline-container-orgfa6945c" class="outline-4">
<h4 id="orgfa6945c"><span class="section-number-4">1.3.3</span> hypothesis function</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
linear regression 的 hypothesis function: \(\hat{y}=h(x)=Wx+B\) 对于
logistic regression 不直接适用， 因为我们需要它输出 0 或 1 的离散值
</p>
</div>
</div>

<div id="outline-container-org40f99e2" class="outline-4">
<h4 id="org40f99e2"><span class="section-number-4">1.3.4</span> sigmoid</h4>
<div class="outline-text-4" id="text-1-3-4">
<p>
\(sigmoid(x)=\frac{1}{1+e^{-x}}\)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">x</span>=np.arange<span style="color: #757575;">(</span>-10<span style="color: #757575;">,</span>10<span style="color: #757575;">,</span>0.1<span style="color: #757575;">)</span>
<span style="color: #268bd2;">y</span>=1/<span style="color: #757575;">(</span>1+np.exp<span style="color: #757575;">(</span>-x<span style="color: #757575;">))</span>
plt.plot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span>y<span style="color: #757575;">)</span>
plt.show<span style="color: #757575;">()</span>
</pre>
</div>


<div id="orgf9494b6" class="figure">
<p><img src="machine_learning_files/machine_learning_52_0.png" alt="machine_learning_52_0.png" />
</p>
<p><span class="figure-number">Figure 8: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org03fe3d3" class="outline-4">
<h4 id="org03fe3d3"><span class="section-number-4">1.3.5</span> cost function</h4>
<div class="outline-text-4" id="text-1-3-5">
<p>
logistic regression 没有使用 mse 做为 cost function <a href="gradient_descent.html#ID-33e1fdaf-8107-45cb-8cc9-2bdb889e471e">sigmoid 为何需要搭配 BCELoss</a>
</p>

<p>
因此， logistic regression 使用 cross entropy 作为 cost function,
直观上说， 两个概率分布越接近， 其 cross entropy 越小
</p>
</div>
</div>

<div id="outline-container-org079c337" class="outline-4">
<h4 id="org079c337"><span class="section-number-4">1.3.6</span> cross entropy</h4>
<div class="outline-text-4" id="text-1-3-6">
<p>
\(H(p,q)=-\sum _{x}p(x)\,\log q(x).\!\)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">cross_entropy</span><span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> labels<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">epsilon</span> = 1e-12
    <span style="color: #268bd2;">predictions</span> = np.clip<span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> epsilon<span style="color: #757575;">,</span> 1 - epsilon<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">N</span> = predictions.shape[0]

    <span style="color: #268bd2;">ce</span> = 0 - np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>labels * np.log<span style="color: #757575;">(</span>predictions<span style="color: #757575;">)))</span> / N
    <span style="color: #859900;">return</span> ce

<span style="color: #859900;">print</span><span style="color: #757575;">(</span>cross_entropy<span style="color: #757575;">(</span>np.array<span style="color: #757575;">(</span>[[0.1<span style="color: #757575;">,</span>0.9]]<span style="color: #757575;">),</span>np.array<span style="color: #757575;">(</span>[[1<span style="color: #757575;">,</span>0]]<span style="color: #757575;">)))</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>cross_entropy<span style="color: #757575;">(</span>np.array<span style="color: #757575;">(</span>[[0.9<span style="color: #757575;">,</span>0.1]]<span style="color: #757575;">),</span>np.array<span style="color: #757575;">(</span>[[1<span style="color: #757575;">,</span>0]]<span style="color: #757575;">)))</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>cross_entropy<span style="color: #757575;">(</span>np.array<span style="color: #757575;">(</span>[[0.9<span style="color: #757575;">,</span>0.1]]<span style="color: #757575;">),</span>np.array<span style="color: #757575;">(</span>[[0<span style="color: #757575;">,</span>1]]<span style="color: #757575;">)))</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>cross_entropy<span style="color: #757575;">(</span>np.array<span style="color: #757575;">(</span>[[0.2<span style="color: #757575;">,</span>0.8]]<span style="color: #757575;">),</span>np.array<span style="color: #757575;">(</span>[[0<span style="color: #757575;">,</span>1]]<span style="color: #757575;">)))</span>
</pre>
</div>

<pre class="example" id="org0d7bbbf">
2.3025850929940455
0.10536051565782628
2.3025850929940455
0.2231435513142097
</pre>

<p>
logistic regression 的 cost function 是一个简化版的 cross entropy:
</p>

<p>
即 p 为 \((\hat{y},1-\hat{y})\), q 为 \((y,1-y)\),
</p>

<p>
所以它的 cost function 为
</p>

<p>
\(J(W,B)=-\sum_1^m({y*\log(\hat{y})+(1-y)*\log(1-\hat{y})})\)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">x</span>=np.arange<span style="color: #757575;">(</span>0.01<span style="color: #757575;">,</span>1<span style="color: #757575;">,</span>0.01<span style="color: #757575;">)</span>
plt.plot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span>-np.log<span style="color: #757575;">(</span>x<span style="color: #757575;">),</span>label=<span style="color: #2aa198;">"-log(x)"</span><span style="color: #757575;">)</span>
plt.plot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span>-np.log<span style="color: #757575;">(</span>1-x<span style="color: #757575;">),</span>label=<span style="color: #2aa198;">"-log(1-x)"</span><span style="color: #757575;">)</span>
plt.legend<span style="color: #757575;">()</span>
plt.show<span style="color: #757575;">()</span>
</pre>
</div>


<div id="org05adc2a" class="figure">
<p><img src="machine_learning_files/machine_learning_59_0.png" alt="machine_learning_59_0.png" />
</p>
<p><span class="figure-number">Figure 9: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org6034eab" class="outline-4">
<h4 id="org6034eab"><span class="section-number-4">1.3.7</span> partial derivative</h4>
<div class="outline-text-4" id="text-1-3-7">
<p>
\(h(x)=Wx+B\)
</p>

<p>
\(\hat{y}=sigmoid(h(x))\)
</p>

<p>
\(J(W,B)=-\sum({y*\log(\hat{y})+(1-y)*\log(1-\hat{y})})\)
</p>
</div>
</div>
</div>

<div id="outline-container-org7c80543" class="outline-3">
<h3 id="org7c80543"><span class="section-number-3">1.4</span> $\frac{\partial}{&part;{W}}J(W,B)</h3>
<div class="outline-text-3" id="text-1-4">
<p>
-&sum;{\frac{y}{\hat{y}}}\frac{\partial}{&part;{W}}\hat{y}-\frac{1-y}{1-\hat{y}}\frac{\partial}{&part;{W}}\hat{y}
$
</p>

<p>
$\frac{\partial}{&part;{W}}{\hat{y}} = \hat{y}/(1-\hat{y})/x $
</p>

<p>
\(\frac{\partial}{\partial{W}}J(W,B) = \frac{1}{m}{\sum{(\hat{y}-y})*x}\)
</p>

<p>
\(\frac{\partial}{\partial{B}}J(W,B) = \frac{1}{m}{\sum{(\hat{y}-y})}\)
</p>
</div>

<div id="outline-container-orgac7cd42" class="outline-4">
<h4 id="orgac7cd42"><span class="section-number-4">1.4.1</span> logistic regression example</h4>
<div class="outline-text-4" id="text-1-4-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">from</span> sklearn <span style="color: #859900;">import</span> preprocessing
<span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> make_moons
<span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> make_circles
<span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">import</span> matplotlib.pyplot <span style="color: #859900;">as</span> plt
<span style="color: #859900;">from</span> matplotlib.colors <span style="color: #859900;">import</span> ListedColormap
<span style="color: #859900;">from</span> PIL <span style="color: #859900;">import</span> Image
<span style="color: #859900;">import</span> sys

<span style="color: #268bd2;">EPOCH</span> = 500
<span style="color: #268bd2;">LEARNING_RATE</span> = 0.01
<span style="color: #268bd2;">BATCH_SIZE</span> = 10
<span style="color: #268bd2;">FEATURE_SIZE</span> = 0
<span style="color: #268bd2;">POLY_FEATURES</span> = 3

<span style="color: #859900;">def</span> <span style="color: #268bd2;">sigmoid</span><span style="color: #757575;">(</span>x<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> 1 / <span style="color: #757575;">(</span>1 + np.exp<span style="color: #757575;">(</span>-x<span style="color: #757575;">))</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cross_entropy</span><span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> labels<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">epsilon</span> = 1e-12
    <span style="color: #268bd2;">predictions</span> = np.clip<span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> epsilon<span style="color: #757575;">,</span> 1 - epsilon<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">N</span> = predictions.shape[0]
    <span style="color: #268bd2;">ce</span> = 0 - np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>labels * np.log<span style="color: #757575;">(</span>predictions<span style="color: #757575;">)))</span> / N
    <span style="color: #859900;">return</span> ce

<span style="color: #859900;">def</span> <span style="color: #268bd2;">draw_decision_boundary</span><span style="color: #757575;">(</span>W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">xx</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">yy</span> = np.meshgrid<span style="color: #757575;">(</span>
        np.arange<span style="color: #757575;">(</span>-1.5<span style="color: #757575;">,</span> 2.5<span style="color: #757575;">,</span> 0.02<span style="color: #757575;">),</span> np.arange<span style="color: #757575;">(</span>-1.5<span style="color: #757575;">,</span> 2.5<span style="color: #757575;">,</span> 0.02<span style="color: #757575;">))</span>
    <span style="color: #268bd2;">X</span> = np.c_[xx.ravel<span style="color: #757575;">(),</span> yy.ravel<span style="color: #757575;">()</span>]

    <span style="color: #268bd2;">poly</span> = preprocessing.PolynomialFeatures<span style="color: #757575;">(</span>POLY_FEATURES<span style="color: #757575;">,</span> include_bias=<span style="color: #268bd2; font-weight: bold;">False</span><span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = poly.fit_transform<span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">Y</span> = <span style="color: #757575;">((</span>sigmoid<span style="color: #757575;">(</span>np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B<span style="color: #757575;">))</span> &gt; 0.5<span style="color: #757575;">)</span>[:<span style="color: #757575;">,</span> 0]
    <span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>xx.shape<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">cm</span> = ListedColormap<span style="color: #757575;">(</span>[<span style="color: #2aa198;">'#FF0000'</span><span style="color: #757575;">,</span> <span style="color: #2aa198;">'#0000FF'</span>]<span style="color: #757575;">)</span>
    plt.contour<span style="color: #757575;">(</span>xx<span style="color: #757575;">,</span> yy<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> cmap=cm<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = make_moons<span style="color: #757575;">(</span>n_samples=1000<span style="color: #757575;">,</span> noise=0.2<span style="color: #757575;">)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">X, Y = make_circles(n_samples=1000, noise=0.2, factor=0.5)</span>
    <span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>1000<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">poly</span> = preprocessing.PolynomialFeatures<span style="color: #757575;">(</span>POLY_FEATURES<span style="color: #757575;">,</span> include_bias=<span style="color: #268bd2; font-weight: bold;">False</span><span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = poly.fit_transform<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">)</span>
    <span style="color: #859900;">global</span> FEATURE_SIZE
    <span style="color: #268bd2;">FEATURE_SIZE</span> = X.shape[1]
    <span style="color: #859900;">return</span> X<span style="color: #757575;">,</span> Y

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cost_function</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">m</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #859900;">assert</span> <span style="color: #757575;">(</span><span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span> == <span style="color: #839496;">len</span><span style="color: #757575;">(</span>Y<span style="color: #757575;">))</span>

    <span style="color: #268bd2;">J</span> = 0.

    <span style="color: #268bd2;">dw</span> = np.zeros_like<span style="color: #757575;">(</span>W<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db</span> = np.zeros_like<span style="color: #757575;">(</span>B<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">y_hat</span> = sigmoid<span style="color: #757575;">(</span>np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">J</span> = cross_entropy<span style="color: #757575;">(</span>np.concatenate<span style="color: #757575;">((</span>y_hat<span style="color: #757575;">,</span> 1 - y_hat<span style="color: #757575;">)),</span> np.concatenate<span style="color: #757575;">((</span>Y<span style="color: #757575;">,</span> 1 - Y<span style="color: #757575;">)))</span>
    <span style="color: #268bd2;">dw</span> = np.matmul<span style="color: #757575;">(</span>X.T<span style="color: #757575;">,</span> y_hat - Y<span style="color: #757575;">)</span> / m
    <span style="color: #268bd2;">db</span> = <span style="color: #757575;">(</span>y_hat - Y<span style="color: #757575;">)</span>.mean<span style="color: #757575;">(</span>axis=0<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> J<span style="color: #757575;">,</span> dw<span style="color: #757575;">,</span> db

<span style="color: #268bd2;">W</span><span style="color: #757575;">,</span><span style="color: #268bd2;">B</span>=0<span style="color: #757575;">,</span>0
<span style="color: #859900;">def</span> <span style="color: #268bd2;">gradient_decent</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">alpha</span> = LEARNING_RATE
    <span style="color: #859900;">for</span> epoch <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>EPOCH<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">batch</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span> // BATCH_SIZE
        <span style="color: #268bd2;">total_loss</span> = 0
        <span style="color: #859900;">for</span> X_batch<span style="color: #757575;">,</span> Y_batch <span style="color: #859900;">in</span> <span style="color: #839496;">zip</span><span style="color: #757575;">(</span>
                np.split<span style="color: #757575;">(</span>X[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">),</span>
                np.split<span style="color: #757575;">(</span>Y[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">))</span>:
            <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db</span> = cost_function<span style="color: #757575;">(</span>X_batch<span style="color: #757575;">,</span> Y_batch<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>
            <span style="color: #268bd2;">total_loss</span> += cost
            <span style="color: #268bd2;">W</span> = W - alpha * dw
            <span style="color: #268bd2;">B</span> = B - alpha * db

        <span style="color: #859900;">if</span> epoch % <span style="color: #757575;">(</span>EPOCH//30<span style="color: #757575;">)</span> == 0:
            <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"training: #"</span><span style="color: #757575;">,</span> epoch<span style="color: #757575;">,</span> total_loss / batch<span style="color: #757575;">)</span>

    <span style="color: #859900;">return</span> W<span style="color: #757575;">,</span> B

<span style="color: #859900;">def</span> <span style="color: #268bd2;">train</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W<span style="color: #757575;">,</span>B
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = get_training_set<span style="color: #757575;">()</span>

    <span style="color: #268bd2;">Z</span> = np.concatenate<span style="color: #757575;">((</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">),</span> axis=1<span style="color: #757575;">)</span>
    np.random.shuffle<span style="color: #757575;">(</span>Z<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = Z[:<span style="color: #757575;">,</span> :FEATURE_SIZE]
    <span style="color: #268bd2;">Y</span> = Z[:<span style="color: #757575;">,</span> FEATURE_SIZE:]

    <span style="color: #268bd2;">W</span> = np.random.randn<span style="color: #757575;">(</span>FEATURE_SIZE<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">W</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B</span> = gradient_decent<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">predict</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W<span style="color: #757575;">,</span>B
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = get_training_set<span style="color: #757575;">()</span>
    <span style="color: #268bd2;">cm</span> = ListedColormap<span style="color: #757575;">(</span>[<span style="color: #2aa198;">'#FF0000'</span><span style="color: #757575;">,</span> <span style="color: #2aa198;">'#0000FF'</span>]<span style="color: #757575;">)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">plt.plot(X[:, 0], X[:, 1], 'bo', label='Real data')</span>
    <span style="color: #268bd2;">y_hat</span> = <span style="color: #757575;">((</span>sigmoid<span style="color: #757575;">(</span>np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B<span style="color: #757575;">))</span> &gt; 0.5<span style="color: #757575;">)</span>[:<span style="color: #757575;">,</span> 0]
    plt.scatter<span style="color: #757575;">(</span>x=X[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> y=X[:<span style="color: #757575;">,</span> 1]<span style="color: #757575;">,</span> c=Y[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> cmap=cm<span style="color: #757575;">)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">plt.scatter(x=X[:, 0], y=X[:, 1], c=y_hat, cmap=cm)</span>
    draw_decision_boundary<span style="color: #757575;">(</span>W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>
    plt.show<span style="color: #757575;">()</span>

train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orga8d14da">
training: # 0 0.619742973585997
training: # 16 0.17178658979627992
training: # 32 0.13487915355393248
training: # 48 0.12197846405639046
training: # 64 0.11395684458496719
training: # 80 0.10787208561892815
training: # 96 0.10291655423822696
training: # 112 0.0987579063665693
training: # 128 0.09521177753383403
training: # 144 0.09215291261899158
training: # 160 0.08948702750211028
training: # 176 0.08714053451732778
training: # 192 0.08505555055681267
training: # 208 0.08318653814486694
training: # 224 0.08149765158102548
training: # 240 0.07996058158625095
training: # 256 0.07855283335926001
training: # 272 0.07725638132916592
training: # 288 0.076056636971483
training: # 304 0.07494166614098187
training: # 320 0.07390159911921022
training: # 336 0.07292818633539222
training: # 352 0.07201446275282071
training: # 368 0.0711544927837573
training: # 384 0.0703431748029327
training: # 400 0.06957608988875362
training: # 416 0.06884938357165127
training: # 432 0.06815967240663312
training: # 448 0.06750396938582705
training: # 464 0.06687962379072875
training: # 480 0.06628427222462412
training: # 496 0.0657157983897877
</pre>


<div id="org4df38f3" class="figure">
<p><img src="machine_learning_files/machine_learning_64_1.png" alt="machine_learning_64_1.png" />
</p>
<p><span class="figure-number">Figure 10: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org9d410a8" class="outline-4">
<h4 id="org9d410a8"><span class="section-number-4">1.4.2</span> polynormial features</h4>
<div class="outline-text-4" id="text-1-4-2">
<p>
moon 这个例子里， decision boundary
明显不是一条直线，如果我们仅仅用原始的 feature 进行 regression,
最终只能得到一条直线， 例如下面 POLY\_FEATURES 为 1 的情形
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">POLY_FEATURES</span>=1
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orga13c16a">
training: # 0 0.2854766049060549
training: # 16 0.17277657607109922
training: # 32 0.15635266723112187
training: # 48 0.1493546886034027
training: # 64 0.1455593393582365
training: # 80 0.14329109540467472
training: # 96 0.14185780692665098
training: # 112 0.14091661921781962
training: # 128 0.14028055239864892
training: # 144 0.13984099949762763
training: # 160 0.1395318373157802
training: # 176 0.139311279131328
training: # 192 0.1391521054830019
training: # 208 0.13903613821495753
training: # 224 0.13895098343274292
training: # 240 0.1388880435606131
training: # 256 0.13884126717244613
training: # 272 0.13880634230124886
training: # 288 0.13878016421457948
training: # 304 0.13876047744704142
training: # 320 0.13874563097468282
training: # 336 0.13873440831324527
training: # 352 0.1387259081022462
training: # 368 0.13871945923467058
training: # 384 0.1387145599485834
training: # 400 0.13871083374087895
training: # 416 0.13870799721751376
training: # 432 0.13870583649403773
training: # 448 0.1387041897724283
training: # 464 0.13870293441266346
training: # 480 0.13870197729689518
training: # 496 0.13870124761970357
</pre>


<div id="org6b2ee88" class="figure">
<p><img src="machine_learning_files/machine_learning_67_1.png" alt="machine_learning_67_1.png" />
</p>
<p><span class="figure-number">Figure 11: </span>png</p>
</div>

<p>
为了拟合成一条曲线， 我们把原始的 feature 做了修改， 例如， 原始 feature
为 [\(x1\),\(x2\),\(x3\)], 我们把它变成
[\(x1\),\(x2\),\(x3\),\(x1^2\),\(x2^2\),\(x3^2\),\(x1*x2\),\(x1*x3\),\(x2*x3\)], sklearn
的 PolynormialFeatures 类可以完成这种操作
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">POLY_FEATURES</span>=7
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orgffd3505">
training: # 0 1.072493450454601
training: # 16 0.12517269994676714
training: # 32 0.10019008105575024
training: # 48 0.08845764537675999
training: # 64 0.08117824825999641
training: # 80 0.07617331085450527
training: # 96 0.0724893405480805
training: # 112 0.06964268516153896
training: # 128 0.06736243690988726
training: # 144 0.06548490220832501
training: # 160 0.06390509140298205
training: # 176 0.06255237236394463
training: # 192 0.06137734432013081
training: # 208 0.0603443289005192
training: # 224 0.05942685621245631
training: # 240 0.05860483518675161
training: # 256 0.057862715087380216
training: # 272 0.05718825356269268
training: # 288 0.05657166868407597
training: # 304 0.056005041406647346
training: # 320 0.055481885676289505
training: # 336 0.05499683340343065
training: # 352 0.05454539978629234
training: # 368 0.05412380589131122
training: # 384 0.05372884272286389
training: # 400 0.05335776581488923
training: # 416 0.053008212586936033
training: # 432 0.052678136893091254
training: # 448 0.05236575670587306
training: # 464 0.05206951194142586
training: # 480 0.05178803019125905
training: # 496 0.051520098673991474

/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in exp
</pre>


<div id="org2e1f995" class="figure">
<p><img src="machine_learning_files/machine_learning_69_2.png" alt="machine_learning_69_2.png" />
</p>
<p><span class="figure-number">Figure 12: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org29dee04" class="outline-4">
<h4 id="org29dee04"><span class="section-number-4">1.4.3</span> underfitting &amp; overfitting</h4>
<div class="outline-text-4" id="text-1-4-3">
<p>
在上面的例子中， POLY\_FEATURES 设为 1 时， 拟合的结果是 underfitting,
当 POLY\_FEATURES 为 7 时， 结果有些 overfitting, FEATURES 为 3
时看起来是比较合适的
</p>
</div>
</div>

<div id="outline-container-orgc1b04eb" class="outline-4">
<h4 id="orgc1b04eb"><span class="section-number-4">1.4.4</span> regularization</h4>
<div class="outline-text-4" id="text-1-4-4">
<ul class="org-ul">
<li>没有 regularization</li>
</ul>

<p>
\(J(W,B)=-\sum({y*\log(\hat{y})+(1-y)*\log(1-\hat{y})})\)
</p>

<p>
\(\frac{\partial}{\partial{W}}J(W,B) = \frac{1}{m}{\sum{(\hat{y}-y})*x}\)
</p>

<ul class="org-ul">
<li>加上 regularization</li>
</ul>

<p>
$J(W,B)=-&sum;({y/log(\hat{y})+(1-y)/log(1-\hat{y})}) +
\frac{\alpha}{2m} &sum;\_i W\_i\^2 $
</p>

<p>
$\frac{\partial}{&part;{W}}J(W,B) = \frac{1}{m}{&sum;{(\hat{y}-y})*x}
+\frac{\alpha}{m}W $
</p>

<p>
通过 \(\alpha\) 可以控制 regularization 的程度， 当 \(\alpha\) 很小时，
倾向于 overfitting, 当 \(\alpha\) 很大时， 倾向于 underfitting
</p>
</div>
</div>
</div>

<div id="outline-container-orgb40856e" class="outline-3">
<h3 id="orgb40856e"><span class="section-number-3">1.5</span> multi-class logistic regression</h3>
<div class="outline-text-3" id="text-1-5">
<p>
普通的 logistic regression 用来作二分类， hypothesis function
输出可以看作是预测结果为 1 的概率， label 只有两种结果: 0 或 1
</p>

<p>
在多分类的问题中， label 会有多个值。 mnist 手写数字识别是一个经典的
multi-classification 问题
</p>
</div>

<div id="outline-container-orgf6f26b8" class="outline-4">
<h4 id="orgf6f26b8"><span class="section-number-4">1.5.1</span> training set</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
mnist training set 中， 每张图片是 28 *28 像素， 处理时把它 flatten
成一个 784 大小的 array.
</p>

<p>
每个 label 的值的范围是 0~9, 表示图片对应的数字
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">from</span> os <span style="color: #859900;">import</span> listdir
<span style="color: #859900;">from</span> os.path <span style="color: #859900;">import</span> isfile<span style="color: #757575;">,</span> join

<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_test_set</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span> = np.ndarray<span style="color: #757575;">(</span>shape=<span style="color: #757575;">(</span>0<span style="color: #757575;">,</span> 784<span style="color: #757575;">))</span>
    <span style="color: #268bd2;">Y</span> = np.ndarray<span style="color: #757575;">(</span>shape=<span style="color: #757575;">(</span>0<span style="color: #757575;">,</span> 10<span style="color: #757575;">))</span>
    <span style="color: #268bd2;">baseDir</span> = <span style="color: #2aa198;">"/home/sunway/program/mnist/testSet"</span>
    <span style="color: #859900;">for</span> i <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>10<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">currDir</span> = <span style="color: #757575;">(</span>baseDir + <span style="color: #2aa198;">"/"</span> + <span style="color: #839496;">str</span><span style="color: #757575;">(</span>i<span style="color: #757575;">))</span>
        <span style="color: #268bd2;">files</span> = [
            join<span style="color: #757575;">(</span>currDir<span style="color: #757575;">,</span> f<span style="color: #757575;">)</span> <span style="color: #859900;">for</span> f <span style="color: #859900;">in</span> listdir<span style="color: #757575;">(</span>currDir<span style="color: #757575;">)</span>
            <span style="color: #859900;">if</span> isfile<span style="color: #757575;">(</span>join<span style="color: #757575;">(</span>currDir<span style="color: #757575;">,</span> f<span style="color: #757575;">))</span>
        ]
        <span style="color: #859900;">for</span> f <span style="color: #859900;">in</span> files:
            <span style="color: #268bd2;">X</span> = np.concatenate<span style="color: #757575;">((</span>X<span style="color: #757575;">,</span> np.array<span style="color: #757575;">(</span>Image.<span style="color: #839496;">open</span><span style="color: #757575;">(</span>f<span style="color: #757575;">))</span>.reshape<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 784<span style="color: #757575;">)))</span>
            <span style="color: #268bd2;">Y</span> = np.concatenate<span style="color: #757575;">((</span>Y<span style="color: #757575;">,</span> one_hot<span style="color: #757575;">(</span>np.array<span style="color: #757575;">(</span>[i]<span style="color: #757575;">),</span> 10<span style="color: #757575;">)))</span>

    <span style="color: #859900;">return</span> X<span style="color: #757575;">,</span> Y

<span style="color: #268bd2;">X</span><span style="color: #757575;">,</span><span style="color: #268bd2;">Y</span>=get_test_set<span style="color: #757575;">()</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"X:"</span><span style="color: #757575;">,</span>X[0]<span style="color: #757575;">)</span>
<span style="color: #859900;">print</span><span style="color: #757575;">()</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"Y:"</span><span style="color: #757575;">,</span>Y[0]<span style="color: #757575;">)</span>
</pre>
</div>

<pre class="example" id="orgced226e">
X: [  0.   0.   0.   0.   0.   0.   0.   0.   0.  11.   3.   0.   6.   8.
   0.   9.   3.   0.   9.   0.   7.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   9.   0.   0.
  14.   0.   0.   1.   3.   0.   0.   3.   1.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.  12.   0.  27.   0.   0.  10.
  15.   0.   0.   0.   0.  20.   0.   0.   0.   4.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.  28.   0.  14.   0.   0.
   0.   2.   9.   5.   0.   1.   0.   9.   7.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   7.   0.   6.   0.  13.   0.
  10. 108. 168. 224. 231. 145.  58.   0.   0.   6.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   7.   3.   6.   0.  14.  56.
 208. 237. 254. 255. 255. 247. 208.  79.   0.   2.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.  12.   0.   0.   8. 215.
 255. 255. 171. 136. 169. 231. 255. 150.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   6.   0.   5. 160. 247.
 255. 192.  32.   0.   4. 104. 248. 238.  33.   7.   0.   0.   0.   0.
   0.   1.   0.   6.   7.   0.   0.   0.   4.   4.   0.  12. 231. 255.
 178.  11.   3.   0.   7.  19. 246. 255.  55.   0.   0.   0.   0.   0.
   0.   5.   0.   0.   0.   5.  10.   2.   0.   0.   0. 145. 255. 232.
   7.   0.   0.  14.   0.  10. 255. 255.  95.  12.   0.   0.   0.   0.
   0.   0.   4.   0.   0.   4.   5.   0.   0.  14.  97. 232. 255. 138.
   0.   3.   0.   7.   0.  18. 255. 234.  48.   0.   0.   0.   0.   0.
   0.   0.   8.  11.   0.   0.   0.   1.   6.   5. 218. 249. 250. 110.
   0.   6.   0.   0.   8.  43. 250. 252.  25.   7.   0.   0.   0.   0.
   6.   0.   5.   0.   0.   6.   0.   7.   1. 170. 255. 188. 133.  38.
   0.   0.   4.   0.  10.  83. 239. 247.  30.   5.   0.   0.   0.   0.
   0.   0.   7.   0.   0.  15.   0.   0. 118. 255. 252.  54.   0.  14.
   6.   6.   4.   0.   2. 175. 255. 163.  10.   0.   0.   0.   0.   0.
   0.   0.   8.   0.   5.   3.   0.  49. 250. 248.  84.  17.   0.   0.
  31.   0.   0.   0.  66. 255. 255.  79.  10.   6.   0.   0.   0.   0.
   9.   0.   0.   0.   6.   0.  13. 168. 248. 244.   7.   0.   9.   0.
   0.   7.   3.  33. 176. 255. 186.  16.   0.   0.   0.   0.   0.   0.
   2.   3.   0.   5.   0.   3.  61. 237. 255.  68.   0.   8.   2.   0.
  12.   2.   8. 112. 255. 239. 103.   0.   0.   0.   0.   0.   0.   0.
   0.   5.   0.   0.   9.   0. 147. 254. 173.  20.   0.   0.   6.  11.
   0.   0.  76. 250. 233. 133.   0.   8.   4.   5.   0.   0.   0.   0.
   0.   0.   3.   0.  10.  18. 214. 238.  43.   0.   6.   0.  10.   0.
   0. 141. 252. 255. 242.  34.   3.   0.   7.   0.   0.   0.   0.   0.
   7.   0.   5.   3.   0.  95. 233. 205.   9.   0.  18.   0.  15.  98.
 182. 248. 255. 228.  28.   0.   0.   7.   0.  29.   0.   0.   0.   0.
   4.   0.   0.   6.   0. 129. 255. 216.  32.  28.  35.  96. 212. 241.
 252. 255. 203.  76.  31.   0.   1.  14.   0.   0.   0.   0.   0.   0.
   0.  10.   0.   0.   0.  84. 255. 255. 255. 251. 252. 255. 255. 255.
 244. 106.   0.   8.   0.   0.  16.   0.   1.   0.   0.   0.   0.   0.
   0.   1.   0.   0.   3.  21. 190. 254. 252. 248. 245. 250. 251. 159.
  65.   0.  10.   0.   9.  17.   0.   0.   0.  14.   0.   0.   0.   0.
  10.   0.   9.   4.   0.   0.  78. 213. 198. 184. 174. 106.  57.   3.
   0.   7.   0.   5.   0.   0.  14.   0.   0.   2.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]

Y: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
</pre>

<p>
mnist 中， W 的 shape 不再是 [784, 1], 而是变成了 [784, 10], 其中 W[:,0]
用来预测图片为 0 的概率， W[:,1] 预测图片为 1 的概率&#x2026;
</p>

<p>
因此 \(WX+B\) 结果是一个 [m,10] 的 matrix, 但 Y 的值却是 0~9,
所以我们需要把 label 值变为一个 [10,1] 的 matrix, 其中第 n 行代表 label
是 n 的概率。
</p>

<p>
这个转换 label 的过程叫做 one\_hot
</p>
</div>
</div>

<div id="outline-container-org586e501" class="outline-4">
<h4 id="org586e501"><span class="section-number-4">1.5.2</span> one\_hot</h4>
<div class="outline-text-4" id="text-1-5-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">one_hot</span><span style="color: #757575;">(</span>Y<span style="color: #757575;">,</span> C<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">one</span> = np.eye<span style="color: #757575;">(</span>C<span style="color: #757575;">)</span>[Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">)</span>]
    <span style="color: #859900;">return</span> one

<span style="color: #268bd2;">x</span>=np.array<span style="color: #757575;">(</span>[[0<span style="color: #757575;">,</span>1<span style="color: #757575;">,</span>2<span style="color: #757575;">,</span>3<span style="color: #757575;">,</span>4<span style="color: #757575;">,</span>5<span style="color: #757575;">,</span>6<span style="color: #757575;">,</span>7<span style="color: #757575;">,</span>8<span style="color: #757575;">,</span>9]]<span style="color: #757575;">)</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>one_hot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span>10<span style="color: #757575;">))</span>
</pre>
</div>

<pre class="example" id="org8067b23">
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]
</pre>

<p>
普通的 logistic regression 通过 sigmoid 把 <code>一个值</code> 转换为
=结果为 1 的概率=， 在 mnist 中 \(XW+B\) 输出 [10,1] 的 matrix，
我们需要一个 hypothesis function 把这个 matrix 变成 10 个概率，
然后再通过某个 cost\_function 与 one\_hot 转换后的 label 比较.
</p>

<p>
把 [10,1] 的 matrix 转换为 10 个概率的方法， 可以是分别进行 sigmoid,
但更常见的是通过 softmax 函数
</p>
</div>
</div>

<div id="outline-container-org51f3b38" class="outline-4">
<h4 id="org51f3b38"><span class="section-number-4">1.5.3</span> softmax</h4>
<div class="outline-text-4" id="text-1-5-3">
<p>
\(softmax=\frac{e^{x^i}}{\sum{e^x}}\)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">softmax</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">exps</span> = np.exp<span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> exps / np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>exps<span style="color: #757575;">)</span>

<span style="color: #268bd2;">x</span>=np.array<span style="color: #757575;">(</span>[[1<span style="color: #757575;">,</span>2<span style="color: #757575;">,</span>3<span style="color: #757575;">,</span>4]]<span style="color: #757575;">)</span>
<span style="color: #859900;">print</span><span style="color: #757575;">(</span>softmax<span style="color: #757575;">(</span>x<span style="color: #757575;">))</span>
</pre>
</div>

<pre class="example" id="org2390470">
[[0.0320586  0.08714432 0.23688282 0.64391426]]
</pre>
</div>
</div>

<div id="outline-container-orgeefc0b5" class="outline-4">
<h4 id="orgeefc0b5"><span class="section-number-4">1.5.4</span> partial derivative</h4>
<div class="outline-text-4" id="text-1-5-4">
<p>
\(h=WX+B\)
</p>

<p>
\(\hat{y}=softmax(h)\)
</p>

<p>
\(J=cross\_entropy(\hat{y},y)\)
</p>

<p>
\(\frac{\partial}{\partial{W}}J(W,B) = \frac{1}{m}{\sum{(\hat{y}-y})*x}\)
</p>

<p>
\(\frac{\partial}{\partial{B}}J(W,B) = \frac{1}{m}{\sum{(\hat{y}-y})}\)
</p>
</div>
</div>

<div id="outline-container-orgd2b7b5e" class="outline-4">
<h4 id="orgd2b7b5e"><span class="section-number-4">1.5.5</span> load\_digits logistic regression example</h4>
<div class="outline-text-4" id="text-1-5-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">from</span> PIL <span style="color: #859900;">import</span> Image
<span style="color: #859900;">import</span> sys
<span style="color: #859900;">from</span> sklearn <span style="color: #859900;">import</span> preprocessing
<span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> load_digits

<span style="color: #268bd2;">EPOCH</span> = 100
<span style="color: #268bd2;">LEARNING_RATE</span> = 0.01
<span style="color: #268bd2;">BATCH_SIZE</span> = 2
<span style="color: #268bd2;">REGULARIZATION_FACTOR</span> = 0.01

<span style="color: #859900;">def</span> <span style="color: #268bd2;">softmax</span><span style="color: #757575;">(</span>z<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">s</span> = np.<span style="color: #839496;">max</span><span style="color: #757575;">(</span>z<span style="color: #757575;">,</span> axis=1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">s</span> = s[:<span style="color: #757575;">,</span> np.newaxis]  <span style="color: #586e75;"># </span><span style="color: #586e75;">necessary step to do broadcasting</span>
    <span style="color: #268bd2;">e_x</span> = np.exp<span style="color: #757575;">(</span>z - s<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">div</span> = np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>e_x<span style="color: #757575;">,</span> axis=1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">div</span> = div[:<span style="color: #757575;">,</span> np.newaxis]  <span style="color: #586e75;"># </span><span style="color: #586e75;">dito</span>
    <span style="color: #859900;">return</span> e_x / div

<span style="color: #859900;">def</span> <span style="color: #268bd2;">one_hot</span><span style="color: #757575;">(</span>Y<span style="color: #757575;">,</span> C<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">Y</span> = np.eye<span style="color: #757575;">(</span>C<span style="color: #757575;">)</span>[Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">)</span>]
    <span style="color: #859900;">return</span> Y

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cross_entropy</span><span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> labels<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">epsilon</span> = 1e-12
    <span style="color: #268bd2;">predictions</span> = np.clip<span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> epsilon<span style="color: #757575;">,</span> 1 - epsilon<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">N</span> = predictions.shape[0]

    <span style="color: #268bd2;">ce</span> = 0 - np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>labels * np.log<span style="color: #757575;">(</span>predictions<span style="color: #757575;">)))</span> / N
    <span style="color: #859900;">return</span> ce

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cost_function</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">m</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #859900;">assert</span> <span style="color: #757575;">(</span><span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span> == <span style="color: #839496;">len</span><span style="color: #757575;">(</span>Y<span style="color: #757575;">))</span>

    <span style="color: #268bd2;">J</span> = 0.

    <span style="color: #268bd2;">dw</span> = np.zeros_like<span style="color: #757575;">(</span>W<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db</span> = np.zeros_like<span style="color: #757575;">(</span>B<span style="color: #757575;">)</span>

    <span style="color: #586e75;"># </span><span style="color: #586e75;">for i in range(m):</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">x = X[i, :].reshape(1, 64)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y = Y[i, :].reshape(1, 10)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">f = np.matmul(x, W) + B</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">assert (f.shape == (1, 10))</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y_hat = softmax(f)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">assert (y.shape == y_hat.shape)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">loss = cross_entropy(y_hat, y)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">J += loss</span>

    <span style="color: #586e75;">#     </span><span style="color: #586e75;">dw += np.matmul(np.transpose(x), y_hat - y)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">db += y_hat - y</span>

    <span style="color: #586e75;"># </span><span style="color: #586e75;">J /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">db /= m</span>

    <span style="color: #268bd2;">f</span> = np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B
    <span style="color: #268bd2;">y_hat</span> = softmax<span style="color: #757575;">(</span>f<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">J</span> = cross_entropy<span style="color: #757575;">(</span>y_hat<span style="color: #757575;">,</span> Y<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">dw</span> = np.matmul<span style="color: #757575;">(</span>np.transpose<span style="color: #757575;">(</span>X<span style="color: #757575;">),</span> y_hat - Y<span style="color: #757575;">)</span> / m
    <span style="color: #268bd2;">db</span> = <span style="color: #757575;">(</span>y_hat - Y<span style="color: #757575;">)</span>.mean<span style="color: #757575;">(</span>axis=0<span style="color: #757575;">)</span>

    <span style="color: #586e75;"># </span><span style="color: #586e75;">regularation</span>
    <span style="color: #268bd2;">J</span> += REGULARIZATION_FACTOR * <span style="color: #839496;">sum</span><span style="color: #757575;">(</span><span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.square<span style="color: #757575;">(</span>W<span style="color: #757575;">)))</span> / <span style="color: #757575;">(</span>2 * m<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">dw</span> += REGULARIZATION_FACTOR * W / m
    <span style="color: #859900;">return</span> J<span style="color: #757575;">,</span> dw<span style="color: #757575;">,</span> db

<span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span> = 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0
<span style="color: #268bd2;">W</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B</span> = 0<span style="color: #757575;">,</span> 0

<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = load_digits<span style="color: #757575;">(</span>10<span style="color: #757575;">,</span> <span style="color: #268bd2; font-weight: bold;">True</span><span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = one_hot<span style="color: #757575;">(</span>Y<span style="color: #757575;">,</span> 10<span style="color: #757575;">)</span>
    [m<span style="color: #757575;">,</span> features] = X.shape
    <span style="color: #268bd2;">Z</span> = np.concatenate<span style="color: #757575;">((</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">),</span> axis=1<span style="color: #757575;">)</span>
    np.random.shuffle<span style="color: #757575;">(</span>Z<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = Z[:<span style="color: #757575;">,</span> :features]
    <span style="color: #268bd2;">Y</span> = Z[:<span style="color: #757575;">,</span> features:]
    <span style="color: #859900;">global</span> X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> X_test<span style="color: #757575;">,</span> Y_test
    <span style="color: #268bd2;">offset</span> = <span style="color: #839496;">int</span><span style="color: #757575;">(</span>0.8 * m<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span> = X[:offset]<span style="color: #757575;">,</span> Y[:offset]
    <span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span> = X[offset:]<span style="color: #757575;">,</span> Y[offset:]

<span style="color: #859900;">def</span> <span style="color: #268bd2;">gradient_decent</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">alpha</span> = LEARNING_RATE
    <span style="color: #859900;">for</span> epoch <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>EPOCH<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">batch</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span> // BATCH_SIZE
        <span style="color: #268bd2;">total_loss</span> = 0
        <span style="color: #859900;">for</span> X_batch<span style="color: #757575;">,</span> Y_batch <span style="color: #859900;">in</span> <span style="color: #839496;">zip</span><span style="color: #757575;">(</span>
                np.split<span style="color: #757575;">(</span>X[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">),</span>
                np.split<span style="color: #757575;">(</span>Y[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">))</span>:
            <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db</span> = cost_function<span style="color: #757575;">(</span>X_batch<span style="color: #757575;">,</span> Y_batch<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>
            <span style="color: #268bd2;">total_loss</span> += cost
            <span style="color: #268bd2;">W</span> = W - alpha * dw
            <span style="color: #268bd2;">B</span> = B - alpha * db
        <span style="color: #859900;">if</span> epoch % <span style="color: #757575;">(</span>EPOCH // 30<span style="color: #757575;">)</span> == 0:
            <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"training: #"</span><span style="color: #757575;">,</span> epoch<span style="color: #757575;">,</span> total_loss / batch<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> W<span style="color: #757575;">,</span> B

<span style="color: #859900;">def</span> <span style="color: #268bd2;">predict</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> X_test<span style="color: #757575;">,</span> Y_test<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B

    <span style="color: #268bd2;">wrong</span> = 0
    <span style="color: #268bd2;">correct</span> = 0
    <span style="color: #859900;">for</span> i <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span><span style="color: #839496;">len</span><span style="color: #757575;">(</span>X_test<span style="color: #757575;">))</span>:
        <span style="color: #268bd2;">x</span> = X_test[i<span style="color: #757575;">,</span> :].reshape<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> -1<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">y</span> = Y_test[i<span style="color: #757575;">,</span> :].reshape<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> -1<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">c</span> = np.matmul<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span> W<span style="color: #757575;">)</span> + B
        <span style="color: #268bd2;">y_hat</span> = softmax<span style="color: #757575;">(</span>c<span style="color: #757575;">)</span>

        <span style="color: #859900;">if</span> np.argmax<span style="color: #757575;">(</span>y_hat<span style="color: #757575;">)</span> == np.argmax<span style="color: #757575;">(</span>y<span style="color: #757575;">)</span>:
            <span style="color: #268bd2;">correct</span> += 1
        <span style="color: #859900;">else</span>:
            <span style="color: #268bd2;">wrong</span> += 1
    <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"correct: %d, wrong: %d, accuracy: %f"</span> % <span style="color: #757575;">(</span>correct<span style="color: #757575;">,</span> wrong<span style="color: #757575;">,</span> correct /
                                                    <span style="color: #757575;">(</span>correct + wrong<span style="color: #757575;">)))</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">train</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">,</span> X_train<span style="color: #757575;">,</span> Y_train
    <span style="color: #268bd2;">W</span> = np.random.randn<span style="color: #757575;">(</span>64<span style="color: #757575;">,</span> 10<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 10<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B</span> = gradient_decent<span style="color: #757575;">(</span>X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> W<span style="color: #757575;">,</span> B<span style="color: #757575;">)</span>

get_training_set<span style="color: #757575;">()</span>
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orgc16294b">
training: # 0 7.413641925368053
training: # 3 2.061976320350589
training: # 6 1.5752044059841135
training: # 9 1.25185391564078
training: # 12 1.0334895315893526
training: # 15 0.9154572322047317
training: # 18 0.7912384177526893
training: # 21 0.6569779524881322
training: # 24 0.6154367878411028
training: # 27 0.6250007208991311
training: # 30 0.519215167487594
training: # 33 0.5119700580330538
training: # 36 0.5275788708720639
training: # 39 0.5304955801897778
training: # 42 0.44298460952993773
training: # 45 0.40653637116386976
training: # 48 0.45331106089167467
training: # 51 0.37611751513467656
training: # 54 0.37240293166520994
training: # 57 0.4553268960419496
training: # 60 0.3623002402468144
training: # 63 0.37149394065324326
training: # 66 0.4276031139481319
training: # 69 0.4003649152441614
training: # 72 0.43875428025202756
training: # 75 0.40422299306062504
training: # 78 0.4026933009211833
training: # 81 0.40849225974261905
training: # 84 0.3801959998258428
training: # 87 0.3976900455580225
training: # 90 0.4330326570439522
training: # 93 0.4622412012606176
training: # 96 0.4132252813914691
training: # 99 0.3563033761424611
correct: 339, wrong: 21, accuracy: 0.941667
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf733ade" class="outline-3">
<h3 id="orgf733ade"><span class="section-number-3">1.6</span> artificial neural networks</h3>
<div class="outline-text-3" id="text-1-6">
<p>
ANN 可以看作是多层的 logistic regression 级联起来， 前一层 logistic
regression 的输出作为后一层 logistic regression 的输入
</p>


<div id="orgedcd6e2" class="figure">
<p><img src="../extra/ann1.png" alt="ann1.png" />
</p>
<p><span class="figure-number">Figure 13: </span>ann</p>
</div>

<p>
把 hidden layer 去掉， 就是一个基本的 logistic regression
</p>
</div>

<div id="outline-container-orgf584438" class="outline-4">
<h4 id="orgf584438"><span class="section-number-4">1.6.1</span> activation function</h4>
<div class="outline-text-4" id="text-1-6-1">
<p>
每个 hidden layer 中的 node 可以认为是一个 logistic regression,
即它们会完成简单的 \(sigmoid(WX+B)\) 运算，其中 sigmoid 在 ANN 中称为
activation function.
</p>

<p>
除了 sigmoid, 常用的 activation function 还有 tanh, relu 等
</p>


<div id="org06e515b" class="figure">
<p><img src="../extra/ann2.png" alt="ann2.png" />
</p>
<p><span class="figure-number">Figure 14: </span>ann2</p>
</div>
</div>
</div>

<div id="outline-container-orge4e857f" class="outline-4">
<h4 id="orge4e857f"><span class="section-number-4">1.6.2</span> relu</h4>
<div class="outline-text-4" id="text-1-6-2">
<p>
relu 是现在的推荐的 activation function
</p>

<p>
\(relu(x)=\max(x,0)\)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">relu</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> np.maximum<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> 0<span style="color: #757575;">)</span>

<span style="color: #268bd2;">x</span>=np.arange<span style="color: #757575;">(</span>-10<span style="color: #757575;">,</span>10<span style="color: #757575;">,</span>0.1<span style="color: #757575;">)</span>
plt.plot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span>relu<span style="color: #757575;">(</span>x<span style="color: #757575;">))</span>
plt.show<span style="color: #757575;">()</span>
</pre>
</div>


<div id="org8948355" class="figure">
<p><img src="machine_learning_files/machine_learning_97_0.png" alt="machine_learning_97_0.png" />
</p>
<p><span class="figure-number">Figure 15: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-orgdf9bd18" class="outline-4">
<h4 id="orgdf9bd18"><span class="section-number-4">1.6.3</span> forward propergation</h4>
<div class="outline-text-4" id="text-1-6-3">
<p>
以 mnist 为例，
</p>

<ol class="org-ol">
<li>假设 ann 有一个 hidden layer, 该 layer 有三个 node</li>

<li>input layer 有 784 个 feature</li>

<li>output layer 有 10 个 node, 对应 0~9 十个数字</li>

<li>hidden layer 使用 sigmoid 作为 activation function</li>

<li>output layer 使用 softmax + cross\_entropy 做为 cost function</li>
</ol>

<p>
input layer 与 hidden layer 之间的 W 记为 W1, 其 shape 为 [784, 3], 其中
W1[:,0] 对应 hidden layer 的第一个节点
</p>

<p>
hidden layer 与 output layer 之间的 W 记为 W2, 其 shape 为 [3,10], 其中
W2[:0] 对应 output layer 第一个节点
</p>

<p>
<i>forward propergation</i>
</p>

<p>
\(c^{1}=W^{1}X+B^{1}\)
</p>

<p>
\(a^{1}=sigmoid(c^{1})\)
</p>

<p>
\(c^{2}=W^{2}*a^{1}+B^{2}\)
</p>

<p>
\(\hat{y}=softmax(c^{2})\)
</p>

<p>
\(cost=cross\_entropy(\hat{y},y)\)
</p>
</div>
</div>

<div id="outline-container-orgd384c36" class="outline-4">
<h4 id="orgd384c36"><span class="section-number-4">1.6.4</span> backward propergation</h4>
<div class="outline-text-4" id="text-1-6-4">
<p>
需要分别计算:
</p>

<ul class="org-ul">
<li>\(\frac{\partial}{\partial{W1}}J(W1,W2,B1,B2)\)</li>
<li>\(\frac{\partial}{\partial{B1}}J(W1,W2,B1,B2)\)</li>
<li>\(\frac{\partial}{\partial{W2}}J(W1,W2,B1,B2)\)</li>
<li>\(\frac{\partial}{\partial{B2}}J(W1,W2,B1,B2)\)</li>
</ul>

<p>
\(\frac{\partial}{\partial{W2}}J(W1,W2,B1,B2)=\frac{1}{m}\sum(\hat{y}-y)a1\)
</p>

<p>
\(\frac{\partial}{\partial{B2}}J(W1,W2,B1,B2)=\frac{1}{m}\sum(\hat{y}-y)\)
</p>

<p>
<i>backward propergation</i>
</p>

<p>
\(\frac{\partial}{\partial{W1}}J(W1,W2,B1,B2)= \frac{\partial}{\partial{a1}}J(W1,W2,B1,B2) * \frac{\partial}{\partial{W1}}a{1}\)
</p>

<p>
\(\frac{\partial}{\partial{W1}}a1=a1*(1-a1)*x\)
</p>

<p>
\(\frac{\partial}{\partial{B1}}J(W1,W2,B1,B2)= \frac{\partial}{\partial{a1}}J(W1,W2,B1,B2) * \frac{\partial}{\partial{B1}}a{1}\)
</p>

<p>
\(\frac{\partial}{\partial{B1}}a1=a1*(1-a1)\)
</p>
</div>
</div>

<div id="outline-container-orgef3cd05" class="outline-4">
<h4 id="orgef3cd05"><span class="section-number-4">1.6.5</span> make\_moon ANN example</h4>
<div class="outline-text-4" id="text-1-6-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">import</span> sys
<span style="color: #859900;">from</span> sklearn <span style="color: #859900;">import</span> preprocessing
<span style="color: #859900;">from</span> matplotlib.colors <span style="color: #859900;">import</span> ListedColormap
<span style="color: #859900;">import</span> matplotlib.pyplot <span style="color: #859900;">as</span> plt
<span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> make_moons

<span style="color: #268bd2;">HIDDEN_NODES_NUM</span> = 30
<span style="color: #268bd2;">LEARNING_RATE</span> = 0.01
<span style="color: #268bd2;">EPOCH</span> = 2000
<span style="color: #268bd2;">BATCH_SIZE</span> = 100

<span style="color: #859900;">def</span> <span style="color: #268bd2;">relu</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> np.maximum<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> 0<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">relu_derivative</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> 1. * <span style="color: #757575;">(</span>X &gt; 0<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">sigmoid</span><span style="color: #757575;">(</span>x<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> 1 / <span style="color: #757575;">(</span>1 + np.exp<span style="color: #757575;">(</span>-x<span style="color: #757575;">))</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">softmax</span><span style="color: #757575;">(</span>z<span style="color: #757575;">)</span>:
    <span style="color: #859900;">assert</span> <span style="color: #839496;">len</span><span style="color: #757575;">(</span>z.shape<span style="color: #757575;">)</span> == 2
    <span style="color: #268bd2;">s</span> = np.<span style="color: #839496;">max</span><span style="color: #757575;">(</span>z<span style="color: #757575;">,</span> axis=1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">s</span> = s[:<span style="color: #757575;">,</span> np.newaxis]  <span style="color: #586e75;"># </span><span style="color: #586e75;">necessary step to do broadcasting</span>
    <span style="color: #268bd2;">e_x</span> = np.exp<span style="color: #757575;">(</span>z - s<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">div</span> = np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>e_x<span style="color: #757575;">,</span> axis=1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">div</span> = div[:<span style="color: #757575;">,</span> np.newaxis]  <span style="color: #586e75;"># </span><span style="color: #586e75;">dito</span>
    <span style="color: #859900;">return</span> e_x / div

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cross_entropy</span><span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> labels<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">epsilon</span> = 1e-12
    <span style="color: #268bd2;">predictions</span> = np.clip<span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> epsilon<span style="color: #757575;">,</span> 1 - epsilon<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">N</span> = predictions.shape[0]

    <span style="color: #268bd2;">ce</span> = 0 - np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>labels * np.log<span style="color: #757575;">(</span>predictions<span style="color: #757575;">)))</span>/N
    <span style="color: #859900;">return</span> ce

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cost_function</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>:
    <span style="color: #586e75;"># </span><span style="color: #586e75;">X:   m   *  2</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">Y:   m   *  1</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">W1:  2   *  HIDDEN_NODES_NUM</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">B1:  1   *  HIDDEN_NODES_NUM</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">W2:  HIDDEN_NODES_NUM   *  1</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">B2:  1   *  1</span>

    <span style="color: #268bd2;">m</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">J</span> = 0.
    <span style="color: #268bd2;">dw1</span> = np.zeros_like<span style="color: #757575;">(</span>W1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db1</span> = np.zeros_like<span style="color: #757575;">(</span>B1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">dw2</span> = np.zeros_like<span style="color: #757575;">(</span>W2<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db2</span> = np.zeros_like<span style="color: #757575;">(</span>B2<span style="color: #757575;">)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">for i in range(m):</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">x = X[i, :].reshape(1, 2)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y = Y[i, :].reshape(1, 1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">z1 = np.matmul(x, W1) + B1</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">a1 = relu(z1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">z2 = np.matmul(a1, W2) + B2</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y_hat = sigmoid(z2)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">loss = cross_entropy(</span>
    <span style="color: #586e75;">#            </span><span style="color: #586e75;">np.concatenate((y_hat, 1 - y_hat)), np.concatenate((y, 1 - y)))</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">J += loss</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;"># bp</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">delta3 = y_hat - y</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">dw2 += np.matmul(np.transpose(a1), delta3)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">db2 += delta3</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;"># 1*HIDDEN_NODES_NUM</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">delta2 = np.matmul(delta3, np.transpose(W2))</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">delta2 = delta2 * relu_derivative(a1)</span>

    <span style="color: #586e75;">#     </span><span style="color: #586e75;"># dw1: 784 * HIDDEN_NODES_NUM</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">dw1 += np.matmul(np.transpose(x), delta2)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;"># db1: 1 * HIDDEN_NODES_NUM</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">db1 += delta2</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">J /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw1 /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">db1 /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw2 /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">db2 /= m</span>

    <span style="color: #268bd2;">z1</span> = np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W1<span style="color: #757575;">)</span> + B1
    <span style="color: #268bd2;">a1</span> = relu<span style="color: #757575;">(</span>z1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">z2</span> = np.matmul<span style="color: #757575;">(</span>a1<span style="color: #757575;">,</span> W2<span style="color: #757575;">)</span> + B2
    <span style="color: #268bd2;">y_hat</span> = sigmoid<span style="color: #757575;">(</span>z2<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">J</span> = cross_entropy<span style="color: #757575;">(</span>
         np.c_[y_hat<span style="color: #757575;">,</span>1-y_hat]<span style="color: #757575;">,</span>np.c_[Y<span style="color: #757575;">,</span>1-Y]<span style="color: #757575;">)</span>

    <span style="color: #586e75;"># </span><span style="color: #586e75;">backward propergation</span>
    <span style="color: #268bd2;">delta3</span> = y_hat - Y
    <span style="color: #268bd2;">dw2</span> = np.matmul<span style="color: #757575;">(</span>np.transpose<span style="color: #757575;">(</span>a1<span style="color: #757575;">),</span> delta3<span style="color: #757575;">)</span> / m
    <span style="color: #268bd2;">db2</span> = delta3.mean<span style="color: #757575;">(</span>axis=0<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">delta2</span> = np.matmul<span style="color: #757575;">(</span>delta3<span style="color: #757575;">,</span> np.transpose<span style="color: #757575;">(</span>W2<span style="color: #757575;">))</span>
    <span style="color: #268bd2;">delta2</span> = delta2 * relu_derivative<span style="color: #757575;">(</span>a1<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">dw1</span> = np.matmul<span style="color: #757575;">(</span>np.transpose<span style="color: #757575;">(</span>X<span style="color: #757575;">),</span> delta2<span style="color: #757575;">)</span> / m
    <span style="color: #268bd2;">db1</span> = delta2.mean<span style="color: #757575;">(</span>axis=0<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> J<span style="color: #757575;">,</span> dw1<span style="color: #757575;">,</span> db1<span style="color: #757575;">,</span> dw2<span style="color: #757575;">,</span> db2

<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = make_moons<span style="color: #757575;">(</span>n_samples=1000<span style="color: #757575;">,</span> noise=0.2<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>1000<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = preprocessing.scale<span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> X<span style="color: #757575;">,</span> Y

<span style="color: #859900;">def</span> <span style="color: #268bd2;">gradient_decent</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">alpha</span> = LEARNING_RATE
    <span style="color: #859900;">for</span> epoch <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>EPOCH<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">batch</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span> // BATCH_SIZE
        <span style="color: #268bd2;">total_loss</span> = 0
        <span style="color: #859900;">for</span> X_batch<span style="color: #757575;">,</span> Y_batch <span style="color: #859900;">in</span> <span style="color: #839496;">zip</span><span style="color: #757575;">(</span>
                np.split<span style="color: #757575;">(</span>X[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">),</span>
                np.split<span style="color: #757575;">(</span>Y[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">))</span>:
            <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw2</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db2</span> = cost_function<span style="color: #757575;">(</span>X_batch<span style="color: #757575;">,</span> Y_batch<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span>
                                                     W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>
            <span style="color: #586e75;"># </span><span style="color: #586e75;">print("training: #", epoch, cost)</span>
            <span style="color: #268bd2;">total_loss</span> += cost
            <span style="color: #268bd2;">W1</span> = W1 - alpha * dw1
            <span style="color: #268bd2;">B1</span> = B1 - alpha * db1
            <span style="color: #268bd2;">W2</span> = W2 - alpha * dw2
            <span style="color: #268bd2;">B2</span> = B2 - alpha * db2
        <span style="color: #859900;">if</span> epoch % <span style="color: #757575;">(</span>EPOCH // 30<span style="color: #757575;">)</span> == 0:
            <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"training: #"</span><span style="color: #757575;">,</span> epoch<span style="color: #757575;">,</span> total_loss / batch<span style="color: #757575;">)</span>
    <span style="color: #859900;">return</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2

<span style="color: #859900;">def</span> <span style="color: #268bd2;">draw_decision_boundary</span><span style="color: #757575;">(</span>W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">xx</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">yy</span> = np.meshgrid<span style="color: #757575;">(</span>np.arange<span style="color: #757575;">(</span>-4<span style="color: #757575;">,</span> 4<span style="color: #757575;">,</span> 0.02<span style="color: #757575;">),</span> np.arange<span style="color: #757575;">(</span>-4<span style="color: #757575;">,</span> 4<span style="color: #757575;">,</span> 0.02<span style="color: #757575;">))</span>
    <span style="color: #268bd2;">X</span> = np.c_[xx.ravel<span style="color: #757575;">(),</span> yy.ravel<span style="color: #757575;">()</span>]

    <span style="color: #268bd2;">z1</span> = np.dot<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W1<span style="color: #757575;">)</span> + B1
    <span style="color: #268bd2;">a1</span> = relu<span style="color: #757575;">(</span>z1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">z2</span> = np.dot<span style="color: #757575;">(</span>a1<span style="color: #757575;">,</span> W2<span style="color: #757575;">)</span> + B2
    <span style="color: #268bd2;">a2</span> = sigmoid<span style="color: #757575;">(</span>z2<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">y_hat</span> = <span style="color: #757575;">(</span>a2 &gt; 0.5<span style="color: #757575;">)</span>[:<span style="color: #757575;">,</span> 0]
    <span style="color: #268bd2;">y_hat</span> = y_hat.reshape<span style="color: #757575;">(</span>xx.shape<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">cm</span> = ListedColormap<span style="color: #757575;">(</span>[<span style="color: #2aa198;">'#FF0000'</span><span style="color: #757575;">,</span> <span style="color: #2aa198;">'#0000FF'</span>]<span style="color: #757575;">)</span>
    plt.contour<span style="color: #757575;">(</span>xx<span style="color: #757575;">,</span> yy<span style="color: #757575;">,</span> y_hat<span style="color: #757575;">,</span> cmap=cm<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">train</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = get_training_set<span style="color: #757575;">()</span>
    <span style="color: #268bd2;">Z</span> = np.concatenate<span style="color: #757575;">((</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">),</span> axis=1<span style="color: #757575;">)</span>
    np.random.shuffle<span style="color: #757575;">(</span>Z<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = Z[:<span style="color: #757575;">,</span> :2]
    <span style="color: #268bd2;">Y</span> = Z[:<span style="color: #757575;">,</span> 2:]
    <span style="color: #268bd2;">W1</span> = np.random.randn<span style="color: #757575;">(</span>2<span style="color: #757575;">,</span> HIDDEN_NODES_NUM<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B1</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> HIDDEN_NODES_NUM<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W2</span> = np.random.randn<span style="color: #757575;">(</span>HIDDEN_NODES_NUM<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B2</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">W2</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B2</span> = gradient_decent<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>

<span style="color: #268bd2;">W1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">W2</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B2</span> = 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0

<span style="color: #859900;">def</span> <span style="color: #268bd2;">predict</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = get_training_set<span style="color: #757575;">()</span>
    <span style="color: #268bd2;">cm</span> = ListedColormap<span style="color: #757575;">(</span>[<span style="color: #2aa198;">'#FF0000'</span><span style="color: #757575;">,</span> <span style="color: #2aa198;">'#0000FF'</span>]<span style="color: #757575;">)</span>
    plt.scatter<span style="color: #757575;">(</span>x=X[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> y=X[:<span style="color: #757575;">,</span> 1]<span style="color: #757575;">,</span> c=Y[:<span style="color: #757575;">,</span> 0]<span style="color: #757575;">,</span> cmap=cm<span style="color: #757575;">)</span>
    draw_decision_boundary<span style="color: #757575;">(</span>W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>
    plt.show<span style="color: #757575;">()</span>

train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="org1e67104">
training: # 0 1.1010464305437424
training: # 66 0.26612700400246736
training: # 132 0.2279739563132131
training: # 198 0.205101820126328
training: # 264 0.1884051410770355
training: # 330 0.17477153275449023
training: # 396 0.16369062967529763
training: # 462 0.1545121735063119
training: # 528 0.14688858135821387
training: # 594 0.14037311583041678
training: # 660 0.13481409437384884
training: # 726 0.1299481748662618
training: # 792 0.1256549732023355
training: # 858 0.1218073002961437
training: # 924 0.11833164864213408
training: # 990 0.11520153425399286
training: # 1056 0.11239083604018733
training: # 1122 0.10985753265561604
training: # 1188 0.10755024891442373
training: # 1254 0.10549406656678581
training: # 1320 0.10362753609096016
training: # 1386 0.10193490774925815
training: # 1452 0.10040633693099095
training: # 1518 0.09902660303283958
training: # 1584 0.09776264737376265
training: # 1650 0.09658752873463469
training: # 1716 0.09549979433826702
training: # 1782 0.09442971652084056
training: # 1848 0.09343720322848759
training: # 1914 0.09254972524996466
training: # 1980 0.09171308756241331
</pre>


<div id="orgda3be86" class="figure">
<p><img src="machine_learning_files/machine_learning_107_1.png" alt="machine_learning_107_1.png" />
</p>
<p><span class="figure-number">Figure 16: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-orga0b9876" class="outline-4">
<h4 id="orga0b9876"><span class="section-number-4">1.6.6</span> gradient checking</h4>
<div class="outline-text-4" id="text-1-6-6">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">check_gradient</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = get_training_set<span style="color: #757575;">()</span>

    <span style="color: #268bd2;">W1</span> = np.random.randn<span style="color: #757575;">(</span>2<span style="color: #757575;">,</span> HIDDEN_NODES_NUM<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B1</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> HIDDEN_NODES_NUM<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W2</span> = np.random.randn<span style="color: #757575;">(</span>HIDDEN_NODES_NUM<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B2</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span><span style="color: #268bd2;">dw1</span><span style="color: #757575;">,</span><span style="color: #268bd2;">db1</span><span style="color: #757575;">,</span><span style="color: #268bd2;">dw2</span><span style="color: #757575;">,</span><span style="color: #268bd2;">db2</span>=cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span>Y<span style="color: #757575;">,</span>W1<span style="color: #757575;">,</span>B1<span style="color: #757575;">,</span>W2<span style="color: #757575;">,</span>B2<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W1</span>[0<span style="color: #757575;">,</span>0]+=1e-3
    <span style="color: #268bd2;">cost2</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span>=cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span>Y<span style="color: #757575;">,</span>W1<span style="color: #757575;">,</span>B1<span style="color: #757575;">,</span>W2<span style="color: #757575;">,</span>B2<span style="color: #757575;">)</span>
    <span style="color: #859900;">print</span><span style="color: #757575;">((</span>cost2-cost<span style="color: #757575;">)</span>/1e-3<span style="color: #757575;">,</span>dw1[0<span style="color: #757575;">,</span>0]<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W1</span>[0<span style="color: #757575;">,</span>0]-=1e-3

    <span style="color: #268bd2;">W2</span>[0<span style="color: #757575;">,</span>0]+=1e-3
    <span style="color: #268bd2;">cost2</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span><span style="color: #757575;">,</span><span style="color: #268bd2;">_</span>=cost_function<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span>Y<span style="color: #757575;">,</span>W1<span style="color: #757575;">,</span>B1<span style="color: #757575;">,</span>W2<span style="color: #757575;">,</span>B2<span style="color: #757575;">)</span>
    <span style="color: #859900;">print</span><span style="color: #757575;">((</span>cost2-cost<span style="color: #757575;">)</span>/1e-3<span style="color: #757575;">,</span>dw2[0<span style="color: #757575;">,</span>0]<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">W2</span>[0<span style="color: #757575;">,</span>0]-=1e-3

check_gradient<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="org2d51cc4">
-0.11087431749534638 -0.11087971896090518
0.2626766888012 0.2626112969246978
</pre>
</div>
</div>

<div id="outline-container-orgeb0519c" class="outline-4">
<h4 id="orgeb0519c"><span class="section-number-4">1.6.7</span> ANN underfitting</h4>
<div class="outline-text-4" id="text-1-6-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">HIDDEN_NODES_NUM</span> = 2
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orge0e84bb">
training: # 0 0.2648734052642972
training: # 66 0.19051075781763988
training: # 132 0.16981209881990778
training: # 198 0.1601615756297182
training: # 264 0.15477825811739088
training: # 330 0.15119051277788853
training: # 396 0.14873291511906206
training: # 462 0.1469816534584579
training: # 528 0.14558059343098362
training: # 594 0.14465389497268938
training: # 660 0.14397394615231032
training: # 726 0.14345675216822246
training: # 792 0.1429674772570023
training: # 858 0.14263718647940898
training: # 924 0.14242584431954342
training: # 990 0.14230632971907475
training: # 1056 0.142229241092
training: # 1122 0.1421798949537487
training: # 1188 0.14214490864219884
training: # 1254 0.14210683414275965
training: # 1320 0.14206771306265004
training: # 1386 0.14201645856299278
training: # 1452 0.14195097849497493
training: # 1518 0.1419079606039002
training: # 1584 0.14188212493955574
training: # 1650 0.14184885602018105
training: # 1716 0.14181514251831864
training: # 1782 0.14177638752625493
training: # 1848 0.14173627526074
training: # 1914 0.14171024414399375
training: # 1980 0.1416899151978159
</pre>


<div id="orgd254854" class="figure">
<p><img src="machine_learning_files/machine_learning_111_1.png" alt="machine_learning_111_1.png" />
</p>
<p><span class="figure-number">Figure 17: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org5b92140" class="outline-4">
<h4 id="org5b92140"><span class="section-number-4">1.6.8</span> ANN overfitting</h4>
<div class="outline-text-4" id="text-1-6-8">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #268bd2;">HIDDEN_NODES_NUM</span> = 500
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="orgdd065c0">
training: # 0 2.0567161790524358
training: # 66 0.04604867297108463
training: # 132 0.03752036254177539
training: # 198 0.034219530144220814
training: # 264 0.03230772048803781
training: # 330 0.030934205053510792
training: # 396 0.02990669936277099
training: # 462 0.029094081507601677
training: # 528 0.028367062027028496
training: # 594 0.027774583043645072
training: # 660 0.027274793841699875
training: # 726 0.026865490017476307
training: # 792 0.026495695363192913
training: # 858 0.026169749917253328
training: # 924 0.02587170841831545
training: # 990 0.025602493238891168
training: # 1056 0.02536622820636284
training: # 1122 0.025144524174879168
training: # 1188 0.02492772562338179
training: # 1254 0.02471288682522171
training: # 1320 0.024507402054118534
training: # 1386 0.024313735181501994
training: # 1452 0.024136089408418184
training: # 1518 0.02397675666435648
training: # 1584 0.0238277056608206
training: # 1650 0.02367850858998746
training: # 1716 0.023515055913084094
training: # 1782 0.02335790705150862
training: # 1848 0.02323471795470979
training: # 1914 0.023123359844330806
training: # 1980 0.023017238312910197
</pre>


<div id="orgfd5d7e4" class="figure">
<p><img src="machine_learning_files/machine_learning_113_1.png" alt="machine_learning_113_1.png" />
</p>
<p><span class="figure-number">Figure 18: </span>png</p>
</div>
</div>
</div>

<div id="outline-container-org60a7195" class="outline-4">
<h4 id="org60a7195"><span class="section-number-4">1.6.9</span> load\_digits ANN example</h4>
<div class="outline-text-4" id="text-1-6-9">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">import</span> sys
<span style="color: #859900;">from</span> sklearn <span style="color: #859900;">import</span> preprocessing
<span style="color: #859900;">from</span> sklearn.datasets <span style="color: #859900;">import</span> load_digits

<span style="color: #268bd2;">HIDDEN_NODES_NUM</span> = 30
<span style="color: #268bd2;">LEARNING_RATE</span> = 0.01
<span style="color: #268bd2;">EPOCH</span> = 100
<span style="color: #268bd2;">BATCH_SIZE</span> = 2
<span style="color: #268bd2;">REGULARIZATION_FACTOR</span> = 0.01
<span style="color: #268bd2;">USE_RELU</span> = <span style="color: #268bd2; font-weight: bold;">False</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">relu</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> np.maximum<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> 0<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">relu_derivative</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> 1. * <span style="color: #757575;">(</span>X &gt; 0<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">sigmoid</span><span style="color: #757575;">(</span>x<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> 1 / <span style="color: #757575;">(</span>1 + np.exp<span style="color: #757575;">(</span>-x<span style="color: #757575;">))</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">sigmoid_derivative</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> X * <span style="color: #757575;">(</span>1 - X<span style="color: #757575;">)</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">softmax</span><span style="color: #757575;">(</span>z<span style="color: #757575;">)</span>:
    <span style="color: #859900;">assert</span> <span style="color: #839496;">len</span><span style="color: #757575;">(</span>z.shape<span style="color: #757575;">)</span> == 2
    <span style="color: #268bd2;">s</span> = np.<span style="color: #839496;">max</span><span style="color: #757575;">(</span>z<span style="color: #757575;">,</span> axis=1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">s</span> = s[:<span style="color: #757575;">,</span> np.newaxis]  <span style="color: #586e75;"># </span><span style="color: #586e75;">necessary step to do broadcasting</span>
    <span style="color: #268bd2;">e_x</span> = np.exp<span style="color: #757575;">(</span>z - s<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">div</span> = np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>e_x<span style="color: #757575;">,</span> axis=1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">div</span> = div[:<span style="color: #757575;">,</span> np.newaxis]  <span style="color: #586e75;"># </span><span style="color: #586e75;">dito</span>
    <span style="color: #859900;">return</span> e_x / div

<span style="color: #859900;">def</span> <span style="color: #268bd2;">one_hot</span><span style="color: #757575;">(</span>Y<span style="color: #757575;">,</span> C<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">Y</span> = np.eye<span style="color: #757575;">(</span>C<span style="color: #757575;">)</span>[Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">)</span>]
    <span style="color: #859900;">return</span> Y

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cross_entropy</span><span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> labels<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">epsilon</span> = 1e-12
    <span style="color: #268bd2;">predictions</span> = np.clip<span style="color: #757575;">(</span>predictions<span style="color: #757575;">,</span> epsilon<span style="color: #757575;">,</span> 1 - epsilon<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">N</span> = predictions.shape[0]

    <span style="color: #268bd2;">ce</span> = 0 - np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>labels * np.log<span style="color: #757575;">(</span>predictions<span style="color: #757575;">)))</span> / N
    <span style="color: #859900;">return</span> ce

<span style="color: #859900;">def</span> <span style="color: #268bd2;">cost_function</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">m</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>
    <span style="color: #859900;">assert</span> <span style="color: #757575;">(</span><span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span> == <span style="color: #839496;">len</span><span style="color: #757575;">(</span>Y<span style="color: #757575;">))</span>

    <span style="color: #268bd2;">J</span> = 0.

    <span style="color: #268bd2;">dw1</span> = np.zeros_like<span style="color: #757575;">(</span>W1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db1</span> = np.zeros_like<span style="color: #757575;">(</span>B1<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">dw2</span> = np.zeros_like<span style="color: #757575;">(</span>W2<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">db2</span> = np.zeros_like<span style="color: #757575;">(</span>B2<span style="color: #757575;">)</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">normal</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">for i in range(m):</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">x = X[i, :].reshape(1, -1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y = Y[i, :].reshape(1, -1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">z1 = np.matmul(x, W1) + B1</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">if USE_RELU:</span>
    <span style="color: #586e75;">#         </span><span style="color: #586e75;">a1 = relu(z1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">else:</span>
    <span style="color: #586e75;">#         </span><span style="color: #586e75;">a1 = sigmoid(z1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">z2 = np.matmul(a1, W2) + B2</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">y_hat = softmax(z2)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">loss = cross_entropy(y_hat, y)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">J += loss</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;"># bp</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">delta3 = y_hat - y</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">dw2 += np.matmul(np.transpose(a1), delta3)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">db2 += delta3</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">delta2 = np.matmul(delta3, np.transpose(W2))</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">if USE_RELU:</span>
    <span style="color: #586e75;">#         </span><span style="color: #586e75;">delta2 = delta2 * relu_derivative(a1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">else:</span>
    <span style="color: #586e75;">#         </span><span style="color: #586e75;">delta2 = delta2 * sigmoid_derivative(a1)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">dw1 += np.matmul(np.transpose(x), delta2)</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">db1 += delta2</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">J += REGULARIZATION_FACTOR * (</span>
    <span style="color: #586e75;">#     </span><span style="color: #586e75;">np.sum(np.sum(np.square(W1))) + np.sum(np.sum(np.square(W2)))) / 2</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw1 += REGULARIZATION_FACTOR * W1</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw2 += REGULARIZATION_FACTOR * W2</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">J /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw1 /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">db1 /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">dw2 /= m</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">db2 /= m</span>

    <span style="color: #586e75;"># </span><span style="color: #586e75;">vectorization</span>
    <span style="color: #268bd2;">z1</span> = np.matmul<span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> W1<span style="color: #757575;">)</span> + B1
    <span style="color: #859900;">if</span> USE_RELU:
        <span style="color: #268bd2;">a1</span> = relu<span style="color: #757575;">(</span>z1<span style="color: #757575;">)</span>
    <span style="color: #859900;">else</span>:
        <span style="color: #268bd2;">a1</span> = sigmoid<span style="color: #757575;">(</span>z1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">z2</span> = np.matmul<span style="color: #757575;">(</span>a1<span style="color: #757575;">,</span> W2<span style="color: #757575;">)</span> + B2
    <span style="color: #268bd2;">y_hat</span> = softmax<span style="color: #757575;">(</span>z2<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">J</span> = cross_entropy<span style="color: #757575;">(</span>y_hat<span style="color: #757575;">,</span> Y<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">delta3</span> = y_hat - Y
    <span style="color: #268bd2;">dw2</span> = np.matmul<span style="color: #757575;">(</span>np.transpose<span style="color: #757575;">(</span>a1<span style="color: #757575;">),</span> delta3<span style="color: #757575;">)</span> / m
    <span style="color: #268bd2;">db2</span> = delta3.mean<span style="color: #757575;">(</span>axis=0<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">delta2</span> = np.matmul<span style="color: #757575;">(</span>delta3<span style="color: #757575;">,</span> np.transpose<span style="color: #757575;">(</span>W2<span style="color: #757575;">))</span>
    <span style="color: #859900;">if</span> USE_RELU:
        <span style="color: #268bd2;">delta2</span> = delta2 * relu_derivative<span style="color: #757575;">(</span>a1<span style="color: #757575;">)</span>
    <span style="color: #859900;">else</span>:
        <span style="color: #268bd2;">delta2</span> = delta2 * sigmoid_derivative<span style="color: #757575;">(</span>a1<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">dw1</span> = np.matmul<span style="color: #757575;">(</span>np.transpose<span style="color: #757575;">(</span>X<span style="color: #757575;">),</span> delta2<span style="color: #757575;">)</span> / m
    <span style="color: #268bd2;">db1</span> = delta2.mean<span style="color: #757575;">(</span>axis=0<span style="color: #757575;">)</span>

    <span style="color: #586e75;"># </span><span style="color: #586e75;">regulation</span>
    <span style="color: #268bd2;">J</span> += REGULARIZATION_FACTOR * <span style="color: #757575;">(</span>
        np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.square<span style="color: #757575;">(</span>W1<span style="color: #757575;">)))</span> + np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>np.square<span style="color: #757575;">(</span>W2<span style="color: #757575;">))))</span> / <span style="color: #757575;">(</span>
            2 * m<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">dw1</span> += REGULARIZATION_FACTOR * W1 / m
    <span style="color: #268bd2;">dw2</span> += REGULARIZATION_FACTOR * W2 / m

    <span style="color: #859900;">return</span> J<span style="color: #757575;">,</span> dw1<span style="color: #757575;">,</span> db1<span style="color: #757575;">,</span> dw2<span style="color: #757575;">,</span> db2

<span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span> = 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0
<span style="color: #268bd2;">W1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">W2</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B2</span> = 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0<span style="color: #757575;">,</span> 0

<span style="color: #859900;">def</span> <span style="color: #268bd2;">get_training_set</span><span style="color: #757575;">()</span>:
    <span style="color: #268bd2;">X</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y</span> = load_digits<span style="color: #757575;">(</span>10<span style="color: #757575;">,</span> <span style="color: #268bd2; font-weight: bold;">True</span><span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = Y.reshape<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">Y</span> = one_hot<span style="color: #757575;">(</span>Y<span style="color: #757575;">,</span> 10<span style="color: #757575;">)</span>
    [m<span style="color: #757575;">,</span> features] = X.shape
    <span style="color: #268bd2;">Z</span> = np.concatenate<span style="color: #757575;">((</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">),</span> axis=1<span style="color: #757575;">)</span>
    np.random.shuffle<span style="color: #757575;">(</span>Z<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X</span> = Z[:<span style="color: #757575;">,</span> :features]
    <span style="color: #268bd2;">Y</span> = Z[:<span style="color: #757575;">,</span> features:]
    <span style="color: #859900;">global</span> X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> X_test<span style="color: #757575;">,</span> Y_test
    <span style="color: #268bd2;">offset</span> = <span style="color: #839496;">int</span><span style="color: #757575;">(</span>0.8 * m<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">X_train</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_train</span> = X[:offset]<span style="color: #757575;">,</span> Y[:offset]
    <span style="color: #268bd2;">X_test</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">Y_test</span> = X[offset:]<span style="color: #757575;">,</span> Y[offset:]

<span style="color: #859900;">def</span> <span style="color: #268bd2;">gradient_decent</span><span style="color: #757575;">(</span>X<span style="color: #757575;">,</span> Y<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">alpha</span> = LEARNING_RATE
    <span style="color: #859900;">for</span> epoch <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>EPOCH<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">batch</span> = <span style="color: #839496;">len</span><span style="color: #757575;">(</span>X<span style="color: #757575;">)</span> // BATCH_SIZE
        <span style="color: #268bd2;">total_loss</span> = 0
        <span style="color: #859900;">for</span> X_batch<span style="color: #757575;">,</span> Y_batch <span style="color: #859900;">in</span> <span style="color: #839496;">zip</span><span style="color: #757575;">(</span>
                np.split<span style="color: #757575;">(</span>X[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">),</span>
                np.split<span style="color: #757575;">(</span>Y[:batch * BATCH_SIZE]<span style="color: #757575;">,</span> batch<span style="color: #757575;">))</span>:
            <span style="color: #268bd2;">cost</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">dw2</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">db2</span> = cost_function<span style="color: #757575;">(</span>X_batch<span style="color: #757575;">,</span> Y_batch<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span>
                                                     W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>
            <span style="color: #268bd2;">total_loss</span> += cost
            <span style="color: #268bd2;">W1</span> = W1 - alpha * dw1
            <span style="color: #268bd2;">B1</span> = B1 - alpha * db1
            <span style="color: #268bd2;">W2</span> = W2 - alpha * dw2
        <span style="color: #859900;">if</span> epoch % <span style="color: #757575;">(</span>EPOCH // 20<span style="color: #757575;">)</span> == 0:
            <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"training: #"</span><span style="color: #757575;">,</span> epoch<span style="color: #757575;">,</span> total_loss / batch<span style="color: #757575;">)</span>

    <span style="color: #859900;">return</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2

<span style="color: #859900;">def</span> <span style="color: #268bd2;">predict</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> X_test<span style="color: #757575;">,</span> Y_test<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2

    <span style="color: #268bd2;">wrong</span> = 0
    <span style="color: #268bd2;">correct</span> = 0
    <span style="color: #859900;">for</span> i <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span><span style="color: #839496;">len</span><span style="color: #757575;">(</span>X_test<span style="color: #757575;">))</span>:
        <span style="color: #268bd2;">x</span> = X_test[i<span style="color: #757575;">,</span> :].reshape<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> -1<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">y</span> = Y_test[i<span style="color: #757575;">,</span> :].reshape<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> -1<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">z1</span> = np.matmul<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span> W1<span style="color: #757575;">)</span> + B1
        <span style="color: #859900;">if</span> USE_RELU:
            <span style="color: #268bd2;">a1</span> = relu<span style="color: #757575;">(</span>z1<span style="color: #757575;">)</span>
        <span style="color: #859900;">else</span>:
            <span style="color: #268bd2;">a1</span> = sigmoid<span style="color: #757575;">(</span>z1<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">z2</span> = np.matmul<span style="color: #757575;">(</span>a1<span style="color: #757575;">,</span> W2<span style="color: #757575;">)</span> + B2
        <span style="color: #268bd2;">a2</span> = softmax<span style="color: #757575;">(</span>z2<span style="color: #757575;">)</span>

        <span style="color: #859900;">if</span> np.argmax<span style="color: #757575;">(</span>a2<span style="color: #757575;">)</span> == np.argmax<span style="color: #757575;">(</span>y<span style="color: #757575;">)</span>:
            <span style="color: #268bd2;">correct</span> += 1
        <span style="color: #859900;">else</span>:
            <span style="color: #268bd2;">wrong</span> += 1
    <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"correct: %d, wrong: %d, accuracy: %f"</span> % <span style="color: #757575;">(</span>correct<span style="color: #757575;">,</span> wrong<span style="color: #757575;">,</span> correct /
                                                    <span style="color: #757575;">(</span>correct + wrong<span style="color: #757575;">)))</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">train</span><span style="color: #757575;">()</span>:
    <span style="color: #859900;">global</span> W1<span style="color: #757575;">,</span> B2<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">,</span> X_train<span style="color: #757575;">,</span> Y_train
    <span style="color: #268bd2;">W1</span> = np.random.randn<span style="color: #757575;">(</span>64<span style="color: #757575;">,</span> HIDDEN_NODES_NUM<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B1</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> HIDDEN_NODES_NUM<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">W2</span> = np.random.randn<span style="color: #757575;">(</span>HIDDEN_NODES_NUM<span style="color: #757575;">,</span> 10<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">B2</span> = np.random.randn<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 10<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">W1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B1</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">W2</span><span style="color: #757575;">,</span> <span style="color: #268bd2;">B2</span> = gradient_decent<span style="color: #757575;">(</span>X_train<span style="color: #757575;">,</span> Y_train<span style="color: #757575;">,</span> W1<span style="color: #757575;">,</span> B1<span style="color: #757575;">,</span> W2<span style="color: #757575;">,</span> B2<span style="color: #757575;">)</span>

get_training_set<span style="color: #757575;">()</span>
train<span style="color: #757575;">()</span>
predict<span style="color: #757575;">()</span>
</pre>
</div>

<pre class="example" id="org4399f0d">
training: # 0 8.179987275868209
training: # 5 4.487616756607857
training: # 10 3.190552810756847
training: # 15 2.3609422313800867
training: # 20 1.7760653062722396
training: # 25 1.3739858353803298
training: # 30 1.0825991991172912
training: # 35 0.8802306595921261
training: # 40 0.7309049938786311
training: # 45 0.6226726072585916
training: # 50 0.5489742276092043
training: # 55 0.49740708896607166
training: # 60 0.46216408821398436
training: # 65 0.43638596801652746
training: # 70 0.4120282356053934
training: # 75 0.3927758648862652
training: # 80 0.3769661143322518
training: # 85 0.36297691382952496
training: # 90 0.3523873696978746
training: # 95 0.34356971806469333
correct: 350, wrong: 10, accuracy: 0.972222
</pre>
</div>
</div>
</div>

<div id="outline-container-org9f5e089" class="outline-3">
<h3 id="org9f5e089"><span class="section-number-3">1.7</span> What's Next</h3>
<div class="outline-text-3" id="text-1-7">
<ul class="org-ul">
<li>Convolutional neural networks (ConvNets)</li>
<li>Recurrent neural networks</li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: <br />
Last updated: 2022-01-25 二 14:10</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
