<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>t-SNE</title>

<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">t-SNE</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org000000d">1. t-SNE</a>
<ul>
<li><a href="#org0000000">1.1. SNE 与 t-SNE</a></li>
<li><a href="#org0000003">1.2. 实现</a></li>
<li><a href="#org0000006">1.3. t-SNE 用途</a></li>
<li><a href="#org000000a">1.4. PCA, t-SNE and auto-encoder</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org000000d" class="outline-2">
<h2 id="org000000d"><span class="section-number-2">1.</span> t-SNE</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org0000000" class="outline-3">
<h3 id="org0000000"><span class="section-number-3">1.1.</span> SNE 与 t-SNE</h3>
<div class="outline-text-3" id="text-1-1">
<p>
t-SNE<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup> 是一种非监督的数据降维算法, 其基本思想是, 把高维的 X 映射到低维的 Y, 期望任意两点, 在高维空间中的`距离`与低维空间中`距离`相近. 这里的`距离`并非欧氏距离,
而是基于欧氏距离的某种概率表示. t-SNE 使用用梯度下降的方法, 其损失函数为高维`距离`的分布与低维`距离`分布的 KL 散度.
</p>

<p>
t-SNE 以 SNE 为基础, SNE 算法的步骤:
</p>

<ol class="org-ol">
<li>假设样本数为 m, 计算一个 \(R^{m\times m}\) 的矩阵 P, 其中 \(P_{ji} =
   \frac{\exp(-\frac{||X_i-X_j||^2}{2\delta^2})}{\sum{\exp{-\frac{||X_i-X_k||^2}{2\delta^2}}}}\)
\(P_{ji}\) 的样子与 softmax 很像, 与高斯分布的概率密度函数也有类似. 可以把 \(P\)
理解为 <code>第 j 个点是第 i 个点的邻近点的概率, 服从高斯分布</code>, 直观上看, \(x_i\) 与
\(x_j\) 的欧氏距离越小, 其概率越大. 所以 P 可以看作是另一种形式的`距离`</li>

<li>定义一个 embedding, 即一张查找表, 这个表的大小为 \(R^{m\times n}\), 每个点 \(X_i\) 被映射为一个大小为 n 的向量 \(Y_i\), 表示 X 降维到 Y</li>

<li>计算另一个 \(R^{m\times m}\) 的矩阵 Q, 其中 \(Q_{ji} =
   \frac{\exp(-\frac{||Y_i-Y_j||^2}{2\delta^2})}{\sum{\exp{-\frac{||Y_i-Y_k||^2}{2\delta^2}}}}\)</li>

<li>计算 KL(P,Q) 做为损失函数. KL 即 KL divergence, 对于两个概率分布 p, q,
\(KL(p,q)=\sum{p_i*\big(log(p_i)-log(q_i)\big)}\), KL 与 cross entropy 类似, 可以评价两个概率分布的相似性</li>

<li>对 KL(P,Q) 进行梯度下降, 需要被优化的参数是 embedding, 即 Y</li>
</ol>

<p>
t-SNE 是把 SNE 中 Q 的计算变为 \(Q_{ij}=\frac{(1+||Y_i-Y_j||^2)^{-1}}{\sum{(1+||Y_k-Y_i||^2)^{-1}}}\), 即由高斯分布变为 t 分布
</p>
</div>
</div>

<div id="outline-container-org0000003" class="outline-3">
<h3 id="org0000003"><span class="section-number-3">1.2.</span> 实现</h3>
<div class="outline-text-3" id="text-1-2">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter"># </span><span class="org-comment">https://github.com/cemoody/topicsne</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">1. &#35745;&#31639; p</span>
<span class="org-variable-name">distances</span> = pairwise_distances(pos, metric=metric, squared=<span class="org-constant">True</span>)
pij = manifold.t_sne._joint_probabilities(distances, perplexity, <span class="org-constant">False</span>)


<span class="org-comment-delimiter"># </span><span class="org-comment">2. &#35745;&#31639; q &#21450; KL divergence</span>
<span class="org-keyword">class</span> <span class="org-type">TSNE</span>(nn.Module):
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>, n_points, n_topics, n_dim):
        <span class="org-keyword">self</span>.n_points = n_points
        <span class="org-keyword">self</span>.n_dim = n_dim
        <span class="org-builtin">super</span>(TSNE, <span class="org-keyword">self</span>).__init__()
        <span class="org-keyword">self</span>.logits = nn.Embedding(n_points, n_topics)

    <span class="org-keyword">def</span> <span class="org-function-name">forward</span>(<span class="org-keyword">self</span>, pij, i, j):
        x = <span class="org-keyword">self</span>.logits.weight
        dkl2 = pairwise(x)
        n_diagonal = dkl2.size()[0]
        part = (1 + dkl2).<span class="org-builtin">pow</span>(-1.0).<span class="org-builtin">sum</span>() - n_diagonal
        xi = <span class="org-keyword">self</span>.logits(i)
        xj = <span class="org-keyword">self</span>.logits(j)
        num = ((1. + (xi - xj)**2.0).<span class="org-builtin">sum</span>(1)).<span class="org-builtin">pow</span>(-1.0).squeeze()
        qij = num / part.expand_as(num)
        <span class="org-comment-delimiter"># </span><span class="org-comment">Compute KL divergence</span>
        loss_kld = pij * (torch.log(pij) - torch.log(qij))
        <span class="org-keyword">return</span> loss_kld.<span class="org-builtin">sum</span>()
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000006" class="outline-3">
<h3 id="org0000006"><span class="section-number-3">1.3.</span> t-SNE 用途</h3>
<div class="outline-text-3" id="text-1-3">
<p>
t-SNE 的主要用途是高维数据的可视化, 因为它可以把高维数据映射到低维(例如 2 维),
而且能保持原来的 clustering 关系.
</p>

<p>
通常 t-SNE 也被认为是一种非线性的降维算法, 与 PCA, autoencoder 类似. 但 t-SNE 一般不能像 PCA, autoencoder 那样做为降维算法对监督学习的数据进行预处理<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>. 因为
t-SNE 学习到的是一个针对每个点的映射表(大小为 m*m*n), 并不知道如何把 X 的 k 的
feature 通过运算映射为 Y 的 n 的 feature (k*n). 对于没有见过的数据, t-SNE 无法处理.<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>
</p>

<p>
以 sklearn 的 TSNE 为例, 它只提供了 fit_transform 的 api, 并没有提供单独的
transform api, 原因同上 <sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup>
</p>
</div>
</div>

<div id="outline-container-org000000a" class="outline-3">
<h3 id="org000000a"><span class="section-number-3">1.4.</span> PCA, t-SNE and auto-encoder</h3>
<div class="outline-text-3" id="text-1-4">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">from</span> matplotlib <span class="org-keyword">import</span> pyplot <span class="org-keyword">as</span> plt
<span class="org-keyword">from</span> sklearn <span class="org-keyword">import</span> datasets
<span class="org-keyword">from</span> sklearn.decomposition <span class="org-keyword">import</span> PCA
<span class="org-keyword">from</span> sklearn.manifold <span class="org-keyword">import</span> TSNE

plt.style.use(<span class="org-string">"classic"</span>)

<span class="org-variable-name">iris</span> = datasets.load_iris()

<span class="org-variable-name">X</span> = iris.data
<span class="org-variable-name">y</span> = iris.target

<span class="org-variable-name">target_ids</span> = <span class="org-builtin">range</span>(<span class="org-builtin">len</span>(iris.target_names))

<span class="org-comment-delimiter"># </span><span class="org-comment">PCA</span>
<span class="org-variable-name">pca</span> = PCA(n_components=2, random_state=0)
X_2d = pca.fit_transform(X)

plt.subplot(131)
plt.title(<span class="org-string">"pca"</span>)
colors = <span class="org-string">'r'</span>, <span class="org-string">'g'</span>, <span class="org-string">'b'</span>, <span class="org-string">'c'</span>, <span class="org-string">'m'</span>, <span class="org-string">'y'</span>, <span class="org-string">'k'</span>, <span class="org-string">'w'</span>, <span class="org-string">'orange'</span>, <span class="org-string">'purple'</span>
<span class="org-keyword">for</span> i, c, label <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(target_ids, colors, iris.target_names):
    plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], c=c, label=label)

<span class="org-comment-delimiter"># </span><span class="org-comment">TSNE</span>
tsne = TSNE(n_components=2, random_state=0)
X_2d = tsne.fit_transform(X)
colors = <span class="org-string">'r'</span>, <span class="org-string">'g'</span>, <span class="org-string">'b'</span>, <span class="org-string">'c'</span>, <span class="org-string">'m'</span>, <span class="org-string">'y'</span>, <span class="org-string">'k'</span>, <span class="org-string">'w'</span>, <span class="org-string">'orange'</span>, <span class="org-string">'purple'</span>
plt.subplot(132)
plt.title(<span class="org-string">"tsne"</span>)
<span class="org-keyword">for</span> i, c, label <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(target_ids, colors, iris.target_names):
    plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], c=c, label=label)

<span class="org-comment-delimiter"># </span><span class="org-comment">autoencoder</span>
<span class="org-keyword">import</span> torch
<span class="org-keyword">from</span> torch <span class="org-keyword">import</span> nn
<span class="org-keyword">from</span> torch <span class="org-keyword">import</span> optim
<span class="org-keyword">from</span> torch.utils.data <span class="org-keyword">import</span> DataLoader, Dataset


<span class="org-comment-delimiter"># </span><span class="org-comment">---------- data ----------</span>
<span class="org-keyword">class</span> <span class="org-type">PlainDataset</span>(Dataset):
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>):
        <span class="org-keyword">self</span>.X = torch.from_numpy(X).<span class="org-builtin">float</span>()
        <span class="org-keyword">self</span>.Y = <span class="org-keyword">self</span>.X

    <span class="org-keyword">def</span> <span class="org-function-name">__getitem__</span>(<span class="org-keyword">self</span>, index):
        <span class="org-keyword">return</span> <span class="org-keyword">self</span>.X[index], <span class="org-keyword">self</span>.Y[index]

    <span class="org-keyword">def</span> <span class="org-function-name">__len__</span>(<span class="org-keyword">self</span>):
        <span class="org-keyword">return</span> <span class="org-builtin">len</span>(<span class="org-keyword">self</span>.X)


training_set = PlainDataset()
training_loader = DataLoader(training_set, batch_size=30, shuffle=<span class="org-constant">True</span>)


<span class="org-keyword">def</span> <span class="org-function-name">train</span>():
    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(5000):
        <span class="org-keyword">for</span> x, y <span class="org-keyword">in</span> training_loader:
            loss = criterion(model(x), y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        <span class="org-comment-delimiter"># </span><span class="org-comment">if i % 20 == 0:</span>
        <span class="org-comment-delimiter">#     </span><span class="org-comment">print("epoch #%d: loss: %f" % (i, loss.item()))</span>


<span class="org-comment-delimiter"># </span><span class="org-comment">---------- model ----------</span>

model = nn.Sequential(nn.Linear(4, 2), nn.ReLU(), nn.Linear(2, 4))
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.001)

train()
X_2d = model[0](torch.from_numpy(X).<span class="org-builtin">float</span>()).detach().numpy()
colors = <span class="org-string">'r'</span>, <span class="org-string">'g'</span>, <span class="org-string">'b'</span>, <span class="org-string">'c'</span>, <span class="org-string">'m'</span>, <span class="org-string">'y'</span>, <span class="org-string">'k'</span>, <span class="org-string">'w'</span>, <span class="org-string">'orange'</span>, <span class="org-string">'purple'</span>
plt.subplot(133)
plt.title(<span class="org-string">"auto-encoder"</span>)
<span class="org-keyword">for</span> i, c, label <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(target_ids, colors, iris.target_names):
    plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], c=c, label=label)

plt.show()
</pre>
</div>


<div id="org0000009" class="figure">
<p><img src="../extra/iris.png" alt="iris.png" />
</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/">从 SNE 到 t-SNE</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://stats.stackexchange.com/questions/340175/why-is-t-sne-not-used-as-a-dimensionality-reduction-technique-for-clustering-or">Why is t-SNE not used as a dimensionality reduction technique</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.scipy-lectures.org/packages/scikit-learn/index.html">Visualization with a non-linear embedding: tSNE</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://github.com/scikit-learn/scikit-learn/issues/5361">tsne has no transform function</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2018-08-30 Thu 00:00<br />
Last updated: 2021-08-11 Wed 21:04</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
