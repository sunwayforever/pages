<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>Inception</title>

<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Inception</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org000001a">1. Inception</a>
<ul>
<li><a href="#org0000017">1.1. Network</a>
<ul>
<li><a href="#org000000a">1.1.1. InceptionV3</a></li>
<li><a href="#ID-1f241bc2-3a32-4a81-a8bd-1d363effe635">1.1.2. Efficient Grid Size Reduction</a></li>
<li><a href="#ID-3a113993-aa89-438f-a265-b54930e449dc">1.1.3. Auxiliary Classifier</a></li>
<li><a href="#org0000014">1.1.4. Label Smoothing</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org000001a" class="outline-2">
<h2 id="org000001a"><span class="section-number-2">1</span> Inception</h2>
<div class="outline-text-2" id="text-1">
<p>
inception 系列中最早的模型是 <a href="https://arxiv.org/pdf/1409.4842.pdf">GoogleNet</a> (2014/9), 提出了 inception 模块. 
</p>

<p>
后来 <a href="https://arxiv.org/pdf/1512.00567.pdf">Rethinking the Inception Architecture for Computer Vision</a> (2015/12, google) 提出了
inception_v2 和inception_v3, 其中 v2 提出了 batchnorm, v3 提出了 factoried conv,
asymmetric conv
</p>
</div>

<div id="outline-container-org0000017" class="outline-3">
<h3 id="org0000017"><span class="section-number-3">1.1</span> Network</h3>
<div class="outline-text-3" id="text-1-1">

<div id="org0000000" class="figure">
<p><img src="../extra/inception.png" alt="inception.png" />
</p>
</div>
</div>

<div id="outline-container-org000000a" class="outline-4">
<h4 id="org000000a"><span class="section-number-4">1.1.1</span> InceptionV3</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
图中的 A, B, C 是三种不同规格的 inception 模块. 注意所有的 inception 模块都是
stride 为 1 和 same padding, 它们没有 downsample 的功能
</p>
</div>

<div id="outline-container-org0000002" class="outline-5">
<h5 id="org0000002"><span class="section-number-5">1.1.1.1</span> Factoried Conv</h5>
<div class="outline-text-5" id="text-1-1-1-1">
<p>
A 是 factoried conv, 是指用两个 3x3 的 conv 代替 5x5 的 conv, receptive field 不变, 但 flops 大约变为原来的 18/25 = 0.72 倍
</p>


<div id="org0000001" class="figure">
<p><img src="../extra/inception_a.png" alt="inception_a.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-ID-1a7f4bfb-0fa7-4ef1-a405-1f03efe6d5a4" class="outline-5">
<h5 id="ID-1a7f4bfb-0fa7-4ef1-a405-1f03efe6d5a4"><span class="section-number-5">1.1.1.2</span> Asymmetric Conv</h5>
<div class="outline-text-5" id="text-1-1-1-2">
<p>
B, C 都是 asymmetric conv, 即用 1xn, nx1 两个 conv 代替 nxn 的 conv, 其中 B 是
1xn 和 nx1 串行, 而 C 是两者并行.
</p>

<p>
串行:
</p>


<div id="org0000005" class="figure">
<p><img src="../extra/inception_b.png" alt="inception_b.png" />
</p>
</div>

<p>
并行:
</p>


<div id="org0000006" class="figure">
<p><img src="../extra/inception_c.png" alt="inception_c.png" />
</p>
</div>
</div>


<div id="outline-container-org000001d" class="outline-6 references">
<h6 id="org000001d">Backlinks</h6>
<div class="outline-text-6" id="text-org000001d">
<p>
<a href="enet.html#ID-f44e5065-f0ab-4f6c-bb43-1baba0e62326">ENet</a>
(<i>ENet &gt; Network &gt; bottleneck</i>):     bottleneck 中间的 conv 变成 <a href="#ID-1a7f4bfb-0fa7-4ef1-a405-1f03efe6d5a4">Asymmetric Conv</a>, 例如 5x5 kernel 变 5x1 和 1x5 两    个kernel, 在保持 receptive field 大小不变的基础上降低了计算量. 参考了 inception    
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-ID-1f241bc2-3a32-4a81-a8bd-1d363effe635" class="outline-4">
<h4 id="ID-1f241bc2-3a32-4a81-a8bd-1d363effe635"><span class="section-number-4">1.1.2</span> Efficient Grid Size Reduction</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
图中的 D, E 为了做 downsample, 但并不是直接使用 pooling, 因为:
</p>

<ol class="org-ol">
<li>先 conv 后 pooling 时计算量太大</li>

<li>先 pooling 后 conv 时丢失的信息太多, 导致特征信息丢失 (representational
bottleneck)</li>
</ol>

<p>
inception_v3 提出一个 `Efficient Grid Size Reduction` 的方法: conv 和 pooling 同时做, 即一路做 pooling, 另一路做 stride 2 的 conv2d, 然后两者 concat.
</p>


<div id="org000000d" class="figure">
<p><img src="../extra/inception_size_reduction.png" alt="inception_size_reduction.png" />
</p>
</div>
</div>


<div id="outline-container-org000000e" class="outline-5 references">
<h5 id="org000000e">Backlinks</h5>
<div class="outline-text-5" id="text-org000000e">
<p>
<a href="enet.html#ID-f44e5065-f0ab-4f6c-bb43-1baba0e62326">ENet</a>
(<i>ENet &gt; Network &gt; initial</i>):  输入数据为 (3, 512, 512), 通过 initial 层后变为 (16, 256, 256), 这里没有直接做 pooling 而是参考了 inception 的 <a href="#ID-1f241bc2-3a32-4a81-a8bd-1d363effe635">Efficient Grid Size Reduction</a>
</p>
</div>
</div>
</div>


<div id="outline-container-ID-3a113993-aa89-438f-a265-b54930e449dc" class="outline-4">
<h4 id="ID-3a113993-aa89-438f-a265-b54930e449dc"><span class="section-number-4">1.1.3</span> Auxiliary Classifier</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
inception 模型会输出两个 softmax, 分别为 F, G, 其中 F 称为 auxiliary
classifier. F, G 训练时使用相同的标签, F 人为的增加了训练的难度, 相当于一种
<a href="regularization.html#ID-23eb97b1-0697-4b3d-8948-9120911e1058">regularization</a> 的手段.
</p>
</div>


<div id="outline-container-org0000011" class="outline-5 references">
<h5 id="org0000011">Backlinks</h5>
<div class="outline-text-5" id="text-org0000011">
<p>
<a href="icnet.html#ID-451151a7-0b4e-48c2-a99c-28b78f58aea9">ICNet</a>
(<i>ICNet &gt; Network &gt; train</i>):  训练时没有执行最后的 4x upsample, 因为并没有使用原始 label 计算 loss. 所以上面计 算的 3 个 loss 都相当于 <a href="#ID-3a113993-aa89-438f-a265-b54930e449dc">Auxiliary Classifier</a>
</p>

<p>
<a href="pspnet.html#ID-5ab05d23-629f-4f08-929a-9d52513c1ef4">PSPNet</a>
(<i>PSPNet &gt; Network &gt; auxiliary loss</i>):  在论文中也使用了和 <a href="#ID-3a113993-aa89-438f-a265-b54930e449dc">Auxiliary Classifier</a> 类似的方法: resnet 中间某一层通过 conv/fc/resize/upsampling/&#x2026; 后与 label 计算 loss, 再乘以一个权重算到最终的 loss 里
</p>
</div>
</div>
</div>


<div id="outline-container-org0000014" class="outline-4">
<h4 id="org0000014"><span class="section-number-4">1.1.4</span> Label Smoothing</h4>
<div class="outline-text-4" id="text-1-1-4">
<p>
\(new\_label=0.9*one\_hot\_labels+0.9/n\_classes\)
</p>

<p>
类似于知识蒸馏中的 soft label, 可以看做一种 <a href="regularization.html#ID-23eb97b1-0697-4b3d-8948-9120911e1058">regularization</a> 手段.
</p>
</div>
</div>
</div>
</div>



<div id="outline-container-org000001e" class="outline-2 references">
<h2 id="org000001e">Backlinks</h2>
<div class="outline-text-2" id="text-org000001e">
<p>
<a href="enet.html#ID-f44e5065-f0ab-4f6c-bb43-1baba0e62326">ENet</a>
(<i>ENet</i>):  ENet 做为一个 semantic segmentation 模型, 基本就是一个标准的 encoder-decoder 结 构, 并且参考了 <a href="resnet.html#ID-0c626f98-0eab-4638-b296-268c65207120">ResNet</a> 和 <a href="inception.html#ID-c8e4ddb9-1372-4a28-99c3-93f7f3e56bdf">Inception</a> 的设计
</p>

<p>
<a href="image_classification.html#ID-187044e1-7a7a-4ec4-9608-65d31d394a8b">Image Classification</a>
(<i>Image Classification &gt; Inception</i>):   <a href="inception.html#ID-c8e4ddb9-1372-4a28-99c3-93f7f3e56bdf">Inception</a>
</p>

<p>
<a href="../tensorflow/tensorflow_architecture.html#ID-d4639ca8-9dbc-4207-a196-fc427b7e12fc">Tensorflow Architecture</a>
(<i>Tensorflow Architecture &gt; CPU Parallelism &gt; 测试</i>):  1. inter_op_parallelism_threads 作用不大, 可能是因为 mnist 模型没有分支结构, 换    成 <a href="inception.html#ID-c8e4ddb9-1372-4a28-99c3-93f7f3e56bdf">Inception</a> 应该会明显起作用.    
</p>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunway@dogdog.run)<br />
Date: 2022-01-20 Thu 00:00<br />
Last updated: 2022-10-21 Fri 17:20</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
