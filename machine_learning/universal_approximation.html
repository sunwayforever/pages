<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>Universal Approximation</title>


<link rel="stylesheet" type="text/css" href="/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="./htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../htmlize.css"/>
<link rel="stylesheet" type="text/css" href="/readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="./readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="../readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Universal Approximation</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0000011">1. Universal Approximation</a>
<ul>
<li><a href="#org0000001">1.1. Sigmoid 做为激活函数</a></li>
<li><a href="#org0000005">1.2. ReLU 做为激活函数</a></li>
<li><a href="#org0000008">1.3. 线性函数无法做为激活函数</a></li>
<li><a href="#org000000b">1.4. 函数能做为激活函数的条件</a></li>
<li><a href="#org000000e">1.5. ANN 并不是万能</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000011" class="outline-2">
<h2 id="org0000011"><span class="section-number-2">1.</span> Universal Approximation</h2>
<div class="outline-text-2" id="text-1">
<p>
Universal Approximation (通用逼近理论) 是指：如果一个前馈神经网络具有线性输出层和至少一层隐藏层，只要给予网络足够数量的神经元，便可以实现以足够高精度来逼近任意一个在 Rn 的紧子集 (Compact
subset) 上的连续函数。
</p>
</div>

<div id="outline-container-org0000001" class="outline-3">
<h3 id="org0000001"><span class="section-number-3">1.1.</span> Sigmoid 做为激活函数</h3>
<div class="outline-text-3" id="text-1-1">
<p>
<a href="http://neuralnetworksanddeeplearning.com/chap4.html">http://neuralnetworksanddeeplearning.com/chap4.html</a>
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt

plt.style.use<span class="org-parenthesis">(</span><span class="org-string">"seaborn"</span><span class="org-parenthesis">)</span>

<span class="org-variable-name">epsilon</span> <span class="org-operator">=</span> 0.001

<span class="org-keyword">def</span> <span class="org-function-name">sigmoid</span><span class="org-parenthesis">(</span>x<span class="org-parenthesis">)</span>:
    <span class="org-keyword">return</span> 1. <span class="org-operator">/</span> <span class="org-parenthesis">(</span>1. <span class="org-operator">+</span> np.exp<span class="org-parenthesis">(</span><span class="org-operator">-</span>x<span class="org-parenthesis">))</span>

<span class="org-keyword">def</span> <span class="org-function-name">bump_sigmoid</span><span class="org-parenthesis">(</span>h<span class="org-parenthesis">,</span> a<span class="org-parenthesis">,</span> b<span class="org-parenthesis">)</span>:
    <span class="org-variable-name">x</span> <span class="org-operator">=</span> np.linspace<span class="org-parenthesis">(</span>0<span class="org-parenthesis">,</span> 5<span class="org-parenthesis">,</span> 100<span class="org-parenthesis">)</span>
    <span class="org-variable-name">left</span> <span class="org-operator">=</span> sigmoid<span class="org-parenthesis">(</span>1 <span class="org-operator">/</span> epsilon <span class="org-operator">*</span> x <span class="org-operator">-</span> 1 <span class="org-operator">/</span> epsilon <span class="org-operator">*</span> a<span class="org-parenthesis">)</span>
    <span class="org-variable-name">right</span> <span class="org-operator">=</span> sigmoid<span class="org-parenthesis">(</span>1 <span class="org-operator">/</span> epsilon <span class="org-operator">*</span> x <span class="org-operator">-</span> 1 <span class="org-operator">/</span> epsilon <span class="org-operator">*</span> b<span class="org-parenthesis">)</span>

    <span class="org-variable-name">out</span> <span class="org-operator">=</span> <span class="org-parenthesis">(</span>left <span class="org-operator">-</span> right<span class="org-parenthesis">)</span> <span class="org-operator">*</span> h
    plt.plot<span class="org-parenthesis">(</span>x<span class="org-parenthesis">,</span> out<span class="org-parenthesis">)</span>


bump_sigmoid<span class="org-parenthesis">(</span><span class="org-operator">-</span>10<span class="org-parenthesis">,</span> 1<span class="org-parenthesis">,</span> 2<span class="org-parenthesis">)</span>

plt.show<span class="org-parenthesis">()</span>

</pre>
</div>


<div id="org0000000" class="figure">
<p><img src="../extra/universal_approximation_sigmoid.png" alt="universal_approximation_sigmoid.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org0000005" class="outline-3">
<h3 id="org0000005"><span class="section-number-3">1.2.</span> ReLU 做为激活函数</h3>
<div class="outline-text-3" id="text-1-2">
<p>
<a href="https://www.quora.com/Is-a-single-layered-ReLu-network-still-a-universal-approximator">https://www.quora.com/Is-a-single-layered-ReLu-network-still-a-universal-approximator</a>
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">relu</span><span class="org-parenthesis">(</span>x<span class="org-parenthesis">)</span>:
    <span class="org-keyword">return</span> np.maximum<span class="org-parenthesis">(</span>0<span class="org-parenthesis">,</span> x<span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">bump_relu</span><span class="org-parenthesis">(</span>h<span class="org-parenthesis">,</span> a<span class="org-parenthesis">,</span> b<span class="org-parenthesis">)</span>:
    <span class="org-variable-name">x</span> <span class="org-operator">=</span> np.linspace<span class="org-parenthesis">(</span>0<span class="org-parenthesis">,</span> 5<span class="org-parenthesis">,</span> 100<span class="org-parenthesis">)</span>
    plt.plot<span class="org-parenthesis">(</span>
        x<span class="org-parenthesis">,</span> h <span class="org-operator">/</span> epsilon <span class="org-operator">*</span> <span class="org-parenthesis">(</span>relu<span class="org-parenthesis">(</span>x <span class="org-operator">-</span> a<span class="org-parenthesis">)</span> <span class="org-operator">-</span> relu<span class="org-parenthesis">(</span>x <span class="org-operator">-</span> a <span class="org-operator">-</span> epsilon<span class="org-parenthesis">)</span> <span class="org-operator">-</span>
                          <span class="org-parenthesis">(</span>relu<span class="org-parenthesis">(</span>x <span class="org-operator">-</span> b<span class="org-parenthesis">)</span> <span class="org-operator">-</span> relu<span class="org-parenthesis">(</span>x <span class="org-operator">-</span> b <span class="org-operator">-</span> epsilon<span class="org-parenthesis">))))</span>

bump_relu<span class="org-parenthesis">(</span>10<span class="org-parenthesis">,</span> 2<span class="org-parenthesis">,</span> 4<span class="org-parenthesis">)</span>
plt.show<span class="org-parenthesis">()</span>
</pre>
</div>


<div id="org0000004" class="figure">
<p><img src="universal_approximator_relu.png" alt="universal_approximator_relu.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org0000008" class="outline-3">
<h3 id="org0000008"><span class="section-number-3">1.3.</span> 线性函数无法做为激活函数</h3>
<div class="outline-text-3" id="text-1-3">
<p>
线性函数做为激活函数时, 最终输出必然还是 x,b 的线性组合
</p>
</div>
</div>

<div id="outline-container-org000000b" class="outline-3">
<h3 id="org000000b"><span class="section-number-3">1.4.</span> 函数能做为激活函数的条件</h3>
</div>

<div id="outline-container-org000000e" class="outline-3">
<h3 id="org000000e"><span class="section-number-3">1.5.</span> ANN 并不是万能</h3>
<div class="outline-text-3" id="text-1-5">
<p>
通用逼近理论的前提是逼近`连续函数`, 所以有些问题无法用 ANN 解决, 例如
\(f(x)=x\pmod{K}\)
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">from</span> torch.utils.data <span class="org-keyword">import</span> Dataset<span class="org-parenthesis">,</span> DataLoader
<span class="org-keyword">import</span> torch

<span class="org-variable-name">N_CLASSES</span> <span class="org-operator">=</span> 2
<span class="org-variable-name">model</span> <span class="org-operator">=</span> torch.nn.Sequential<span class="org-parenthesis">(</span>
    torch.nn.Linear<span class="org-parenthesis">(</span>1<span class="org-parenthesis">,</span> 10<span class="org-parenthesis">),</span> torch.nn.ReLU<span class="org-parenthesis">(),</span> torch.nn.Linear<span class="org-parenthesis">(</span>10<span class="org-parenthesis">,</span> N_CLASSES<span class="org-parenthesis">))</span>


<span class="org-keyword">class</span> <span class="org-type">OddsAndEvenDataset</span><span class="org-parenthesis">(</span>Dataset<span class="org-parenthesis">)</span>:
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> low<span class="org-parenthesis">,</span> high<span class="org-parenthesis">,</span> size<span class="org-parenthesis">)</span>:
        <span class="org-variable-name">X</span> <span class="org-operator">=</span> np.random.randint<span class="org-parenthesis">(</span>low<span class="org-parenthesis">,</span> high<span class="org-parenthesis">,</span> size<span class="org-parenthesis">)</span>
        <span class="org-variable-name">Y</span> <span class="org-operator">=</span> X <span class="org-operator">%</span> N_CLASSES
        <span class="org-keyword">self</span>.<span class="org-variable-name">X</span> <span class="org-operator">=</span> torch.from_numpy<span class="org-parenthesis">(</span>X<span class="org-parenthesis">)</span>.<span class="org-builtin">float</span><span class="org-parenthesis">()</span>.view<span class="org-parenthesis">(</span><span class="org-operator">-</span>1<span class="org-parenthesis">,</span> 1<span class="org-parenthesis">)</span>
        <span class="org-keyword">self</span>.<span class="org-variable-name">Y</span> <span class="org-operator">=</span> torch.from_numpy<span class="org-parenthesis">(</span>Y<span class="org-parenthesis">)</span>.<span class="org-builtin">long</span><span class="org-parenthesis">()</span>.view<span class="org-parenthesis">(</span><span class="org-operator">-</span>1<span class="org-parenthesis">)</span>

    <span class="org-keyword">def</span> <span class="org-function-name">__getitem__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> index<span class="org-parenthesis">)</span>:
        <span class="org-keyword">return</span> <span class="org-keyword">self</span>.X[index]<span class="org-parenthesis">,</span> <span class="org-keyword">self</span>.Y[index]

    <span class="org-keyword">def</span> <span class="org-function-name">__len__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">)</span>:
        <span class="org-keyword">return</span> <span class="org-builtin">len</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span>.X<span class="org-parenthesis">)</span>


<span class="org-variable-name">training_set</span> <span class="org-operator">=</span> OddsAndEvenDataset<span class="org-parenthesis">(</span>0<span class="org-parenthesis">,</span> 1000<span class="org-parenthesis">,</span> 500<span class="org-parenthesis">)</span>
<span class="org-variable-name">training_loader</span> <span class="org-operator">=</span> DataLoader<span class="org-parenthesis">(</span>training_set<span class="org-parenthesis">,</span> batch_size<span class="org-operator">=</span>100<span class="org-parenthesis">)</span>

<span class="org-variable-name">test_set</span> <span class="org-operator">=</span> OddsAndEvenDataset<span class="org-parenthesis">(</span>500<span class="org-parenthesis">,</span> 2000<span class="org-parenthesis">,</span> 500<span class="org-parenthesis">)</span>
<span class="org-variable-name">test_loader</span> <span class="org-operator">=</span> DataLoader<span class="org-parenthesis">(</span>test_set<span class="org-parenthesis">,</span> batch_size<span class="org-operator">=</span>500<span class="org-parenthesis">)</span>

<span class="org-comment-delimiter"># </span><span class="org-comment">criterion = torch.nn.BCEWithLogitsLoss()</span>
<span class="org-variable-name">criterion</span> <span class="org-operator">=</span> torch.nn.CrossEntropyLoss<span class="org-parenthesis">()</span>

<span class="org-variable-name">optimizer</span> <span class="org-operator">=</span> torch.optim.Adam<span class="org-parenthesis">(</span>model.parameters<span class="org-parenthesis">(),</span> lr<span class="org-operator">=</span>1e<span class="org-operator">-</span>3<span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">train</span><span class="org-parenthesis">()</span>:
    model.train<span class="org-parenthesis">()</span>
    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span><span class="org-parenthesis">(</span>1000<span class="org-parenthesis">)</span>:
        <span class="org-keyword">for</span> x<span class="org-parenthesis">,</span> y <span class="org-keyword">in</span> training_loader:
            <span class="org-variable-name">loss</span> <span class="org-operator">=</span> criterion<span class="org-parenthesis">(</span>model<span class="org-parenthesis">(</span>x<span class="org-parenthesis">),</span> y<span class="org-parenthesis">)</span>
            optimizer.zero_grad<span class="org-parenthesis">()</span>
            loss.backward<span class="org-parenthesis">()</span>
            optimizer.step<span class="org-parenthesis">()</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">if i % 20 == 0:</span>
    <span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"loss:"</span><span class="org-parenthesis">,</span>loss.item<span class="org-parenthesis">())</span>


<span class="org-keyword">def</span> <span class="org-function-name">test</span><span class="org-parenthesis">()</span>:
    model.<span class="org-builtin">eval</span><span class="org-parenthesis">()</span>
    <span class="org-keyword">for</span> x<span class="org-parenthesis">,</span> y <span class="org-keyword">in</span> training_loader:
        <span class="org-variable-name">y_hat</span> <span class="org-operator">=</span> model<span class="org-parenthesis">(</span>x<span class="org-parenthesis">)</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">y_hat = F.sigmoid(y_hat)</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">y_hat = y_hat &gt; 0.5</span>
        <span class="org-variable-name">y_hat</span> <span class="org-operator">=</span> torch.argmax<span class="org-parenthesis">(</span>y_hat<span class="org-parenthesis">,</span> dim<span class="org-operator">=</span>1<span class="org-parenthesis">)</span>
        <span class="org-variable-name">accu</span> <span class="org-operator">=</span> torch.<span class="org-builtin">sum</span><span class="org-parenthesis">(</span>y_hat.byte<span class="org-parenthesis">()</span> <span class="org-operator">==</span> y.byte<span class="org-parenthesis">())</span>.item<span class="org-parenthesis">()</span> <span class="org-operator">/</span> 100
        <span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"train:"</span><span class="org-parenthesis">,</span> accu<span class="org-parenthesis">)</span>
        <span class="org-keyword">break</span>

    <span class="org-keyword">for</span> x<span class="org-parenthesis">,</span> y <span class="org-keyword">in</span> test_loader:
        <span class="org-variable-name">y_hat</span> <span class="org-operator">=</span> model<span class="org-parenthesis">(</span>x<span class="org-parenthesis">)</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">y_hat = F.sigmoid(y_hat)</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">y_hat = y_hat &gt; 0.5</span>
        <span class="org-variable-name">y_hat</span> <span class="org-operator">=</span> torch.argmax<span class="org-parenthesis">(</span>y_hat<span class="org-parenthesis">,</span> dim<span class="org-operator">=</span>1<span class="org-parenthesis">)</span>
        <span class="org-variable-name">accu</span> <span class="org-operator">=</span> torch.<span class="org-builtin">sum</span><span class="org-parenthesis">(</span>y_hat.byte<span class="org-parenthesis">()</span> <span class="org-operator">==</span> y.byte<span class="org-parenthesis">())</span>.item<span class="org-parenthesis">()</span> <span class="org-operator">/</span> 500
        <span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"test:"</span><span class="org-parenthesis">,</span> accu<span class="org-parenthesis">)</span>


train<span class="org-parenthesis">()</span>
test<span class="org-parenthesis">()</span>
</pre>
</div>

<p>
loss: 0.6905694007873535
train: 0.47
test: 0.536
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway@dogdog.run<br />
Date: 2018-07-31 Tue 00:00<br />
Last updated: 2024-01-31 Wed 17:35</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
</div>
</body>
</html>