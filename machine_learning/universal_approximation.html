<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-01-25 二 15:53 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Universal Approximation</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Wei Sun (孙伟)" />
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Universal Approximation</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org34756ad">1. Universal Approximation</a>
<ul>
<li><a href="#orgb99f09d">1.1. Sigmoid 做为激活函数</a></li>
<li><a href="#org770f33e">1.2. ReLU 做为激活函数</a></li>
<li><a href="#orgffdbb07">1.3. 线性函数无法做为激活函数</a></li>
<li><a href="#org8421e1b">1.4. 函数能做为激活函数的条件</a></li>
<li><a href="#org19be909">1.5. ANN 并不是万能</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org34756ad" class="outline-2">
<h2 id="org34756ad"><span class="section-number-2">1</span> Universal Approximation</h2>
<div class="outline-text-2" id="text-1">
<p>
Universal Approximation (通用逼近理论) 是指：如果一个前馈神经网络具有线性输出层和至少一层隐藏层，只要给予网络足够数量的神经元，便可以实现以足够高精度来逼近任意一个在 Rn 的紧子集 (Compact
subset) 上的连续函数。
</p>
</div>

<div id="outline-container-orgb99f09d" class="outline-3">
<h3 id="orgb99f09d"><span class="section-number-3">1.1</span> Sigmoid 做为激活函数</h3>
<div class="outline-text-3" id="text-1-1">
<p>
<a href="http://neuralnetworksanddeeplearning.com/chap4.html">http://neuralnetworksanddeeplearning.com/chap4.html</a>
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">import</span> matplotlib.pyplot <span style="color: #859900;">as</span> plt

plt.style.use<span style="color: #757575;">(</span><span style="color: #2aa198;">"seaborn"</span><span style="color: #757575;">)</span>

<span style="color: #268bd2;">epsilon</span> = 0.001

<span style="color: #859900;">def</span> <span style="color: #268bd2;">sigmoid</span><span style="color: #757575;">(</span>x<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> 1. / <span style="color: #757575;">(</span>1. + np.exp<span style="color: #757575;">(</span>-x<span style="color: #757575;">))</span>

<span style="color: #859900;">def</span> <span style="color: #268bd2;">bump_sigmoid</span><span style="color: #757575;">(</span>h<span style="color: #757575;">,</span> a<span style="color: #757575;">,</span> b<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">x</span> = np.linspace<span style="color: #757575;">(</span>0<span style="color: #757575;">,</span> 5<span style="color: #757575;">,</span> 100<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">left</span> = sigmoid<span style="color: #757575;">(</span>1 / epsilon * x - 1 / epsilon * a<span style="color: #757575;">)</span>
    <span style="color: #268bd2;">right</span> = sigmoid<span style="color: #757575;">(</span>1 / epsilon * x - 1 / epsilon * b<span style="color: #757575;">)</span>

    <span style="color: #268bd2;">out</span> = <span style="color: #757575;">(</span>left - right<span style="color: #757575;">)</span> * h
    plt.plot<span style="color: #757575;">(</span>x<span style="color: #757575;">,</span> out<span style="color: #757575;">)</span>


bump_sigmoid<span style="color: #757575;">(</span>-10<span style="color: #757575;">,</span> 1<span style="color: #757575;">,</span> 2<span style="color: #757575;">)</span>

plt.show<span style="color: #757575;">()</span>

</pre>
</div>


<div id="org1739426" class="figure">
<p><img src="../extra/universal_approximation_sigmoid.png" alt="universal_approximation_sigmoid.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org770f33e" class="outline-3">
<h3 id="org770f33e"><span class="section-number-3">1.2</span> ReLU 做为激活函数</h3>
<div class="outline-text-3" id="text-1-2">
<p>
<a href="https://www.quora.com/Is-a-single-layered-ReLu-network-still-a-universal-approximator">https://www.quora.com/Is-a-single-layered-ReLu-network-still-a-universal-approximator</a>
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #859900;">def</span> <span style="color: #268bd2;">relu</span><span style="color: #757575;">(</span>x<span style="color: #757575;">)</span>:
    <span style="color: #859900;">return</span> np.maximum<span style="color: #757575;">(</span>0<span style="color: #757575;">,</span> x<span style="color: #757575;">)</span>


<span style="color: #859900;">def</span> <span style="color: #268bd2;">bump_relu</span><span style="color: #757575;">(</span>h<span style="color: #757575;">,</span> a<span style="color: #757575;">,</span> b<span style="color: #757575;">)</span>:
    <span style="color: #268bd2;">x</span> = np.linspace<span style="color: #757575;">(</span>0<span style="color: #757575;">,</span> 5<span style="color: #757575;">,</span> 100<span style="color: #757575;">)</span>
    plt.plot<span style="color: #757575;">(</span>
        x<span style="color: #757575;">,</span> h / epsilon * <span style="color: #757575;">(</span>relu<span style="color: #757575;">(</span>x - a<span style="color: #757575;">)</span> - relu<span style="color: #757575;">(</span>x - a - epsilon<span style="color: #757575;">)</span> -
                          <span style="color: #757575;">(</span>relu<span style="color: #757575;">(</span>x - b<span style="color: #757575;">)</span> - relu<span style="color: #757575;">(</span>x - b - epsilon<span style="color: #757575;">))))</span>

bump_relu<span style="color: #757575;">(</span>10<span style="color: #757575;">,</span> 2<span style="color: #757575;">,</span> 4<span style="color: #757575;">)</span>
plt.show<span style="color: #757575;">()</span>
</pre>
</div>


<div id="org1ceed9a" class="figure">
<p><img src="universal_approximator_relu.png" alt="universal_approximator_relu.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgffdbb07" class="outline-3">
<h3 id="orgffdbb07"><span class="section-number-3">1.3</span> 线性函数无法做为激活函数</h3>
<div class="outline-text-3" id="text-1-3">
<p>
线性函数做为激活函数时, 最终输出必然还是 x,b 的线性组合
</p>
</div>
</div>

<div id="outline-container-org8421e1b" class="outline-3">
<h3 id="org8421e1b"><span class="section-number-3">1.4</span> 函数能做为激活函数的条件</h3>
</div>

<div id="outline-container-org19be909" class="outline-3">
<h3 id="org19be909"><span class="section-number-3">1.5</span> ANN 并不是万能</h3>
<div class="outline-text-3" id="text-1-5">
<p>
通用逼近理论的前提是逼近`连续函数`, 所以有些问题无法用 ANN 解决, 例如
\(f(x)=x\pmod{K}\)
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #859900;">import</span> numpy <span style="color: #859900;">as</span> np
<span style="color: #859900;">from</span> torch.utils.data <span style="color: #859900;">import</span> Dataset<span style="color: #757575;">,</span> DataLoader
<span style="color: #859900;">import</span> torch

<span style="color: #268bd2;">N_CLASSES</span> = 2
<span style="color: #268bd2;">model</span> = torch.nn.Sequential<span style="color: #757575;">(</span>
    torch.nn.Linear<span style="color: #757575;">(</span>1<span style="color: #757575;">,</span> 10<span style="color: #757575;">),</span> torch.nn.ReLU<span style="color: #757575;">(),</span> torch.nn.Linear<span style="color: #757575;">(</span>10<span style="color: #757575;">,</span> N_CLASSES<span style="color: #757575;">))</span>


<span style="color: #859900;">class</span> <span style="color: #b58900;">OddsAndEvenDataset</span><span style="color: #757575;">(</span>Dataset<span style="color: #757575;">)</span>:
    <span style="color: #859900;">def</span> <span style="color: #268bd2;">__init__</span><span style="color: #757575;">(</span><span style="color: #859900;">self</span><span style="color: #757575;">,</span> low<span style="color: #757575;">,</span> high<span style="color: #757575;">,</span> size<span style="color: #757575;">)</span>:
        <span style="color: #268bd2;">X</span> = np.random.randint<span style="color: #757575;">(</span>low<span style="color: #757575;">,</span> high<span style="color: #757575;">,</span> size<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">Y</span> = X % N_CLASSES
        <span style="color: #859900;">self</span>.X = torch.from_numpy<span style="color: #757575;">(</span>X<span style="color: #757575;">)</span>.<span style="color: #839496;">float</span><span style="color: #757575;">()</span>.view<span style="color: #757575;">(</span>-1<span style="color: #757575;">,</span> 1<span style="color: #757575;">)</span>
        <span style="color: #859900;">self</span>.Y = torch.from_numpy<span style="color: #757575;">(</span>Y<span style="color: #757575;">)</span>.<span style="color: #839496;">long</span><span style="color: #757575;">()</span>.view<span style="color: #757575;">(</span>-1<span style="color: #757575;">)</span>

    <span style="color: #859900;">def</span> <span style="color: #268bd2;">__getitem__</span><span style="color: #757575;">(</span><span style="color: #859900;">self</span><span style="color: #757575;">,</span> index<span style="color: #757575;">)</span>:
        <span style="color: #859900;">return</span> <span style="color: #859900;">self</span>.X[index]<span style="color: #757575;">,</span> <span style="color: #859900;">self</span>.Y[index]

    <span style="color: #859900;">def</span> <span style="color: #268bd2;">__len__</span><span style="color: #757575;">(</span><span style="color: #859900;">self</span><span style="color: #757575;">)</span>:
        <span style="color: #859900;">return</span> <span style="color: #839496;">len</span><span style="color: #757575;">(</span><span style="color: #859900;">self</span>.X<span style="color: #757575;">)</span>


<span style="color: #268bd2;">training_set</span> = OddsAndEvenDataset<span style="color: #757575;">(</span>0<span style="color: #757575;">,</span> 1000<span style="color: #757575;">,</span> 500<span style="color: #757575;">)</span>
<span style="color: #268bd2;">training_loader</span> = DataLoader<span style="color: #757575;">(</span>training_set<span style="color: #757575;">,</span> batch_size=100<span style="color: #757575;">)</span>

<span style="color: #268bd2;">test_set</span> = OddsAndEvenDataset<span style="color: #757575;">(</span>500<span style="color: #757575;">,</span> 2000<span style="color: #757575;">,</span> 500<span style="color: #757575;">)</span>
<span style="color: #268bd2;">test_loader</span> = DataLoader<span style="color: #757575;">(</span>test_set<span style="color: #757575;">,</span> batch_size=500<span style="color: #757575;">)</span>

<span style="color: #586e75;"># </span><span style="color: #586e75;">criterion = torch.nn.BCEWithLogitsLoss()</span>
<span style="color: #268bd2;">criterion</span> = torch.nn.CrossEntropyLoss<span style="color: #757575;">()</span>

<span style="color: #268bd2;">optimizer</span> = torch.optim.Adam<span style="color: #757575;">(</span>model.parameters<span style="color: #757575;">(),</span> lr=1e-3<span style="color: #757575;">)</span>


<span style="color: #859900;">def</span> <span style="color: #268bd2;">train</span><span style="color: #757575;">()</span>:
    model.train<span style="color: #757575;">()</span>
    <span style="color: #859900;">for</span> i <span style="color: #859900;">in</span> <span style="color: #839496;">range</span><span style="color: #757575;">(</span>1000<span style="color: #757575;">)</span>:
        <span style="color: #859900;">for</span> x<span style="color: #757575;">,</span> y <span style="color: #859900;">in</span> training_loader:
            <span style="color: #268bd2;">loss</span> = criterion<span style="color: #757575;">(</span>model<span style="color: #757575;">(</span>x<span style="color: #757575;">),</span> y<span style="color: #757575;">)</span>
            optimizer.zero_grad<span style="color: #757575;">()</span>
            loss.backward<span style="color: #757575;">()</span>
            optimizer.step<span style="color: #757575;">()</span>
    <span style="color: #586e75;"># </span><span style="color: #586e75;">if i % 20 == 0:</span>
    <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"loss:"</span><span style="color: #757575;">,</span>loss.item<span style="color: #757575;">())</span>


<span style="color: #859900;">def</span> <span style="color: #268bd2;">test</span><span style="color: #757575;">()</span>:
    model.<span style="color: #839496;">eval</span><span style="color: #757575;">()</span>
    <span style="color: #859900;">for</span> x<span style="color: #757575;">,</span> y <span style="color: #859900;">in</span> training_loader:
        <span style="color: #268bd2;">y_hat</span> = model<span style="color: #757575;">(</span>x<span style="color: #757575;">)</span>
        <span style="color: #586e75;"># </span><span style="color: #586e75;">y_hat = F.sigmoid(y_hat)</span>
        <span style="color: #586e75;"># </span><span style="color: #586e75;">y_hat = y_hat &gt; 0.5</span>
        <span style="color: #268bd2;">y_hat</span> = torch.argmax<span style="color: #757575;">(</span>y_hat<span style="color: #757575;">,</span> dim=1<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">accu</span> = torch.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>y_hat.byte<span style="color: #757575;">()</span> == y.byte<span style="color: #757575;">())</span>.item<span style="color: #757575;">()</span> / 100
        <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"train:"</span><span style="color: #757575;">,</span> accu<span style="color: #757575;">)</span>
        <span style="color: #859900;">break</span>

    <span style="color: #859900;">for</span> x<span style="color: #757575;">,</span> y <span style="color: #859900;">in</span> test_loader:
        <span style="color: #268bd2;">y_hat</span> = model<span style="color: #757575;">(</span>x<span style="color: #757575;">)</span>
        <span style="color: #586e75;"># </span><span style="color: #586e75;">y_hat = F.sigmoid(y_hat)</span>
        <span style="color: #586e75;"># </span><span style="color: #586e75;">y_hat = y_hat &gt; 0.5</span>
        <span style="color: #268bd2;">y_hat</span> = torch.argmax<span style="color: #757575;">(</span>y_hat<span style="color: #757575;">,</span> dim=1<span style="color: #757575;">)</span>
        <span style="color: #268bd2;">accu</span> = torch.<span style="color: #839496;">sum</span><span style="color: #757575;">(</span>y_hat.byte<span style="color: #757575;">()</span> == y.byte<span style="color: #757575;">())</span>.item<span style="color: #757575;">()</span> / 500
        <span style="color: #859900;">print</span><span style="color: #757575;">(</span><span style="color: #2aa198;">"test:"</span><span style="color: #757575;">,</span> accu<span style="color: #757575;">)</span>


train<span style="color: #757575;">()</span>
test<span style="color: #757575;">()</span>
</pre>
</div>

<p>
loss: 0.6905694007873535
train: 0.47
test: 0.536
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2018-07-31 二 00:00<br />
Last updated: 2022-01-03 一 10:53</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
