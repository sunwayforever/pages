<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>Universal Approximation</title>


<link rel="stylesheet" type="text/css" href="/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="./htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../../htmlize.css"/>
<link rel="stylesheet" type="text/css" href="/readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="./readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="../readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="../../readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Universal Approximation</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0000011">1. Universal Approximation</a>
<ul>
<li><a href="#org0000001">1.1. Sigmoid 做为激活函数</a></li>
<li><a href="#org0000005">1.2. ReLU 做为激活函数</a></li>
<li><a href="#org0000008">1.3. 线性函数无法做为激活函数</a></li>
<li><a href="#org000000b">1.4. 函数能做为激活函数的条件</a></li>
<li><a href="#org000000e">1.5. ANN 并不是万能</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000011" class="outline-2">
<h2 id="org0000011"><span class="section-number-2">1.</span> Universal Approximation</h2>
<div class="outline-text-2" id="text-1">
<p>
Universal Approximation (通用逼近理论) 是指：如果一个前馈神经网络具有线性输出层和至少一层隐藏层，只要给予网络足够数量的神经元，便可以实现以足够高精度来逼近任意一个在 Rn 的紧子集 (Compact
subset) 上的连续函数。
</p>
</div>

<div id="outline-container-org0000001" class="outline-3">
<h3 id="org0000001"><span class="section-number-3">1.1.</span> Sigmoid 做为激活函数</h3>
<div class="outline-text-3" id="text-1-1">
<p>
<a href="http://neuralnetworksanddeeplearning.com/chap4.html">http://neuralnetworksanddeeplearning.com/chap4.html</a>
</p>

<div class="org-src-container">
<pre class="src src-ipython">import numpy as np
import matplotlib.pyplot as plt

plt.style.use("seaborn")

epsilon = 0.001

def sigmoid(x):
    return 1. / (1. + np.exp(-x))

def bump_sigmoid(h, a, b):
    x = np.linspace(0, 5, 100)
    left = sigmoid(1 / epsilon * x - 1 / epsilon * a)
    right = sigmoid(1 / epsilon * x - 1 / epsilon * b)

    out = (left - right) * h
    plt.plot(x, out)


bump_sigmoid(-10, 1, 2)

plt.show()

</pre>
</div>


<div id="org0000000" class="figure">
<p><img src="../extra/universal_approximation_sigmoid.png" alt="universal_approximation_sigmoid.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org0000005" class="outline-3">
<h3 id="org0000005"><span class="section-number-3">1.2.</span> ReLU 做为激活函数</h3>
<div class="outline-text-3" id="text-1-2">
<p>
<a href="https://www.quora.com/Is-a-single-layered-ReLu-network-still-a-universal-approximator">https://www.quora.com/Is-a-single-layered-ReLu-network-still-a-universal-approximator</a>
</p>

<div class="org-src-container">
<pre class="src src-ipython">def relu(x):
    return np.maximum(0, x)


def bump_relu(h, a, b):
    x = np.linspace(0, 5, 100)
    plt.plot(
        x, h / epsilon * (relu(x - a) - relu(x - a - epsilon) -
                          (relu(x - b) - relu(x - b - epsilon))))

bump_relu(10, 2, 4)
plt.show()
</pre>
</div>


<div id="org0000004" class="figure">
<p><img src="universal_approximator_relu.png" alt="universal_approximator_relu.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org0000008" class="outline-3">
<h3 id="org0000008"><span class="section-number-3">1.3.</span> 线性函数无法做为激活函数</h3>
<div class="outline-text-3" id="text-1-3">
<p>
线性函数做为激活函数时, 最终输出必然还是 x,b 的线性组合
</p>
</div>
</div>

<div id="outline-container-org000000b" class="outline-3">
<h3 id="org000000b"><span class="section-number-3">1.4.</span> 函数能做为激活函数的条件</h3>
</div>

<div id="outline-container-org000000e" class="outline-3">
<h3 id="org000000e"><span class="section-number-3">1.5.</span> ANN 并不是万能</h3>
<div class="outline-text-3" id="text-1-5">
<p>
通用逼近理论的前提是逼近`连续函数`, 所以有些问题无法用 ANN 解决, 例如
\(f(x)=x\pmod{K}\)
</p>

<div class="org-src-container">
<pre class="src src-ipython">import numpy as np
from torch.utils.data import Dataset, DataLoader
import torch

N_CLASSES = 2
model = torch.nn.Sequential(
    torch.nn.Linear(1, 10), torch.nn.ReLU(), torch.nn.Linear(10, N_CLASSES))


class OddsAndEvenDataset(Dataset):
    def __init__(self, low, high, size):
        X = np.random.randint(low, high, size)
        Y = X % N_CLASSES
        self.X = torch.from_numpy(X).float().view(-1, 1)
        self.Y = torch.from_numpy(Y).long().view(-1)

    def __getitem__(self, index):
        return self.X[index], self.Y[index]

    def __len__(self):
        return len(self.X)


training_set = OddsAndEvenDataset(0, 1000, 500)
training_loader = DataLoader(training_set, batch_size=100)

test_set = OddsAndEvenDataset(500, 2000, 500)
test_loader = DataLoader(test_set, batch_size=500)

# criterion = torch.nn.BCEWithLogitsLoss()
criterion = torch.nn.CrossEntropyLoss()

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)


def train():
    model.train()
    for i in range(1000):
        for x, y in training_loader:
            loss = criterion(model(x), y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    # if i % 20 == 0:
    print("loss:",loss.item())


def test():
    model.eval()
    for x, y in training_loader:
        y_hat = model(x)
        # y_hat = F.sigmoid(y_hat)
        # y_hat = y_hat &gt; 0.5
        y_hat = torch.argmax(y_hat, dim=1)
        accu = torch.sum(y_hat.byte() == y.byte()).item() / 100
        print("train:", accu)
        break

    for x, y in test_loader:
        y_hat = model(x)
        # y_hat = F.sigmoid(y_hat)
        # y_hat = y_hat &gt; 0.5
        y_hat = torch.argmax(y_hat, dim=1)
        accu = torch.sum(y_hat.byte() == y.byte()).item() / 500
        print("test:", accu)


train()
test()
</pre>
</div>

<p>
loss: 0.6905694007873535
train: 0.47
test: 0.536
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: <a href="mailto:sunway@dogdog.run">sunway@dogdog.run</a><br />
Date: 2018-07-31 Tue 00:00<br />
Last updated: 2022-01-03 Mon 10:55</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
</div>
</body>
</html>
