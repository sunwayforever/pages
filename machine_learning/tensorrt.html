<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>TensorRT</title>


<link rel="stylesheet" type="text/css" href="/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="./htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../htmlize.css"/>
<link rel="stylesheet" type="text/css" href="/readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="./readtheorg.css"/>
<link rel="stylesheet" type="text/css" href="../readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">TensorRT</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0000027">1. TensorRT</a>
<ul>
<li><a href="#ID-beebccdd-76dc-4f17-afa4-074611a912d2">1.1. Quantization Aware Training</a>
<ul>
<li><a href="#org0000000">1.1.1. Overview</a></li>
<li><a href="#org000001c">1.1.2. Impl</a></li>
<li><a href="#org0000021">1.1.3. TensorRT Optimizer</a></li>
</ul>
</li>
<li><a href="#org0000024">1.2. Sparsity</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000027" class="outline-2">
<h2 id="org0000027"><span class="section-number-2">1.</span> TensorRT</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-ID-beebccdd-76dc-4f17-afa4-074611a912d2" class="outline-3">
<h3 id="ID-beebccdd-76dc-4f17-afa4-074611a912d2"><span class="section-number-3">1.1.</span> Quantization Aware Training</h3>
<div class="outline-text-3" id="text-1-1">
</div>

<div id="outline-container-org0000000" class="outline-4">
<h4 id="org0000000"><span class="section-number-4">1.1.1.</span> Overview</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
<a href="https://developer.nvidia.com/blog/achieving-fp32-accuracy-for-int8-inference-using-quantization-aware-training-with-tensorrt/">https://developer.nvidia.com/blog/achieving-fp32-accuracy-for-int8-inference-using-quantization-aware-training-with-tensorrt/</a>
</p>

<p>
<a href="https://github.com/NVIDIA/TensorRT/tree/master/tools/pytorch-quantization">https://github.com/NVIDIA/TensorRT/tree/master/tools/pytorch-quantization</a>
</p>

<p>
TensorRT 的 pytorch_quantization 是一个实现 fake quantization 的 pytorch plugin
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-10-29 14:24</span>
<span class="org-keyword">import</span> os
<span class="org-keyword">import</span> torch
<span class="org-keyword">from</span> torch <span class="org-keyword">import</span> nn
<span class="org-keyword">from</span> torch <span class="org-keyword">import</span> optim
<span class="org-keyword">from</span> torch.utils.data <span class="org-keyword">import</span> DataLoader<span class="org-parenthesis">,</span> Dataset
<span class="org-keyword">import</span> torch.nn.functional <span class="org-keyword">as</span> F
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">import</span> torch.onnx

<span class="org-keyword">from</span> pytorch_quantization <span class="org-keyword">import</span> nn <span class="org-keyword">as</span> quant_nn
<span class="org-keyword">from</span> pytorch_quantization <span class="org-keyword">import</span> calib
<span class="org-keyword">from</span> pytorch_quantization.tensor_quant <span class="org-keyword">import</span> QuantDescriptor
<span class="org-keyword">from</span> pytorch_quantization <span class="org-keyword">import</span> quant_modules
<span class="org-keyword">from</span> absl <span class="org-keyword">import</span> logging

logging.set_verbosity<span class="org-parenthesis">(</span>logging.FATAL<span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">export_to_onnx</span><span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>:
    model.<span class="org-builtin">eval</span><span class="org-parenthesis">()</span>
    <span class="org-variable-name">dummy_input</span> <span class="org-operator">=</span> torch.randn<span class="org-parenthesis">(</span>1<span class="org-parenthesis">,</span> 5<span class="org-parenthesis">)</span>

    <span class="org-comment-delimiter"># </span><span class="org-comment">use_fb_fake_quant &#26159; tensorrt &#30340;&#19968;&#20010; hack: &#24403;&#38656;&#35201;&#23548;&#20986;&#20026; onnx &#26102;&#35774;&#20026; true,</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">forward &#26102; fake_tensor_quant &#20250;&#34987;&#26367;&#25442;&#20026; _fb_fake_quant, &#21518;&#32773;&#20250;&#35843;&#29992;torch &#33258;</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">&#24049;&#30340; fake_quantize_per_channel_affine &#20197;&#20415;&#23548;&#20986;&#20026; onnx &#30340;</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">QuantizeLinear/DequantizeLinear</span>
    quant_nn.TensorQuantizer.<span class="org-variable-name">use_fb_fake_quant</span> <span class="org-operator">=</span> <span class="org-constant">True</span>

    torch.onnx.export<span class="org-parenthesis">(</span>
        model<span class="org-parenthesis">,</span>
        dummy_input<span class="org-parenthesis">,</span>
        <span class="org-string">"fake.onnx"</span><span class="org-parenthesis">,</span>
        opset_version<span class="org-operator">=</span>13<span class="org-parenthesis">,</span>
    <span class="org-parenthesis">)</span>
    quant_nn.TensorQuantizer.<span class="org-variable-name">use_fb_fake_quant</span> <span class="org-operator">=</span> <span class="org-constant">False</span>


<span class="org-keyword">def</span> <span class="org-function-name">get_data</span><span class="org-parenthesis">()</span>:
    <span class="org-keyword">class</span> <span class="org-type">PlainDataset</span><span class="org-parenthesis">(</span>Dataset<span class="org-parenthesis">)</span>:
        <span class="org-keyword">def</span> <span class="org-function-name">__init__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">)</span>:
            <span class="org-variable-name">x</span> <span class="org-operator">=</span> torch.<span class="org-builtin">round</span><span class="org-parenthesis">(</span>torch.rand<span class="org-parenthesis">(</span>10000<span class="org-parenthesis">)</span> <span class="org-operator">*</span> 200<span class="org-parenthesis">)</span>
            <span class="org-variable-name">x</span> <span class="org-operator">=</span> x.unsqueeze<span class="org-parenthesis">(</span>1<span class="org-parenthesis">)</span>
            <span class="org-variable-name">x</span> <span class="org-operator">=</span> torch.cat<span class="org-parenthesis">((</span>x<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 2<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 3<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 4<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 5<span class="org-parenthesis">),</span> 1<span class="org-parenthesis">)</span>
            <span class="org-keyword">self</span>.<span class="org-variable-name">X</span> <span class="org-operator">=</span> x

        <span class="org-keyword">def</span> <span class="org-function-name">__getitem__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> index<span class="org-parenthesis">)</span>:
            <span class="org-keyword">return</span> <span class="org-keyword">self</span>.X[index]

        <span class="org-keyword">def</span> <span class="org-function-name">__len__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">)</span>:
            <span class="org-keyword">return</span> <span class="org-builtin">len</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span>.X<span class="org-parenthesis">)</span>

    <span class="org-variable-name">training_set</span> <span class="org-operator">=</span> PlainDataset<span class="org-parenthesis">()</span>
    <span class="org-keyword">return</span> DataLoader<span class="org-parenthesis">(</span>training_set<span class="org-parenthesis">,</span> batch_size<span class="org-operator">=</span>100<span class="org-parenthesis">,</span> shuffle<span class="org-operator">=</span><span class="org-constant">True</span><span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">pretrain_model</span><span class="org-parenthesis">()</span>:
    <span class="org-variable-name">model</span> <span class="org-operator">=</span> nn.Sequential<span class="org-parenthesis">(</span>
        nn.Linear<span class="org-parenthesis">(</span>5<span class="org-parenthesis">,</span> 1<span class="org-parenthesis">),</span>
        nn.Linear<span class="org-parenthesis">(</span>1<span class="org-parenthesis">,</span> 5<span class="org-parenthesis">),</span>
    <span class="org-parenthesis">)</span>

    <span class="org-keyword">if</span> os.path.exists<span class="org-parenthesis">(</span><span class="org-string">"model.pt"</span><span class="org-parenthesis">)</span>:
        <span class="org-keyword">return</span>

    train_model<span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>
    torch.save<span class="org-parenthesis">(</span>model.state_dict<span class="org-parenthesis">(),</span> <span class="org-string">"model.pt"</span><span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">train_model</span><span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> epoch<span class="org-operator">=</span>500<span class="org-parenthesis">)</span>:
    <span class="org-variable-name">criterion</span> <span class="org-operator">=</span> nn.MSELoss<span class="org-parenthesis">()</span>
    <span class="org-variable-name">optimizer</span> <span class="org-operator">=</span> optim.Adam<span class="org-parenthesis">(</span>model.parameters<span class="org-parenthesis">())</span>

    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span><span class="org-parenthesis">(</span>epoch<span class="org-parenthesis">)</span>:
        <span class="org-keyword">for</span> x <span class="org-keyword">in</span> get_data<span class="org-parenthesis">()</span>:
            <span class="org-variable-name">loss</span> <span class="org-operator">=</span> criterion<span class="org-parenthesis">(</span>model<span class="org-parenthesis">(</span>x<span class="org-parenthesis">),</span> x<span class="org-parenthesis">)</span>
            optimizer.zero_grad<span class="org-parenthesis">()</span>
            loss.backward<span class="org-parenthesis">()</span>
            optimizer.step<span class="org-parenthesis">()</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">if i % 10 == 0:</span>
        <span class="org-comment-delimiter">#     </span><span class="org-comment">print("epoch #%d: loss: %f" % (i, loss.detach().item()))</span>


<span class="org-keyword">def</span> <span class="org-function-name">load_model</span><span class="org-parenthesis">()</span>:
    <span class="org-variable-name">quant_desc_input</span> <span class="org-operator">=</span> QuantDescriptor<span class="org-parenthesis">(</span>calib_method<span class="org-operator">=</span><span class="org-string">"histogram"</span><span class="org-parenthesis">)</span>
    quant_nn.QuantConv2d.set_default_quant_desc_input<span class="org-parenthesis">(</span>quant_desc_input<span class="org-parenthesis">)</span>
    quant_nn.QuantLinear.set_default_quant_desc_input<span class="org-parenthesis">(</span>quant_desc_input<span class="org-parenthesis">)</span>

    quant_modules.initialize<span class="org-parenthesis">()</span>

    <span class="org-variable-name">model</span> <span class="org-operator">=</span> nn.Sequential<span class="org-parenthesis">(</span>
        nn.Linear<span class="org-parenthesis">(</span>5<span class="org-parenthesis">,</span> 1<span class="org-parenthesis">),</span>
        nn.Linear<span class="org-parenthesis">(</span>1<span class="org-parenthesis">,</span> 5<span class="org-parenthesis">),</span>
    <span class="org-parenthesis">)</span>
    model.load_state_dict<span class="org-parenthesis">(</span>torch.load<span class="org-parenthesis">(</span><span class="org-string">"model.pt"</span><span class="org-parenthesis">))</span>
    <span class="org-keyword">return</span> model


<span class="org-keyword">def</span> <span class="org-function-name">fake_quantize</span><span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>:
    <span class="org-keyword">def</span> <span class="org-function-name">collect_stats</span><span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> data<span class="org-parenthesis">,</span> num_batches<span class="org-parenthesis">)</span>:
        <span class="org-keyword">for</span> name<span class="org-parenthesis">,</span> module <span class="org-keyword">in</span> model.named_modules<span class="org-parenthesis">()</span>:
            <span class="org-keyword">if</span> <span class="org-builtin">isinstance</span><span class="org-parenthesis">(</span>module<span class="org-parenthesis">,</span> quant_nn.TensorQuantizer<span class="org-parenthesis">)</span>:
                module.disable_quant<span class="org-parenthesis">()</span>
                module.enable_calib<span class="org-parenthesis">()</span>

        <span class="org-keyword">for</span> i<span class="org-parenthesis">,</span> data <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span><span class="org-parenthesis">(</span>data<span class="org-parenthesis">)</span>:
            model<span class="org-parenthesis">(</span>data<span class="org-parenthesis">)</span>
            <span class="org-keyword">if</span> i <span class="org-operator">&gt;=</span> num_batches:
                <span class="org-keyword">break</span>
        <span class="org-keyword">for</span> name<span class="org-parenthesis">,</span> module <span class="org-keyword">in</span> model.named_modules<span class="org-parenthesis">()</span>:
            <span class="org-keyword">if</span> <span class="org-builtin">isinstance</span><span class="org-parenthesis">(</span>module<span class="org-parenthesis">,</span> quant_nn.TensorQuantizer<span class="org-parenthesis">)</span>:
                module.enable_quant<span class="org-parenthesis">()</span>
                module.disable_calib<span class="org-parenthesis">()</span>

    <span class="org-keyword">def</span> <span class="org-function-name">compute_amax</span><span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> <span class="org-operator">**</span>kwargs<span class="org-parenthesis">)</span>:
        <span class="org-keyword">for</span> name<span class="org-parenthesis">,</span> module <span class="org-keyword">in</span> model.named_modules<span class="org-parenthesis">()</span>:
            <span class="org-keyword">if</span> <span class="org-builtin">isinstance</span><span class="org-parenthesis">(</span>module<span class="org-parenthesis">,</span> quant_nn.TensorQuantizer<span class="org-parenthesis">)</span>:
                <span class="org-keyword">if</span> <span class="org-builtin">isinstance</span><span class="org-parenthesis">(</span>module._calibrator<span class="org-parenthesis">,</span> calib.MaxCalibrator<span class="org-parenthesis">)</span>:
                    module.load_calib_amax<span class="org-parenthesis">()</span>
                <span class="org-keyword">else</span>:
                    module.load_calib_amax<span class="org-parenthesis">(</span>method<span class="org-operator">=</span><span class="org-string">"percentile"</span><span class="org-parenthesis">)</span>

    <span class="org-keyword">with</span> torch.no_grad<span class="org-parenthesis">()</span>:
        collect_stats<span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> get_data<span class="org-parenthesis">(),</span> num_batches<span class="org-operator">=</span>1000<span class="org-parenthesis">)</span>
        compute_amax<span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>

    <span class="org-comment-delimiter"># </span><span class="org-comment">for name, module in model.named_modules():</span>
    <span class="org-comment-delimiter">#     </span><span class="org-comment">if isinstance(module, quant_nn.TensorQuantizer):</span>
    <span class="org-comment-delimiter">#         </span><span class="org-comment">print("------")</span>
    <span class="org-comment-delimiter">#         </span><span class="org-comment">print(name, module)</span>

    <span class="org-keyword">return</span> model


<span class="org-keyword">def</span> <span class="org-function-name">test</span><span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>:
    <span class="org-variable-name">x</span> <span class="org-operator">=</span> torch.tensor<span class="org-parenthesis">(</span>[[10<span class="org-parenthesis">,</span> 20<span class="org-parenthesis">,</span> 30<span class="org-parenthesis">,</span> 40<span class="org-parenthesis">,</span> 50]]<span class="org-parenthesis">)</span>.<span class="org-builtin">float</span><span class="org-parenthesis">()</span>
    <span class="org-variable-name">y_hat</span> <span class="org-operator">=</span> model<span class="org-parenthesis">(</span>x<span class="org-parenthesis">)</span>
    <span class="org-builtin">print</span><span class="org-parenthesis">(</span>y_hat<span class="org-parenthesis">)</span>


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> <span class="org-operator">==</span> <span class="org-string">"__main__"</span>:
    pretrain_model<span class="org-parenthesis">()</span>

    <span class="org-variable-name">model</span> <span class="org-operator">=</span> load_model<span class="org-parenthesis">()</span>
    test<span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>

    fake_quantize<span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>
    test<span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>

    train_model<span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> epoch<span class="org-operator">=</span>1<span class="org-parenthesis">)</span>
    fake_quantize<span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>
    test<span class="org-parenthesis">(</span>model<span class="org-parenthesis">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org000001c" class="outline-4">
<h4 id="org000001c"><span class="section-number-4">1.1.2.</span> Impl</h4>
<div class="outline-text-4" id="text-1-1-2">
</div>
<div id="outline-container-org0000003" class="outline-5">
<h5 id="org0000003"><span class="section-number-5">1.1.2.1.</span> monkey patching</h5>
<div class="outline-text-5" id="text-1-1-2-1">
<p>
quant_modules.initialize 会把 torch.nn 中的 Linear 等模块替换成 QuantLinear 等模块
</p>
</div>
</div>

<div id="outline-container-org0000013" class="outline-5">
<h5 id="org0000013"><span class="section-number-5">1.1.2.2.</span> foward</h5>
<div class="outline-text-5" id="text-1-1-2-2">
</div>
<div id="outline-container-org0000006" class="outline-6">
<h6 id="org0000006"><span class="section-number-6">1.1.2.2.1.</span> QuantLinear</h6>
<div class="outline-text-6" id="text-1-1-2-2-1">
<p>
forward 会被 propagate 给两个 TensorQuantizer: input_quantizer 和
weight_quantizer
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">forward</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> <span class="org-builtin">input</span><span class="org-parenthesis">)</span>:
    <span class="org-variable-name">quant_input</span> <span class="org-operator">=</span> <span class="org-keyword">self</span>._input_quantizer<span class="org-parenthesis">(</span><span class="org-builtin">input</span><span class="org-parenthesis">)</span>
    <span class="org-variable-name">quant_weight</span> <span class="org-operator">=</span> <span class="org-keyword">self</span>._weight_quantizer<span class="org-parenthesis">(</span><span class="org-keyword">self</span>.weight<span class="org-parenthesis">)</span>
    <span class="org-variable-name">output</span> <span class="org-operator">=</span> F.linear<span class="org-parenthesis">(</span>quant_input<span class="org-parenthesis">,</span> quant_weight<span class="org-parenthesis">,</span> bias<span class="org-operator">=</span><span class="org-keyword">self</span>.bias<span class="org-parenthesis">)</span>
    <span class="org-keyword">return</span> output
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000009" class="outline-6">
<h6 id="org0000009"><span class="section-number-6">1.1.2.2.2.</span> TensorQuantizer</h6>
<div class="outline-text-6" id="text-1-1-2-2-2">
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">forward</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> inputs<span class="org-parenthesis">)</span>:
    <span class="org-keyword">if</span> <span class="org-keyword">self</span>._disabled:
        <span class="org-keyword">return</span> inputs

    <span class="org-variable-name">outputs</span> <span class="org-operator">=</span> inputs

    <span class="org-comment-delimiter"># </span><span class="org-comment">&#35843;&#29992; TensorQuantizer.enable_calib() &#20250;&#35774;&#32622; _if_calib, &#34920;&#31034; calibrator &#38656;&#35201;</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">&#35760;&#24405;&#20197;&#33719;&#24471;&#26368;&#22823;&#20540; amax (abs max)</span>
    <span class="org-keyword">if</span> <span class="org-keyword">self</span>._if_calib:
        <span class="org-keyword">self</span>._calibrator.collect<span class="org-parenthesis">(</span>inputs<span class="org-parenthesis">)</span>

    <span class="org-comment-delimiter"># </span><span class="org-comment">&#35843;&#29992; enable_quant() &#20250;&#35774;&#32622; _if_quant, &#34920;&#31034;&#38656;&#35201;&#20351;&#29992; amax &#36827;&#34892; fake quant&#20351;</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">&#29992;&#26102;&#38656;&#35201;&#20808; enable calib, disable quant, calib &#23436;&#25104;&#21518;&#35745;&#31639; amax, &#28982;&#21518;&#20877;</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">enable quant, disable calib &#36827;&#34892;&#24102; fake quant &#30340; evaluation</span>
    <span class="org-keyword">if</span> <span class="org-keyword">self</span>._if_quant:
        <span class="org-variable-name">outputs</span> <span class="org-operator">=</span> <span class="org-keyword">self</span>._quant_forward<span class="org-parenthesis">(</span>inputs<span class="org-parenthesis">)</span>

    <span class="org-keyword">return</span> outputs


<span class="org-keyword">def</span> <span class="org-function-name">_quant_forward</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> inputs<span class="org-parenthesis">)</span>:
    <span class="org-comment-delimiter"># </span><span class="org-comment">amax &#26102;&#36890;&#36807; load_calib_amax &#35745;&#31639;&#30340; amax</span>
    <span class="org-variable-name">amax</span> <span class="org-operator">=</span> <span class="org-keyword">self</span>._get_amax<span class="org-parenthesis">(</span>inputs<span class="org-parenthesis">)</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">fake_tensor_quant &#26159;&#27880;&#20876;&#30340; autograd function</span>
    <span class="org-keyword">if</span> <span class="org-keyword">not</span> TensorQuantizer.use_fb_fake_quant:
        <span class="org-variable-name">outputs</span> <span class="org-operator">=</span> fake_tensor_quant<span class="org-parenthesis">(</span>
            inputs<span class="org-parenthesis">,</span> amax<span class="org-parenthesis">,</span> <span class="org-keyword">self</span>._num_bits<span class="org-parenthesis">,</span> <span class="org-keyword">self</span>._unsigned<span class="org-parenthesis">,</span> <span class="org-keyword">self</span>._narrow_range
        <span class="org-parenthesis">)</span>
    <span class="org-keyword">else</span>:
        <span class="org-variable-name">outputs</span> <span class="org-operator">=</span> <span class="org-keyword">self</span>._fb_fake_quant<span class="org-parenthesis">(</span>inputs<span class="org-parenthesis">,</span> amax<span class="org-parenthesis">)</span>
    <span class="org-keyword">return</span> outputs
</pre>
</div>
</div>
</div>

<div id="outline-container-org000000c" class="outline-6">
<h6 id="org000000c"><span class="section-number-6">1.1.2.2.3.</span> fake_tensor_quant</h6>
<div class="outline-text-6" id="text-1-1-2-2-3">
<p>
<a href="https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html">https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html</a>
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">class</span> <span class="org-type">FakeTensorQuantFunction</span><span class="org-parenthesis">(</span>Function<span class="org-parenthesis">)</span>:
    @<span class="org-builtin">staticmethod</span>
    <span class="org-keyword">def</span> <span class="org-function-name">forward</span><span class="org-parenthesis">(</span>ctx<span class="org-parenthesis">,</span> inputs<span class="org-parenthesis">,</span> amax<span class="org-parenthesis">,</span> num_bits<span class="org-operator">=</span>8<span class="org-parenthesis">,</span> unsigned<span class="org-operator">=</span><span class="org-constant">False</span><span class="org-parenthesis">,</span> narrow_range<span class="org-operator">=</span><span class="org-constant">True</span><span class="org-parenthesis">)</span>:
        ctx.save_for_backward<span class="org-parenthesis">(</span>inputs<span class="org-parenthesis">,</span> amax<span class="org-parenthesis">)</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">fake quant &#21363; outputs=dequant(quant(inputs))</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">1. quant, &#35745;&#31639; scale &#24182;&#35745;&#31639; outputs=inputs*scale</span>
        <span class="org-variable-name">outputs</span><span class="org-parenthesis">,</span> <span class="org-variable-name">scale</span> <span class="org-operator">=</span> _tensor_quant<span class="org-parenthesis">(</span>inputs<span class="org-parenthesis">,</span> amax<span class="org-parenthesis">,</span> num_bits<span class="org-parenthesis">,</span> unsigned<span class="org-parenthesis">,</span> narrow_range<span class="org-parenthesis">)</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">2. dequant, outputs=outputs/scale</span>
        <span class="org-keyword">return</span> outputs <span class="org-operator">/</span> scale.to<span class="org-parenthesis">(</span>inputs.dtype<span class="org-parenthesis">)</span>

    @<span class="org-builtin">staticmethod</span>
    <span class="org-keyword">def</span> <span class="org-function-name">backward</span><span class="org-parenthesis">(</span>ctx<span class="org-parenthesis">,</span> grad_outputs<span class="org-parenthesis">)</span>:
        <span class="org-comment-delimiter"># </span><span class="org-comment">...</span>

<span class="org-variable-name">fake_tensor_quant</span> <span class="org-operator">=</span> FakeTensorQuantFunction.<span class="org-builtin">apply</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000010" class="outline-6">
<h6 id="org0000010"><span class="section-number-6">1.1.2.2.4.</span> _fb_fake_quant</h6>
<div class="outline-text-6" id="text-1-1-2-2-4">
<p>
在导出成 onnx 时需要通过设置 use_fb_fake_quant = True 调用_fb_fake_quant, 后者会调用 torch.fake_quantize_per_channel_affine,以便 export 时能导出成 onnx 标准的
QuantizeLinear / DequantizeLinear
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">_fb_fake_quant</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> inputs<span class="org-parenthesis">,</span> amax<span class="org-parenthesis">)</span>:
    <span class="org-variable-name">bound</span> <span class="org-operator">=</span> <span class="org-parenthesis">(</span>1 <span class="org-operator">&lt;&lt;</span> <span class="org-parenthesis">(</span><span class="org-keyword">self</span>._num_bits <span class="org-operator">-</span> 1 <span class="org-operator">+</span> <span class="org-builtin">int</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span>._unsigned<span class="org-parenthesis">)))</span> <span class="org-operator">-</span> 1
    <span class="org-variable-name">outputs</span> <span class="org-operator">=</span> torch.fake_quantize_per_tensor_affine<span class="org-parenthesis">(</span>
        inputs<span class="org-parenthesis">,</span>
        amax.item<span class="org-parenthesis">()</span> <span class="org-operator">/</span> bound<span class="org-parenthesis">,</span>
        0<span class="org-parenthesis">,</span>
        <span class="org-operator">-</span>bound <span class="org-operator">-</span> 1 <span class="org-keyword">if</span> <span class="org-keyword">not</span> <span class="org-keyword">self</span>._unsigned <span class="org-keyword">else</span> 0<span class="org-parenthesis">,</span>
        bound<span class="org-parenthesis">,</span>
    <span class="org-parenthesis">)</span>
    <span class="org-keyword">return</span> outputs
</pre>
</div>

<p>
导出成 onnx 的结果为:
</p>


<div id="org000000f" class="figure">
<p><img src="../extra/trt_quant.png" alt="trt_quant.png" />
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org0000019" class="outline-5">
<h5 id="org0000019"><span class="section-number-5">1.1.2.3.</span> backward</h5>
<div class="outline-text-5" id="text-1-1-2-3">
</div>
<div id="outline-container-org0000016" class="outline-6">
<h6 id="org0000016"><span class="section-number-6">1.1.2.3.1.</span> FakeTensorQuantFunction</h6>
<div class="outline-text-6" id="text-1-1-2-3-1">
<p>
Straight Through Estimation (STE) with clipping
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">backward</span><span class="org-parenthesis">(</span>ctx<span class="org-parenthesis">,</span> grad_outputs<span class="org-parenthesis">)</span>:
    <span class="org-variable-name">inputs</span><span class="org-parenthesis">,</span> <span class="org-variable-name">amax</span> <span class="org-operator">=</span> ctx.saved_tensors
    <span class="org-variable-name">zero</span> <span class="org-operator">=</span> grad_outputs.new_zeros<span class="org-parenthesis">(</span>1<span class="org-parenthesis">)</span>
    <span class="org-variable-name">grad_inputs</span> <span class="org-operator">=</span> torch.where<span class="org-parenthesis">(</span>inputs.<span class="org-builtin">abs</span><span class="org-parenthesis">()</span> <span class="org-operator">&lt;=</span> amax<span class="org-parenthesis">,</span> grad_outputs<span class="org-parenthesis">,</span> zero<span class="org-parenthesis">)</span>
    <span class="org-keyword">return</span> grad_inputs<span class="org-parenthesis">,</span> <span class="org-constant">None</span><span class="org-parenthesis">,</span> <span class="org-constant">None</span><span class="org-parenthesis">,</span> <span class="org-constant">None</span><span class="org-parenthesis">,</span> <span class="org-constant">None</span>
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-org0000021" class="outline-4">
<h4 id="org0000021"><span class="section-number-4">1.1.3.</span> TensorRT Optimizer</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
<a href="https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31653/">https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31653/</a>
</p>

<p>
QuantLinear 把原来的 \(w*x+b\) 变成为 \(DQ(Q(w))*DQ(Q(x))+b\), 后续需要 tensorrt 的
optimizer 把 DQ 和 Q 前移或后移达到量化计算的目的, 例如:
</p>

<pre class="example" id="org000001f">
x -&gt; Q1 -&gt; DQ1 -&gt; [mul] -&gt;  y
                    ^
w -&gt; Q2 -&gt; DQ2 -----|
</pre>

<p>
可以优化为:
</p>

<pre class="example" id="org0000020">
x -&gt; Q1 -&gt; [mul] -&gt; [DQ1 -&gt; DQ2] -&gt; y
             ^
    [w-&gt;Q2] -|
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000024" class="outline-3">
<h3 id="org0000024"><span class="section-number-3">1.2.</span> Sparsity</h3>
<div class="outline-text-3" id="text-1-2">
<p>
<a href="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/">https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/</a>
</p>

<p>
<a href="https://github.com/NVIDIA/apex/tree/master/apex/contrib/sparsity">https://github.com/NVIDIA/apex/tree/master/apex/contrib/sparsity</a> 是一个做
prunning 的 pytorch 插件
</p>

<ol class="org-ol">
<li>它只会对 Linear, Conv2D 等的 weight 做 prunning,</li>

<li>它要求 weight 有特定的 shape, 比如对于 [x,y] 大小的 Linear Layer 需要 x%8==0,
y%16==0</li>

<li>在 pruning 时, 默认使用 m4n2_1d 的方式, 即在一维的方向上每 4 个数固定选择两个绝对值最小的数进行 prunning</li>

<li>prunning 之后会在 torch 模型中针对每个被 prune 的参数记录一个 mask buffer, 这个 buffer 有两个作用:

<ol class="org-ol">
<li>GPU 需要根据这个 buffer 进行 sparsity 操作</li>

<li>sparsity 工具 (ASP) 会对 pytorch 的 optimizer 进行 monkey patching, 修改过的 optimizer 会利用这个 buffer 保证对 prunning 后的模型进行训练时会跳过已经被 prune 的数据</li>
</ol></li>
</ol>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-11-09 13:38</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-------------------- sparse_masklib.py --------------------</span>
<span class="org-keyword">import</span> sys
<span class="org-keyword">import</span> torch
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> collections
<span class="org-keyword">from</span> itertools <span class="org-keyword">import</span> permutations


<span class="org-keyword">def</span> <span class="org-function-name">fill</span><span class="org-parenthesis">(</span>x<span class="org-parenthesis">)</span>:
    <span class="org-keyword">return</span> <span class="org-builtin">float</span><span class="org-parenthesis">(</span>x.nonzero<span class="org-parenthesis">()</span>.size<span class="org-parenthesis">(</span>0<span class="org-parenthesis">))</span> <span class="org-operator">/</span> torch.numel<span class="org-parenthesis">(</span>x<span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">reshape_1d</span><span class="org-parenthesis">(</span>matrix<span class="org-parenthesis">,</span> m<span class="org-parenthesis">)</span>:
    <span class="org-comment-delimiter"># </span><span class="org-comment">If not a nice multiple of m, fill with zeroes.</span>
    <span class="org-keyword">if</span> matrix.shape[1] <span class="org-operator">%</span> m <span class="org-operator">&gt;</span> 0:
        <span class="org-variable-name">mat</span> <span class="org-operator">=</span> torch.cuda.FloatTensor<span class="org-parenthesis">(</span>
            matrix.shape[0]<span class="org-parenthesis">,</span> matrix.shape[1] <span class="org-operator">+</span> <span class="org-parenthesis">(</span>m <span class="org-operator">-</span> matrix.shape[1] <span class="org-operator">%</span> m<span class="org-parenthesis">)</span>
        <span class="org-parenthesis">)</span>.fill_<span class="org-parenthesis">(</span>0<span class="org-parenthesis">)</span>
        mat[:<span class="org-parenthesis">,</span> : matrix.shape[1]] <span class="org-operator">=</span> matrix
        <span class="org-variable-name">shape</span> <span class="org-operator">=</span> mat.shape
        <span class="org-keyword">return</span> mat.view<span class="org-parenthesis">(</span><span class="org-operator">-</span>1<span class="org-parenthesis">,</span> m<span class="org-parenthesis">),</span> shape
    <span class="org-keyword">else</span>:
        <span class="org-keyword">return</span> matrix.view<span class="org-parenthesis">(</span><span class="org-operator">-</span>1<span class="org-parenthesis">,</span> m<span class="org-parenthesis">),</span> matrix.shape


<span class="org-variable-name">valid_m4n2_1d_patterns</span> <span class="org-operator">=</span> <span class="org-constant">None</span>


<span class="org-keyword">def</span> <span class="org-function-name">compute_valid_1d_patterns</span><span class="org-parenthesis">(</span>m<span class="org-parenthesis">,</span> n<span class="org-parenthesis">)</span>:
    <span class="org-comment-delimiter"># </span><span class="org-comment">Early exit if patterns was already created.</span>
    <span class="org-keyword">global</span> valid_m4n2_1d_patterns

    <span class="org-keyword">if</span> m <span class="org-operator">==</span> 4 <span class="org-keyword">and</span> n <span class="org-operator">==</span> 2 <span class="org-keyword">and</span> valid_m4n2_1d_patterns <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span>:
        <span class="org-keyword">return</span> valid_m4n2_1d_patterns
    <span class="org-variable-name">patterns</span> <span class="org-operator">=</span> torch.zeros<span class="org-parenthesis">(</span>m<span class="org-parenthesis">)</span>
    <span class="org-variable-name">patterns</span>[:n] <span class="org-operator">=</span> 1
    <span class="org-variable-name">valid_patterns</span> <span class="org-operator">=</span> torch.Tensor<span class="org-parenthesis">(</span><span class="org-builtin">list</span><span class="org-parenthesis">(</span><span class="org-builtin">set</span><span class="org-parenthesis">(</span>permutations<span class="org-parenthesis">(</span>patterns.tolist<span class="org-parenthesis">()))))</span>
    <span class="org-keyword">if</span> m <span class="org-operator">==</span> 4 <span class="org-keyword">and</span> n <span class="org-operator">==</span> 2:
        <span class="org-variable-name">valid_m4n2_1d_patterns</span> <span class="org-operator">=</span> valid_patterns
    <span class="org-keyword">return</span> valid_patterns


<span class="org-string">""" m:n 1d structured best """</span>


<span class="org-keyword">def</span> <span class="org-function-name">mn_1d_best</span><span class="org-parenthesis">(</span>matrix<span class="org-parenthesis">,</span> m<span class="org-parenthesis">,</span> n<span class="org-parenthesis">)</span>:
    <span class="org-comment-delimiter"># </span><span class="org-comment">Find all possible patterns.</span>
    <span class="org-variable-name">patterns</span> <span class="org-operator">=</span> compute_valid_1d_patterns<span class="org-parenthesis">(</span>m<span class="org-parenthesis">,</span> n<span class="org-parenthesis">)</span>.cuda<span class="org-parenthesis">()</span>

    <span class="org-comment-delimiter"># </span><span class="org-comment">Find the best m:n pattern (sum of non-masked weights).</span>
    <span class="org-variable-name">mask</span> <span class="org-operator">=</span> torch.cuda.IntTensor<span class="org-parenthesis">(</span>matrix.shape<span class="org-parenthesis">)</span>.fill_<span class="org-parenthesis">(</span>1<span class="org-parenthesis">)</span>.view<span class="org-parenthesis">(</span><span class="org-operator">-</span>1<span class="org-parenthesis">,</span> m<span class="org-parenthesis">)</span>
    <span class="org-variable-name">mat</span><span class="org-parenthesis">,</span> <span class="org-variable-name">shape</span> <span class="org-operator">=</span> reshape_1d<span class="org-parenthesis">(</span>matrix<span class="org-parenthesis">,</span> m<span class="org-parenthesis">)</span>
    <span class="org-variable-name">pmax</span> <span class="org-operator">=</span> torch.argmax<span class="org-parenthesis">(</span>torch.matmul<span class="org-parenthesis">(</span>mat.<span class="org-builtin">abs</span><span class="org-parenthesis">(),</span> patterns.t<span class="org-parenthesis">()),</span> dim<span class="org-operator">=</span>1<span class="org-parenthesis">)</span>
    <span class="org-variable-name">mask</span>[:] <span class="org-operator">=</span> patterns[pmax[:]]
    <span class="org-variable-name">mask</span> <span class="org-operator">=</span> mask.view<span class="org-parenthesis">(</span>matrix.shape<span class="org-parenthesis">)</span>
    <span class="org-keyword">return</span> mask


<span class="org-keyword">def</span> <span class="org-function-name">m4n2_1d</span><span class="org-parenthesis">(</span>mat<span class="org-parenthesis">,</span> density<span class="org-parenthesis">)</span>:
    <span class="org-keyword">return</span> mn_1d_best<span class="org-parenthesis">(</span>mat<span class="org-parenthesis">,</span> 4<span class="org-parenthesis">,</span> 2<span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">create_mask</span><span class="org-parenthesis">(</span>tensor<span class="org-parenthesis">,</span> pattern<span class="org-operator">=</span><span class="org-string">"m4n2_1d"</span><span class="org-parenthesis">,</span> density<span class="org-operator">=</span>0.5<span class="org-parenthesis">)</span>:
    <span class="org-comment-delimiter"># </span><span class="org-comment">Reshape tensor and mask.</span>
    <span class="org-variable-name">shape</span> <span class="org-operator">=</span> tensor.shape
    <span class="org-variable-name">ttype</span> <span class="org-operator">=</span> tensor.<span class="org-builtin">type</span><span class="org-parenthesis">()</span>
    <span class="org-variable-name">t</span> <span class="org-operator">=</span> tensor.<span class="org-builtin">float</span><span class="org-parenthesis">()</span>.contiguous<span class="org-parenthesis">()</span>

    <span class="org-comment-delimiter"># </span><span class="org-comment">1d-tensor</span>
    <span class="org-keyword">if</span> <span class="org-builtin">len</span><span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span> <span class="org-operator">==</span> 1:
        <span class="org-variable-name">t</span> <span class="org-operator">=</span> t.view<span class="org-parenthesis">(</span>1<span class="org-parenthesis">,</span> shape[0]<span class="org-parenthesis">)</span>
        <span class="org-variable-name">func</span> <span class="org-operator">=</span> <span class="org-builtin">getattr</span><span class="org-parenthesis">(</span>sys.modules[<span class="org-builtin">__name__</span>]<span class="org-parenthesis">,</span> pattern<span class="org-parenthesis">,</span> <span class="org-constant">None</span><span class="org-parenthesis">)</span>
        <span class="org-variable-name">mask</span> <span class="org-operator">=</span> func<span class="org-parenthesis">(</span>t<span class="org-parenthesis">,</span> density<span class="org-parenthesis">)</span>
        <span class="org-keyword">return</span> mask.view<span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span>.<span class="org-builtin">type</span><span class="org-parenthesis">(</span>ttype<span class="org-parenthesis">)</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">2d-tensor (in, out)</span>
    <span class="org-keyword">elif</span> <span class="org-builtin">len</span><span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span> <span class="org-operator">==</span> 2:
        <span class="org-variable-name">t</span> <span class="org-operator">=</span> t.view<span class="org-parenthesis">(</span>shape[0]<span class="org-parenthesis">,</span> shape[1]<span class="org-parenthesis">)</span>
        <span class="org-variable-name">func</span> <span class="org-operator">=</span> <span class="org-builtin">getattr</span><span class="org-parenthesis">(</span>sys.modules[<span class="org-builtin">__name__</span>]<span class="org-parenthesis">,</span> pattern<span class="org-parenthesis">,</span> <span class="org-constant">None</span><span class="org-parenthesis">)</span>
        <span class="org-variable-name">mask</span> <span class="org-operator">=</span> func<span class="org-parenthesis">(</span>t<span class="org-parenthesis">,</span> density<span class="org-parenthesis">)</span>
        <span class="org-keyword">return</span> mask.view<span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span>.<span class="org-builtin">type</span><span class="org-parenthesis">(</span>ttype<span class="org-parenthesis">)</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">3d-tensor (batch, in, out)</span>
    <span class="org-keyword">elif</span> <span class="org-builtin">len</span><span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span> <span class="org-operator">==</span> 3:
        <span class="org-variable-name">t</span> <span class="org-operator">=</span> t.view<span class="org-parenthesis">(</span>shape[0] <span class="org-operator">*</span> shape[1]<span class="org-parenthesis">,</span> shape[2]<span class="org-parenthesis">)</span>
        <span class="org-variable-name">func</span> <span class="org-operator">=</span> <span class="org-builtin">getattr</span><span class="org-parenthesis">(</span>sys.modules[<span class="org-builtin">__name__</span>]<span class="org-parenthesis">,</span> pattern<span class="org-parenthesis">,</span> <span class="org-constant">None</span><span class="org-parenthesis">)</span>
        <span class="org-variable-name">mask</span> <span class="org-operator">=</span> func<span class="org-parenthesis">(</span>t<span class="org-parenthesis">,</span> density<span class="org-parenthesis">)</span>
        <span class="org-keyword">return</span> mask.view<span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span>.<span class="org-builtin">type</span><span class="org-parenthesis">(</span>ttype<span class="org-parenthesis">)</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">4d-tensor (in, out, h, w)</span>
    <span class="org-keyword">elif</span> <span class="org-builtin">len</span><span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span> <span class="org-operator">==</span> 4:
        <span class="org-comment-delimiter"># </span><span class="org-comment">convs</span>
        <span class="org-variable-name">t</span> <span class="org-operator">=</span> <span class="org-parenthesis">(</span>
            t.permute<span class="org-parenthesis">(</span>2<span class="org-parenthesis">,</span> 3<span class="org-parenthesis">,</span> 0<span class="org-parenthesis">,</span> 1<span class="org-parenthesis">)</span>
            .contiguous<span class="org-parenthesis">()</span>
            .view<span class="org-parenthesis">(</span>shape[2] <span class="org-operator">*</span> shape[3] <span class="org-operator">*</span> shape[0]<span class="org-parenthesis">,</span> shape[1]<span class="org-parenthesis">)</span>
        <span class="org-parenthesis">)</span>
        <span class="org-variable-name">func</span> <span class="org-operator">=</span> <span class="org-builtin">getattr</span><span class="org-parenthesis">(</span>sys.modules[<span class="org-builtin">__name__</span>]<span class="org-parenthesis">,</span> pattern<span class="org-parenthesis">,</span> <span class="org-constant">None</span><span class="org-parenthesis">)</span>
        <span class="org-variable-name">mask</span> <span class="org-operator">=</span> func<span class="org-parenthesis">(</span>t<span class="org-parenthesis">,</span> density<span class="org-parenthesis">)</span>
        <span class="org-variable-name">mask</span> <span class="org-operator">=</span> <span class="org-parenthesis">(</span>
            mask.view<span class="org-parenthesis">(</span>shape[2]<span class="org-parenthesis">,</span> shape[3]<span class="org-parenthesis">,</span> shape[0]<span class="org-parenthesis">,</span> shape[1]<span class="org-parenthesis">)</span>
            .permute<span class="org-parenthesis">(</span>2<span class="org-parenthesis">,</span> 3<span class="org-parenthesis">,</span> 0<span class="org-parenthesis">,</span> 1<span class="org-parenthesis">)</span>
            .contiguous<span class="org-parenthesis">()</span>
        <span class="org-parenthesis">)</span>
        <span class="org-keyword">return</span> mask.view<span class="org-parenthesis">(</span>shape<span class="org-parenthesis">)</span>.<span class="org-builtin">type</span><span class="org-parenthesis">(</span>ttype<span class="org-parenthesis">)</span>


<span class="org-comment-delimiter"># </span><span class="org-comment">-------------------- asp.py --------------------</span>
<span class="org-keyword">import</span> types
<span class="org-keyword">import</span> torch

<span class="org-variable-name">torchvision_imported</span> <span class="org-operator">=</span> <span class="org-constant">True</span>
<span class="org-keyword">try</span>:
    <span class="org-keyword">import</span> torchvision
<span class="org-keyword">except</span> <span class="org-type">ImportError</span>:
    <span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"[ASP][Warning] torchvision cannot be imported."</span><span class="org-parenthesis">)</span>
    <span class="org-variable-name">torchvision_imported</span> <span class="org-operator">=</span> <span class="org-constant">False</span>


<span class="org-keyword">def</span> <span class="org-function-name">eligible_modules</span><span class="org-parenthesis">(</span>
    model<span class="org-parenthesis">,</span> whitelist_layer_types<span class="org-parenthesis">,</span> allowed_layer_names<span class="org-parenthesis">,</span> disallowed_layer_names
<span class="org-parenthesis">)</span>:
    <span class="org-variable-name">eligible_modules_list</span> <span class="org-operator">=</span> []
    <span class="org-keyword">for</span> name<span class="org-parenthesis">,</span> mod <span class="org-keyword">in</span> model.named_modules<span class="org-parenthesis">()</span>:
        <span class="org-keyword">if</span> <span class="org-parenthesis">(</span>
            <span class="org-builtin">isinstance</span><span class="org-parenthesis">(</span>mod<span class="org-parenthesis">,</span> whitelist_layer_types<span class="org-parenthesis">)</span>
            <span class="org-keyword">and</span> name <span class="org-keyword">not</span> <span class="org-keyword">in</span> disallowed_layer_names
        <span class="org-parenthesis">)</span>:
            <span class="org-keyword">if</span> allowed_layer_names <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span> <span class="org-keyword">and</span> name <span class="org-keyword">not</span> <span class="org-keyword">in</span> allowed_layer_names:
                <span class="org-keyword">continue</span>
            eligible_modules_list.append<span class="org-parenthesis">((</span>name<span class="org-parenthesis">,</span> mod<span class="org-parenthesis">))</span>
    <span class="org-keyword">return</span> eligible_modules_list


<span class="org-keyword">class</span> <span class="org-type">ASP</span>:
    <span class="org-variable-name">__model</span> <span class="org-operator">=</span> <span class="org-constant">None</span>
    <span class="org-variable-name">__verbosity</span> <span class="org-operator">=</span> 0
    <span class="org-variable-name">__optimizer</span> <span class="org-operator">=</span> <span class="org-constant">None</span>
    <span class="org-variable-name">__sparse_parameters</span> <span class="org-operator">=</span> []
    <span class="org-variable-name">__calculate_mask</span> <span class="org-operator">=</span> <span class="org-constant">None</span>

    @<span class="org-builtin">classmethod</span>
    <span class="org-keyword">def</span> <span class="org-function-name">init_model_for_pruning</span><span class="org-parenthesis">(</span>
        cls<span class="org-parenthesis">,</span>
        model<span class="org-parenthesis">,</span>
        mask_calculator<span class="org-operator">=</span><span class="org-string">"m4n2_1d"</span><span class="org-parenthesis">,</span>
        verbosity<span class="org-operator">=</span>3<span class="org-parenthesis">,</span>
        whitelist<span class="org-operator">=</span>[torch.nn.Linear<span class="org-parenthesis">,</span> torch.nn.Conv1d<span class="org-parenthesis">,</span> torch.nn.Conv2d<span class="org-parenthesis">,</span> torch.nn.Conv3d]<span class="org-parenthesis">,</span>
        allowed_layer_names<span class="org-operator">=</span><span class="org-constant">None</span><span class="org-parenthesis">,</span>
        disallowed_layer_names<span class="org-operator">=</span>[]<span class="org-parenthesis">,</span>
        allow_recompute_mask<span class="org-operator">=</span><span class="org-constant">False</span><span class="org-parenthesis">,</span>
        custom_layer_dict<span class="org-operator">=</span><span class="org-parenthesis">{},</span>
    <span class="org-parenthesis">)</span>:
        <span class="org-keyword">assert</span> cls.__model <span class="org-keyword">is</span> <span class="org-constant">None</span><span class="org-parenthesis">,</span> <span class="org-string">"ASP has been initialized already."</span>
        cls.<span class="org-variable-name">__model</span> <span class="org-operator">=</span> model
        cls.<span class="org-variable-name">__verbosity</span> <span class="org-operator">=</span> verbosity

        <span class="org-keyword">if</span> <span class="org-builtin">isinstance</span><span class="org-parenthesis">(</span>mask_calculator<span class="org-parenthesis">,</span> <span class="org-builtin">str</span><span class="org-parenthesis">)</span>:

            <span class="org-keyword">def</span> <span class="org-function-name">create_mask_from_pattern</span><span class="org-parenthesis">(</span>param<span class="org-parenthesis">)</span>:
                <span class="org-keyword">return</span> create_mask<span class="org-parenthesis">(</span>param<span class="org-parenthesis">,</span> mask_calculator<span class="org-parenthesis">)</span>.<span class="org-builtin">bool</span><span class="org-parenthesis">()</span>

            cls.<span class="org-variable-name">__calculate_mask</span> <span class="org-operator">=</span> create_mask_from_pattern
        <span class="org-keyword">else</span>:
            cls.<span class="org-variable-name">__calculate_mask</span> <span class="org-operator">=</span> mask_calculator  <span class="org-comment-delimiter"># </span><span class="org-comment">user defined function</span>

        <span class="org-comment-delimiter"># </span><span class="org-comment">function to extract variables that will be sparsified.</span>
        <span class="org-comment-delimiter"># </span><span class="org-comment">idea is that you will add one of these functions for each module type that can be sparsified.</span>
        <span class="org-keyword">if</span> torchvision_imported:
            <span class="org-builtin">print</span><span class="org-parenthesis">(</span>
                <span class="org-string">"[ASP] torchvision is imported, can work with the MaskRCNN/KeypointRCNN from torchvision."</span>
            <span class="org-parenthesis">)</span>
            <span class="org-variable-name">sparse_parameter_list</span> <span class="org-operator">=</span> <span class="org-parenthesis">{</span>
                torch.nn.Linear: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
                torch.nn.Conv1d: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
                torch.nn.Conv2d: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
                torch.nn.Conv3d: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
                torchvision.ops.misc.Conv2d: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
            <span class="org-parenthesis">}</span>
        <span class="org-keyword">else</span>:
            <span class="org-variable-name">sparse_parameter_list</span> <span class="org-operator">=</span> <span class="org-parenthesis">{</span>
                torch.nn.Linear: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
                torch.nn.Conv1d: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
                torch.nn.Conv2d: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
                torch.nn.Conv3d: [<span class="org-string">"weight"</span>]<span class="org-parenthesis">,</span>
            <span class="org-parenthesis">}</span>
        <span class="org-keyword">if</span> <span class="org-parenthesis">(</span>
            custom_layer_dict
        <span class="org-parenthesis">)</span>:  <span class="org-comment-delimiter"># </span><span class="org-comment">Update default list to include user supplied custom (layer type : parameter tensor), make sure this tensor type is something ASP knows how to prune</span>
            sparse_parameter_list.update<span class="org-parenthesis">(</span>custom_layer_dict<span class="org-parenthesis">)</span>
            <span class="org-variable-name">whitelist</span> <span class="org-operator">+=</span> <span class="org-builtin">list</span><span class="org-parenthesis">(</span>custom_layer_dict.keys<span class="org-parenthesis">())</span>

        <span class="org-keyword">for</span> module_type <span class="org-keyword">in</span> whitelist:
            <span class="org-keyword">assert</span> module_type <span class="org-keyword">in</span> sparse_parameter_list<span class="org-parenthesis">,</span> <span class="org-parenthesis">(</span>
                <span class="org-string">"Module %s :: Don't know how to sparsify module."</span> <span class="org-operator">%</span> module.dtype<span class="org-parenthesis">()</span>
            <span class="org-parenthesis">)</span>

        <span class="org-comment-delimiter"># </span><span class="org-comment">find all sparse modules, extract sparse parameters and decorate</span>
        <span class="org-keyword">def</span> <span class="org-function-name">add_sparse_attributes</span><span class="org-parenthesis">(</span>module_name<span class="org-parenthesis">,</span> module<span class="org-parenthesis">)</span>:
            <span class="org-variable-name">sparse_parameters</span> <span class="org-operator">=</span> sparse_parameter_list[<span class="org-builtin">type</span><span class="org-parenthesis">(</span>module<span class="org-parenthesis">)</span>]
            <span class="org-keyword">for</span> p_name<span class="org-parenthesis">,</span> p <span class="org-keyword">in</span> module.named_parameters<span class="org-parenthesis">()</span>:
                <span class="org-keyword">if</span> p_name <span class="org-keyword">in</span> sparse_parameters <span class="org-keyword">and</span> p.requires_grad:
                    <span class="org-comment-delimiter"># </span><span class="org-comment">check for NVIDIA's TC compatibility: we check along the horizontal direction</span>
                    <span class="org-keyword">if</span> p.dtype <span class="org-operator">==</span> torch.float32 <span class="org-keyword">and</span> <span class="org-parenthesis">(</span>
                        <span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()</span>[0] <span class="org-operator">%</span> 8<span class="org-parenthesis">)</span> <span class="org-operator">!=</span> 0 <span class="org-keyword">or</span> <span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()</span>[1] <span class="org-operator">%</span> 16<span class="org-parenthesis">)</span> <span class="org-operator">!=</span> 0
                    <span class="org-parenthesis">)</span>:  <span class="org-comment-delimiter"># </span><span class="org-comment">User defines FP32 and APEX internally uses FP16 math</span>
                        <span class="org-builtin">print</span><span class="org-parenthesis">(</span>
                            <span class="org-string">"[ASP] Auto skipping pruning %s::%s of size=%s and type=%s for sparsity"</span>
                            <span class="org-operator">%</span> <span class="org-parenthesis">(</span>module_name<span class="org-parenthesis">,</span> p_name<span class="org-parenthesis">,</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()),</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.dtype<span class="org-parenthesis">))</span>
                        <span class="org-parenthesis">)</span>
                        <span class="org-keyword">continue</span>
                    <span class="org-keyword">if</span> p.dtype <span class="org-operator">==</span> torch.float16 <span class="org-keyword">and</span> <span class="org-parenthesis">(</span>
                        <span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()</span>[0] <span class="org-operator">%</span> 8<span class="org-parenthesis">)</span> <span class="org-operator">!=</span> 0 <span class="org-keyword">or</span> <span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()</span>[1] <span class="org-operator">%</span> 16<span class="org-parenthesis">)</span> <span class="org-operator">!=</span> 0
                    <span class="org-parenthesis">)</span>:  <span class="org-comment-delimiter"># </span><span class="org-comment">For Conv2d dim= K x CRS; we prune along C</span>
                        <span class="org-builtin">print</span><span class="org-parenthesis">(</span>
                            <span class="org-string">"[ASP] Auto skipping pruning %s::%s of size=%s and type=%s for sparsity"</span>
                            <span class="org-operator">%</span> <span class="org-parenthesis">(</span>module_name<span class="org-parenthesis">,</span> p_name<span class="org-parenthesis">,</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()),</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.dtype<span class="org-parenthesis">))</span>
                        <span class="org-parenthesis">)</span>
                        <span class="org-keyword">continue</span>

                    <span class="org-keyword">if</span> cls.__verbosity <span class="org-operator">&gt;=</span> 3:
                        <span class="org-builtin">print</span><span class="org-parenthesis">(</span>
                            <span class="org-string">"[ASP] Sparsifying %s::%s of size=%s and type=%s for sparsity"</span>
                            <span class="org-operator">%</span> <span class="org-parenthesis">(</span>module_name<span class="org-parenthesis">,</span> p_name<span class="org-parenthesis">,</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()),</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.dtype<span class="org-parenthesis">))</span>
                        <span class="org-parenthesis">)</span>

                    <span class="org-variable-name">mask</span> <span class="org-operator">=</span> torch.ones_like<span class="org-parenthesis">(</span>p<span class="org-parenthesis">)</span>.<span class="org-builtin">bool</span><span class="org-parenthesis">()</span>
                    <span class="org-variable-name">buffname</span> <span class="org-operator">=</span> p_name.split<span class="org-parenthesis">(</span><span class="org-string">"."</span><span class="org-parenthesis">)</span>[<span class="org-operator">-</span>1]  <span class="org-comment-delimiter"># </span><span class="org-comment">buffer names cannot contain "."</span>
                    module.register_buffer<span class="org-parenthesis">(</span><span class="org-string">"__%s_mma_mask"</span> <span class="org-operator">%</span> buffname<span class="org-parenthesis">,</span> mask<span class="org-parenthesis">)</span>
                    <span class="org-keyword">if</span> allow_recompute_mask:
                        <span class="org-variable-name">pruned</span> <span class="org-operator">=</span> torch.zeros_like<span class="org-parenthesis">(</span>p<span class="org-parenthesis">)</span>.cpu<span class="org-parenthesis">()</span>
                        module.register_buffer<span class="org-parenthesis">(</span><span class="org-string">"__%s_mma_pruned_p"</span> <span class="org-operator">%</span> buffname<span class="org-parenthesis">,</span> pruned<span class="org-parenthesis">)</span>
                    <span class="org-keyword">else</span>:
                        <span class="org-variable-name">pruned</span> <span class="org-operator">=</span> <span class="org-constant">None</span>
                    cls.__sparse_parameters.append<span class="org-parenthesis">(</span>
                        <span class="org-parenthesis">(</span>module_name<span class="org-parenthesis">,</span> module<span class="org-parenthesis">,</span> p_name<span class="org-parenthesis">,</span> p<span class="org-parenthesis">,</span> mask<span class="org-parenthesis">,</span> pruned<span class="org-parenthesis">)</span>
                    <span class="org-parenthesis">)</span>
                <span class="org-keyword">else</span>:
                    <span class="org-keyword">if</span> cls.__verbosity <span class="org-operator">&gt;=</span> 3:
                        <span class="org-builtin">print</span><span class="org-parenthesis">(</span>
                            <span class="org-string">"[ASP] Not sparsifying %s::%s of size=%s and type=%s"</span>
                            <span class="org-operator">%</span> <span class="org-parenthesis">(</span>module_name<span class="org-parenthesis">,</span> p_name<span class="org-parenthesis">,</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()),</span> <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.dtype<span class="org-parenthesis">))</span>
                        <span class="org-parenthesis">)</span>

        <span class="org-keyword">for</span> name<span class="org-parenthesis">,</span> sparse_module <span class="org-keyword">in</span> eligible_modules<span class="org-parenthesis">(</span>
            model<span class="org-parenthesis">,</span> <span class="org-builtin">tuple</span><span class="org-parenthesis">(</span>whitelist<span class="org-parenthesis">),</span> allowed_layer_names<span class="org-parenthesis">,</span> disallowed_layer_names
        <span class="org-parenthesis">)</span>:
            add_sparse_attributes<span class="org-parenthesis">(</span>name<span class="org-parenthesis">,</span> sparse_module<span class="org-parenthesis">)</span>

    @<span class="org-builtin">classmethod</span>
    <span class="org-keyword">def</span> <span class="org-function-name">init_optimizer_for_pruning</span><span class="org-parenthesis">(</span>cls<span class="org-parenthesis">,</span> optimizer<span class="org-parenthesis">)</span>:
        <span class="org-keyword">assert</span> cls.__optimizer <span class="org-keyword">is</span> <span class="org-constant">None</span><span class="org-parenthesis">,</span> <span class="org-string">"ASP has initialized optimizer already."</span>
        <span class="org-keyword">assert</span> <span class="org-parenthesis">(</span>
            cls.__calculate_mask <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span>
        <span class="org-parenthesis">),</span> <span class="org-string">"Called ASP.init_optimizer_for_pruning before ASP.init_model_for_pruning."</span>

        <span class="org-comment-delimiter"># </span><span class="org-comment">store pointer to original optimizer step method</span>
        cls.<span class="org-variable-name">__optimizer</span> <span class="org-operator">=</span> optimizer
        cls.__optimizer.<span class="org-variable-name">__step</span> <span class="org-operator">=</span> optimizer.step

        <span class="org-keyword">def</span> <span class="org-function-name">__step</span><span class="org-parenthesis">(</span>opt_self<span class="org-parenthesis">,</span> <span class="org-operator">*</span>args<span class="org-parenthesis">,</span> <span class="org-operator">**</span>kwargs<span class="org-parenthesis">)</span>:
            <span class="org-comment-delimiter"># </span><span class="org-comment">prune gradients before step method</span>
            <span class="org-keyword">with</span> torch.no_grad<span class="org-parenthesis">()</span>:
                <span class="org-keyword">for</span> <span class="org-parenthesis">(</span>
                    module_name<span class="org-parenthesis">,</span>
                    module<span class="org-parenthesis">,</span>
                    p_name<span class="org-parenthesis">,</span>
                    p<span class="org-parenthesis">,</span>
                    mask<span class="org-parenthesis">,</span>
                    pruned<span class="org-parenthesis">,</span>
                <span class="org-parenthesis">)</span> <span class="org-keyword">in</span> cls.__sparse_parameters:
                    <span class="org-keyword">if</span> p.grad <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span>:  <span class="org-comment-delimiter"># </span><span class="org-comment">thx pjudd</span>
                        p.grad.mul_<span class="org-parenthesis">(</span>mask<span class="org-parenthesis">)</span>
            <span class="org-comment-delimiter"># </span><span class="org-comment">call original optimizer step method</span>
            <span class="org-variable-name">rval</span> <span class="org-operator">=</span> opt_self.__step<span class="org-parenthesis">(</span><span class="org-operator">*</span>args<span class="org-parenthesis">,</span> <span class="org-operator">**</span>kwargs<span class="org-parenthesis">)</span>
            <span class="org-comment-delimiter"># </span><span class="org-comment">prune parameters after step method</span>
            <span class="org-keyword">with</span> torch.no_grad<span class="org-parenthesis">()</span>:
                <span class="org-keyword">for</span> <span class="org-parenthesis">(</span>
                    module_name<span class="org-parenthesis">,</span>
                    module<span class="org-parenthesis">,</span>
                    p_name<span class="org-parenthesis">,</span>
                    p<span class="org-parenthesis">,</span>
                    mask<span class="org-parenthesis">,</span>
                    pruned<span class="org-parenthesis">,</span>
                <span class="org-parenthesis">)</span> <span class="org-keyword">in</span> cls.__sparse_parameters:
                    p.mul_<span class="org-parenthesis">(</span>mask<span class="org-parenthesis">)</span>
            <span class="org-keyword">return</span> rval

        cls.__optimizer.<span class="org-variable-name">step</span> <span class="org-operator">=</span> types.MethodType<span class="org-parenthesis">(</span>__step<span class="org-parenthesis">,</span> cls.__optimizer<span class="org-parenthesis">)</span>

    @<span class="org-builtin">classmethod</span>
    <span class="org-keyword">def</span> <span class="org-function-name">compute_sparse_masks</span><span class="org-parenthesis">(</span>cls<span class="org-parenthesis">)</span>:
        <span class="org-keyword">with</span> torch.no_grad<span class="org-parenthesis">()</span>:
            <span class="org-keyword">for</span> module_name<span class="org-parenthesis">,</span> module<span class="org-parenthesis">,</span> p_name<span class="org-parenthesis">,</span> p<span class="org-parenthesis">,</span> mask<span class="org-parenthesis">,</span> pruned <span class="org-keyword">in</span> cls.__sparse_parameters:
                <span class="org-keyword">if</span> mask.<span class="org-builtin">sum</span><span class="org-parenthesis">()</span> <span class="org-operator">&lt;</span> mask.numel<span class="org-parenthesis">()</span>:  <span class="org-comment-delimiter"># </span><span class="org-comment">when recalculating masks</span>
                    <span class="org-comment-delimiter"># </span><span class="org-comment">restore dense parameter if allow_recompute_mask is enabled</span>
                    <span class="org-keyword">assert</span> <span class="org-parenthesis">(</span>
                        pruned <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span>
                    <span class="org-parenthesis">),</span> <span class="org-string">"Unable to restore dense parameter because allow_recompute_mask == False"</span>
                    p.add_<span class="org-parenthesis">(</span>pruned.cuda<span class="org-parenthesis">())</span>

                mask.set_<span class="org-parenthesis">(</span>cls.__calculate_mask<span class="org-parenthesis">(</span>p<span class="org-parenthesis">))</span>

                <span class="org-keyword">if</span> pruned <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span>:  <span class="org-comment-delimiter"># </span><span class="org-comment">stow away pruned weights to cpu</span>
                    pruned.set_<span class="org-parenthesis">((</span>p <span class="org-operator">*</span> <span class="org-parenthesis">(</span><span class="org-operator">~</span>mask<span class="org-parenthesis">))</span>.cpu<span class="org-parenthesis">())</span>

                p.mul_<span class="org-parenthesis">(</span>
                    mask
                <span class="org-parenthesis">)</span>  <span class="org-comment-delimiter"># </span><span class="org-comment">in-place multiplication, so pruned weights are 0-values, hence checkpoint will have 0s for pruned weights</span>
                <span class="org-keyword">if</span> cls.__verbosity <span class="org-operator">&gt;=</span> 2:
                    <span class="org-builtin">print</span><span class="org-parenthesis">(</span>
                        <span class="org-string">"[ASP] Enabled %.2f%% sparsity for %s::%s of size=%s and type=%s"</span>
                        <span class="org-operator">%</span> <span class="org-parenthesis">(</span>
                            100.0 <span class="org-operator">*</span> mask.<span class="org-builtin">sum</span><span class="org-parenthesis">()</span> <span class="org-operator">/</span> mask.numel<span class="org-parenthesis">(),</span>
                            module_name<span class="org-parenthesis">,</span>
                            p_name<span class="org-parenthesis">,</span>
                            <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.size<span class="org-parenthesis">()),</span>
                            <span class="org-builtin">str</span><span class="org-parenthesis">(</span>p.dtype<span class="org-parenthesis">),</span>
                        <span class="org-parenthesis">)</span>
                    <span class="org-parenthesis">)</span>

    @<span class="org-builtin">classmethod</span>
    <span class="org-keyword">def</span> <span class="org-function-name">prune_trained_model</span><span class="org-parenthesis">(</span>cls<span class="org-parenthesis">,</span> model<span class="org-parenthesis">,</span> optimizer<span class="org-parenthesis">)</span>:
        <span class="org-comment-delimiter"># </span><span class="org-comment">add mask buffers to model (init_model_for_pruning), augment optimizer (init_optimizer_for_pruning) and compute masks (compute_sparse_masks)</span>
        cls.init_model_for_pruning<span class="org-parenthesis">(</span>
            model<span class="org-parenthesis">,</span>
            mask_calculator<span class="org-operator">=</span><span class="org-string">"m4n2_1d"</span><span class="org-parenthesis">,</span>
            verbosity<span class="org-operator">=</span>2<span class="org-parenthesis">,</span>
            whitelist<span class="org-operator">=</span>[torch.nn.Linear<span class="org-parenthesis">,</span> torch.nn.Conv2d]<span class="org-parenthesis">,</span>
            allow_recompute_mask<span class="org-operator">=</span><span class="org-constant">False</span><span class="org-parenthesis">,</span>
        <span class="org-parenthesis">)</span>
        cls.init_optimizer_for_pruning<span class="org-parenthesis">(</span>optimizer<span class="org-parenthesis">)</span>
        cls.compute_sparse_masks<span class="org-parenthesis">()</span>


<span class="org-comment-delimiter"># </span><span class="org-comment">-------------------- test.py --------------------</span>
<span class="org-keyword">import</span> os
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> torch
<span class="org-keyword">from</span> torch <span class="org-keyword">import</span> nn
<span class="org-keyword">from</span> torch <span class="org-keyword">import</span> optim
<span class="org-keyword">from</span> torch.utils.data <span class="org-keyword">import</span> DataLoader<span class="org-parenthesis">,</span> Dataset
<span class="org-keyword">import</span> torch.nn.functional <span class="org-keyword">as</span> F

<span class="org-variable-name">model</span> <span class="org-operator">=</span> <span class="org-constant">None</span>
<span class="org-variable-name">optimizer</span> <span class="org-operator">=</span> <span class="org-constant">None</span>


<span class="org-keyword">class</span> <span class="org-type">ToyDataset</span><span class="org-parenthesis">(</span>Dataset<span class="org-parenthesis">)</span>:
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">)</span>:
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> torch.<span class="org-builtin">round</span><span class="org-parenthesis">(</span>torch.rand<span class="org-parenthesis">(</span>1000<span class="org-parenthesis">)</span> <span class="org-operator">*</span> 200<span class="org-parenthesis">)</span>
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> x.unsqueeze<span class="org-parenthesis">(</span>1<span class="org-parenthesis">)</span>
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> torch.cat<span class="org-parenthesis">((</span>x<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 2<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 3<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 4<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 5<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 6<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 7<span class="org-parenthesis">,</span> x <span class="org-operator">*</span> 8<span class="org-parenthesis">),</span> 1<span class="org-parenthesis">)</span>
        <span class="org-keyword">self</span>.<span class="org-variable-name">X</span> <span class="org-operator">=</span> x
        <span class="org-keyword">self</span>.<span class="org-variable-name">Y</span> <span class="org-operator">=</span> <span class="org-keyword">self</span>.X

    <span class="org-keyword">def</span> <span class="org-function-name">__getitem__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">,</span> index<span class="org-parenthesis">)</span>:
        <span class="org-keyword">return</span> <span class="org-keyword">self</span>.X[index]<span class="org-parenthesis">,</span> <span class="org-keyword">self</span>.Y[index]

    <span class="org-keyword">def</span> <span class="org-function-name">__len__</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span><span class="org-parenthesis">)</span>:
        <span class="org-keyword">return</span> <span class="org-builtin">len</span><span class="org-parenthesis">(</span><span class="org-keyword">self</span>.X<span class="org-parenthesis">)</span>


<span class="org-variable-name">training_loader</span> <span class="org-operator">=</span> DataLoader<span class="org-parenthesis">(</span>ToyDataset<span class="org-parenthesis">(),</span> batch_size<span class="org-operator">=</span>100<span class="org-parenthesis">,</span> shuffle<span class="org-operator">=</span><span class="org-constant">True</span><span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">train</span><span class="org-parenthesis">()</span>:
    <span class="org-variable-name">criterion</span> <span class="org-operator">=</span> nn.MSELoss<span class="org-parenthesis">()</span>
    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span><span class="org-parenthesis">(</span>500<span class="org-parenthesis">)</span>:
        <span class="org-keyword">for</span> x<span class="org-parenthesis">,</span> y <span class="org-keyword">in</span> training_loader:
            <span class="org-variable-name">loss</span> <span class="org-operator">=</span> criterion<span class="org-parenthesis">(</span>model<span class="org-parenthesis">(</span>x.to<span class="org-parenthesis">(</span><span class="org-string">"cuda"</span><span class="org-parenthesis">)),</span> y.to<span class="org-parenthesis">(</span><span class="org-string">"cuda"</span><span class="org-parenthesis">))</span>
            optimizer.zero_grad<span class="org-parenthesis">()</span>
            loss.backward<span class="org-parenthesis">()</span>
            optimizer.step<span class="org-parenthesis">()</span>
    <span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"epoch #%d: loss: %f"</span> <span class="org-operator">%</span> <span class="org-parenthesis">(</span>i<span class="org-parenthesis">,</span> loss.item<span class="org-parenthesis">()))</span>


<span class="org-keyword">def</span> <span class="org-function-name">test</span><span class="org-parenthesis">()</span>:
    <span class="org-variable-name">x</span> <span class="org-operator">=</span> torch.tensor<span class="org-parenthesis">(</span>[[2<span class="org-parenthesis">,</span> 4<span class="org-parenthesis">,</span> 6<span class="org-parenthesis">,</span> 8<span class="org-parenthesis">,</span> 10<span class="org-parenthesis">,</span> 12<span class="org-parenthesis">,</span> 14<span class="org-parenthesis">,</span> 16]]<span class="org-parenthesis">)</span>.<span class="org-builtin">float</span><span class="org-parenthesis">()</span>
    <span class="org-variable-name">y_hat</span> <span class="org-operator">=</span> model<span class="org-parenthesis">(</span>x.to<span class="org-parenthesis">(</span><span class="org-string">"cuda"</span><span class="org-parenthesis">))</span>
    <span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"orig: "</span><span class="org-parenthesis">,</span> x<span class="org-parenthesis">,</span> <span class="org-string">" new: "</span><span class="org-parenthesis">,</span> y_hat<span class="org-parenthesis">)</span>


<span class="org-keyword">def</span> <span class="org-function-name">get_model</span><span class="org-parenthesis">(</span>f<span class="org-parenthesis">)</span>:
    <span class="org-keyword">global</span> model<span class="org-parenthesis">,</span> optimizer
    <span class="org-keyword">if</span> os.path.exists<span class="org-parenthesis">(</span>f<span class="org-parenthesis">)</span>:
        <span class="org-variable-name">model</span> <span class="org-operator">=</span> torch.load<span class="org-parenthesis">(</span>f<span class="org-parenthesis">)</span>.cuda<span class="org-parenthesis">()</span>
        <span class="org-variable-name">optimizer</span> <span class="org-operator">=</span> optim.Adam<span class="org-parenthesis">(</span>model.parameters<span class="org-parenthesis">(),</span> lr<span class="org-operator">=</span>0.01<span class="org-parenthesis">)</span>
    <span class="org-keyword">else</span>:
        <span class="org-variable-name">model</span> <span class="org-operator">=</span> nn.Sequential<span class="org-parenthesis">(</span>
            nn.Linear<span class="org-parenthesis">(</span>8<span class="org-parenthesis">,</span> 16<span class="org-parenthesis">),</span>
            nn.PReLU<span class="org-parenthesis">(),</span>
            nn.Linear<span class="org-parenthesis">(</span>16<span class="org-parenthesis">,</span> 8<span class="org-parenthesis">),</span>
        <span class="org-parenthesis">)</span>.cuda<span class="org-parenthesis">()</span>
        <span class="org-variable-name">optimizer</span> <span class="org-operator">=</span> optim.Adam<span class="org-parenthesis">(</span>model.parameters<span class="org-parenthesis">(),</span> lr<span class="org-operator">=</span>0.01<span class="org-parenthesis">)</span>
        train<span class="org-parenthesis">()</span>
        torch.save<span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> f<span class="org-parenthesis">)</span>


get_model<span class="org-parenthesis">(</span><span class="org-string">"/tmp/model.pt"</span><span class="org-parenthesis">)</span>
<span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"-------orig---------"</span><span class="org-parenthesis">)</span>
test<span class="org-parenthesis">()</span>

<span class="org-builtin">print</span><span class="org-parenthesis">(</span>model[2].state_dict<span class="org-parenthesis">())</span>
ASP.prune_trained_model<span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> optimizer<span class="org-parenthesis">)</span>
<span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"-------pruned---------"</span><span class="org-parenthesis">)</span>
test<span class="org-parenthesis">()</span>
<span class="org-builtin">print</span><span class="org-parenthesis">(</span>model[2].state_dict<span class="org-parenthesis">())</span>
train<span class="org-parenthesis">()</span>
<span class="org-builtin">print</span><span class="org-parenthesis">(</span><span class="org-string">"-------retrain---------"</span><span class="org-parenthesis">)</span>
test<span class="org-parenthesis">()</span>
<span class="org-builtin">print</span><span class="org-parenthesis">(</span>model[2].state_dict<span class="org-parenthesis">())</span>
torch.save<span class="org-parenthesis">(</span>model<span class="org-parenthesis">,</span> <span class="org-string">"/tmp/model_sparse.pt"</span><span class="org-parenthesis">)</span>
</pre>
</div>

<p>
--&#x2013;&#x2014;orig----&#x2013;&#x2014;
orig:  tensor()  new:  tensor(,
       device='cuda:0', grad_fn=&lt;AddmmBackward&gt;)
OrderedDict([('weight', tensor([[ 0.1899, -0.1074, -0.0064, -0.0016,  0.0893,  0.2194, -0.1457, -0.1500,
          0.0482,  0.0495, -0.1510,  0.0169, -0.0174,  0.0402,  0.1461, -0.1233],
        [-0.0973, -0.2051,  0.0303, -0.0798,  0.1052, -0.1524, -0.0244,  0.1359,
          0.0051,  0.0985, -0.1482,  0.1417, -0.0118,  0.1361,  0.2233, -0.1164],
        [ 0.1049, -0.1537, -0.1860,  0.1423, -0.1657, -0.0253, -0.0455,  0.1699,
          0.2134,  0.0081, -0.2659,  0.1806,  0.0515,  0.2417, -0.0409,  0.3283],
        [ 0.1426,  0.0729,  0.0950,  0.2379, -0.2145,  0.0646, -0.0936,  0.1097,
          0.0842, -0.2154, -0.0906, -0.0958,  0.0363,  0.2453,  0.1978,  0.3038],
        [ 0.2264, -0.0101,  0.3551, -0.3178,  0.2250, -0.0257,  0.0879, -0.3122,
         -0.1913, -0.0425, -0.0036,  0.1085,  0.1470,  0.0149,  0.0971,  0.3013],
        [ 0.3303,  0.0674, -0.1155, -0.1443, -0.0213, -0.0546,  0.0669, -0.2751,
         -0.0199,  0.0575, -0.2252,  0.3843, -0.1892,  0.4178, -0.0364,  0.0071],
        [ 0.3373, -0.0020,  0.2039, -0.0458,  0.2323, -0.3360,  0.0140, -0.1100,
         -0.1204, -0.0694, -0.0018,  0.1073,  0.2118,  0.3473,  0.0345, -0.0222],
        [ 0.0731, -0.3941,  0.1664,  0.0100,  0.1053, -0.4457,  0.2373, -0.0818,
         -0.0015, -0.0019, -0.4326,  0.0886, -0.2492,  0.2418,  0.2013,  0.0996]],
       device='cuda:0')), ('bias', tensor([0.0658, 0.0500, 0.1469, 0.0165, 0.1377, 0.1143, 0.0687, 0.1848],
       device='cuda:0'))])
[ASP] torchvision is imported, can work with the MaskRCNN/KeypointRCNN from torchvision.
[ASP] Auto skipping pruning 0::weight of size=torch.Size([16, 8]) and type=torch.float32 for sparsity
[ASP] Enabled 50.00% sparsity for 2::weight of size=torch.Size([8, 16]) and type=torch.float32
--&#x2013;&#x2014;pruned----&#x2013;&#x2014;
orig:  tensor()  new:  tensor(,
       device='cuda:0', grad_fn=&lt;AddmmBackward&gt;)
OrderedDict([('weight', tensor([[ 0.1899, -0.1074, -0.0000, -0.0000,  0.0000,  0.2194, -0.0000, -0.1500,
          0.0000,  0.0495, -0.1510,  0.0000, -0.0000,  0.0000,  0.1461, -0.1233],
        [-0.0973, -0.2051,  0.0000, -0.0000,  0.0000, -0.1524, -0.0000,  0.1359,
          0.0000,  0.0000, -0.1482,  0.1417, -0.0000,  0.1361,  0.2233, -0.0000],
        [ 0.0000, -0.1537, -0.1860,  0.0000, -0.1657, -0.0000, -0.0000,  0.1699,
          0.2134,  0.0000, -0.2659,  0.0000,  0.0000,  0.2417, -0.0000,  0.3283],
        [ 0.1426,  0.0000,  0.0000,  0.2379, -0.2145,  0.0000, -0.0000,  0.1097,
          0.0000, -0.2154, -0.0000, -0.0958,  0.0000,  0.2453,  0.0000,  0.3038],
        [ 0.0000, -0.0000,  0.3551, -0.3178,  0.2250, -0.0000,  0.0000, -0.3122,
         -0.1913, -0.0000, -0.0000,  0.1085,  0.1470,  0.0000,  0.0000,  0.3013],
        [ 0.3303,  0.0000, -0.0000, -0.1443, -0.0000, -0.0000,  0.0669, -0.2751,
         -0.0000,  0.0000, -0.2252,  0.3843, -0.1892,  0.4178, -0.0000,  0.0000],
        [ 0.3373, -0.0000,  0.2039, -0.0000,  0.2323, -0.3360,  0.0000, -0.0000,
         -0.1204, -0.0000, -0.0000,  0.1073,  0.2118,  0.3473,  0.0000, -0.0000],
        [ 0.0000, -0.3941,  0.1664,  0.0000,  0.0000, -0.4457,  0.2373, -0.0000,
         -0.0000, -0.0000, -0.4326,  0.0886, -0.2492,  0.2418,  0.0000,  0.0000]],
       device='cuda:0')), ('bias', tensor([0.0658, 0.0500, 0.1469, 0.0165, 0.1377, 0.1143, 0.0687, 0.1848],
       device='cuda:0')), ('__weight_mma_mask', tensor([[ True,  True, False, False, False,  True, False,  True, False,  True,
          True, False, False, False,  True,  True],
        [ True,  True, False, False, False,  True, False,  True, False, False,
          True,  True, False,  True,  True, False],
        [False,  True,  True, False,  True, False, False,  True,  True, False,
          True, False, False,  True, False,  True],
        [ True, False, False,  True,  True, False, False,  True, False,  True,
         False,  True, False,  True, False,  True],
        [False, False,  True,  True,  True, False, False,  True,  True, False,
         False,  True,  True, False, False,  True],
        [ True, False, False,  True, False, False,  True,  True, False, False,
          True,  True,  True,  True, False, False],
        [ True, False,  True, False,  True,  True, False, False,  True, False,
         False,  True,  True,  True, False, False],
        [False,  True,  True, False, False,  True,  True, False, False, False,
          True,  True,  True,  True, False, False]], device='cuda:0'))])
epoch #499: loss: 0.610391
--&#x2013;&#x2014;retrain----&#x2013;&#x2014;
orig:  tensor()  new:  tensor(,
       device='cuda:0', grad_fn=&lt;AddmmBackward&gt;)
OrderedDict([('weight', tensor([[ 0.2176, -0.1109, -0.0000, -0.0000,  0.0000,  0.1861, -0.0000, -0.1460,
          0.0000,  0.0276, -0.1884,  0.0000, -0.0000,  0.0000,  0.0870, -0.0764],
        [-0.1423, -0.1618,  0.0000, -0.0000,  0.0000, -0.1394, -0.0000,  0.1436,
          0.0000,  0.0000, -0.1384, -0.0720, -0.0000,  0.1603,  0.1100, -0.0000],
        [ 0.0000, -0.1045, -0.1682,  0.0000, -0.1040, -0.0000, -0.0000,  0.1698,
          0.1514,  0.0000, -0.2424,  0.0000,  0.0000,  0.2411, -0.0000,  0.2935],
        [ 0.1369,  0.0000,  0.0000,  0.2759, -0.1883,  0.0000, -0.0000,  0.1236,
          0.0000, -0.0164, -0.0000, -0.1456,  0.0000,  0.2672,  0.0000,  0.2691],
        [ 0.0000, -0.0000,  0.4154, -0.2569,  0.1915, -0.0000,  0.0000, -0.3162,
         -0.1192, -0.0000, -0.0000,  0.0208, -0.0131,  0.0000,  0.0000,  0.3485],
        [ 0.2522,  0.0000, -0.0000, -0.0961, -0.0000, -0.0000,  0.0340, -0.2356,
         -0.0000,  0.0000, -0.1943,  0.2541, -0.0421,  0.4076, -0.0000,  0.0000],
        [ 0.2798, -0.0000,  0.2241, -0.0000,  0.1726, -0.3089,  0.0000, -0.0000,
         -0.0214, -0.0000, -0.0000, -0.1063,  0.3034,  0.3635,  0.0000, -0.0000],
        [ 0.0000, -0.3632,  0.2074,  0.0000,  0.0000, -0.4494,  0.2390, -0.0000,
         -0.0000, -0.0000, -0.4418, -0.0210, -0.2601,  0.2938,  0.0000,  0.0000]],
       device='cuda:0')), ('bias', tensor([0.0612, 0.0340, 0.1160, 0.0579, 0.1724, 0.1567, 0.1405, 0.1688],
       device='cuda:0')), ('__weight_mma_mask', tensor([[ True,  True, False, False, False,  True, False,  True, False,  True,
          True, False, False, False,  True,  True],
        [ True,  True, False, False, False,  True, False,  True, False, False,
          True,  True, False,  True,  True, False],
        [False,  True,  True, False,  True, False, False,  True,  True, False,
          True, False, False,  True, False,  True],
        [ True, False, False,  True,  True, False, False,  True, False,  True,
         False,  True, False,  True, False,  True],
        [False, False,  True,  True,  True, False, False,  True,  True, False,
         False,  True,  True, False, False,  True],
        [ True, False, False,  True, False, False,  True,  True, False, False,
          True,  True,  True,  True, False, False],
        [ True, False,  True, False,  True,  True, False, False,  True, False,
         False,  True,  True,  True, False, False],
        [False,  True,  True, False, False,  True,  True, False, False, False,
          True,  True,  True,  True, False, False]], device='cuda:0'))])
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway@dogdog.run<br />
Date: 2021-10-26 Tue 00:00<br />
Last updated: 2022-03-07 Mon 14:58</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
</div>
</body>
</html>