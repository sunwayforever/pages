<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>Android NN API</title>

<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Android NN API</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org000000a">1. Android NN API</a>
<ul>
<li><a href="#org0000000">1.1. NN API</a></li>
<li><a href="#org0000003">1.2. example</a></li>
<li><a href="#org0000007">1.3. NN HAL</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org000000a" class="outline-2">
<h2 id="org000000a"><span class="section-number-2">1.</span> Android NN API</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org0000000" class="outline-3">
<h3 id="org0000000"><span class="section-number-3">1.1.</span> NN API</h3>
<div class="outline-text-3" id="text-1-1">
<p>
<a href="https://developer.android.com/ndk/guides/neuralnetworks/">https://developer.android.com/ndk/guides/neuralnetworks/</a>
</p>

<ol class="org-ol">
<li>NN API 面向 tensorflow lite 等机器学习框架</li>
<li>它提供了基本的 tensor 操作, 可以构造计算图并对计算图求值</li>
<li>它只支持 inference, 不支持 training</li>
<li>与底层的 android NN HAL 配合, 支持各种硬件加速</li>
<li>只提供了 c++ API</li>
</ol>
</div>
</div>

<div id="outline-container-org0000003" class="outline-3">
<h3 id="org0000003"><span class="section-number-3">1.2.</span> example</h3>
<div class="outline-text-3" id="text-1-2">
<p>
使用 NN API 计算一个简单的 \(w*x\):
</p>
<div class="org-src-container">
<pre class="src src-c"><span class="org-comment-delimiter">// </span><span class="org-comment">2018-08-06 11:04</span>
<span class="org-preprocessor">#include</span> <span class="org-string">&lt;NeuralNetworks.h&gt;</span>
<span class="org-preprocessor">#include</span> <span class="org-string">&lt;sys/types.h&gt;</span>
<span class="org-preprocessor">#include</span> <span class="org-string">&lt;sys/stat.h&gt;</span>
<span class="org-preprocessor">#include</span> <span class="org-string">&lt;fcntl.h&gt;</span>
<span class="org-preprocessor">#include</span> <span class="org-string">&lt;sys/mman.h&gt;</span>
<span class="org-preprocessor">#include</span> <span class="org-string">&lt;stdio.h&gt;</span>

<span class="org-type">int</span> <span class="org-function-name">main</span>(<span class="org-type">int</span> <span class="org-variable-name">argc</span>, <span class="org-type">char</span> *<span class="org-variable-name">argv</span>[]) {
    <span class="org-type">ANeuralNetworksModel</span>* <span class="org-variable-name">model</span> = <span class="org-constant">NULL</span>;
    ANeuralNetworksModel_create(&amp;model);

    <span class="org-type">ANeuralNetworksOperandType</span> <span class="org-variable-name">tensorW</span>;
    tensorW.type = ANEURALNETWORKS_TENSOR_FLOAT32;
    tensorW.dimensionCount = 0;
    tensorW.dimensions = <span class="org-constant">NULL</span>;

    <span class="org-type">ANeuralNetworksOperandType</span> <span class="org-variable-name">tensorX</span>;
    tensorX.type = ANEURALNETWORKS_TENSOR_FLOAT32;
    tensorX.dimensionCount = 0;
    tensorX.dimensions = <span class="org-constant">NULL</span>;

    <span class="org-type">ANeuralNetworksOperandType</span> <span class="org-variable-name">tensorOut</span>;
    tensorOut.type = ANEURALNETWORKS_TENSOR_FLOAT32;
    tensorOut.dimensionCount = 0;
    tensorOut.dimensions = <span class="org-constant">NULL</span>;

    <span class="org-type">ANeuralNetworksOperandType</span> <span class="org-variable-name">activationType</span>;
    activationType.type = ANEURALNETWORKS_INT32;
    activationType.scale = 0.f;
    activationType.zeroPoint = 0;
    activationType.dimensionCount = 0;
    activationType.dimensions = <span class="org-constant">NULL</span>;

    <span class="org-type">int</span> <span class="org-variable-name">ret</span> = 0;

    ret += ANeuralNetworksModel_addOperand(model, &amp;tensorW);
    ret += ANeuralNetworksModel_addOperand(model, &amp;tensorX);
    ret += ANeuralNetworksModel_addOperand(model, &amp;activationType);
    ret += ANeuralNetworksModel_addOperand(model, &amp;tensorOut);

    <span class="org-comment-delimiter">// </span><span class="org-comment">w=111.</span>
    <span class="org-type">float</span> <span class="org-variable-name">w_value</span> = 111.0;
    ret += ANeuralNetworksModel_setOperandValue(model, 0, &amp;w_value, <span class="org-keyword">sizeof</span>(w_value));

    <span class="org-type">int32_t</span> <span class="org-variable-name">noneValue</span> = ANEURALNETWORKS_FUSED_NONE;
    ret += ANeuralNetworksModel_setOperandValue(model, 2, &amp;noneValue, <span class="org-keyword">sizeof</span>(noneValue));

    <span class="org-type">uint32_t</span> <span class="org-variable-name">addInputIndexes</span>[3]= {0, 1, 2};
    <span class="org-type">uint32_t</span> <span class="org-variable-name">addOutputIndexes</span>[1] = {3};
    ret += ANeuralNetworksModel_addOperation(model, ANEURALNETWORKS_ADD, 3, addInputIndexes, 1, addOutputIndexes);

    <span class="org-type">uint32_t</span> <span class="org-variable-name">modelInputIndexes</span>[1] = {1};
    <span class="org-type">uint32_t</span> <span class="org-variable-name">modelOutputIndexes</span>[1] = {3};
    ret += ANeuralNetworksModel_identifyInputsAndOutputs(model, 1, modelInputIndexes, 1, modelOutputIndexes);
    ret += ANeuralNetworksModel_finish(model);

    <span class="org-comment-delimiter">// </span><span class="org-comment">compilation</span>
    <span class="org-type">ANeuralNetworksCompilation</span>* <span class="org-variable-name">compilation</span>;
    ret += ANeuralNetworksCompilation_create(model, &amp;compilation);

    ANeuralNetworksCompilation_finish(compilation);

    <span class="org-comment-delimiter">// </span><span class="org-comment">run</span>
    <span class="org-type">ANeuralNetworksExecution</span>* <span class="org-variable-name">run</span> = <span class="org-constant">NULL</span>;
    ret += ANeuralNetworksExecution_create(compilation, &amp;run);

    <span class="org-type">float</span> <span class="org-variable-name">myInput</span> = 10;
    ANeuralNetworksExecution_setInput(run, 0, <span class="org-constant">NULL</span>, &amp;myInput, <span class="org-keyword">sizeof</span>(myInput));

    <span class="org-type">float</span> <span class="org-variable-name">myOutput</span> = 0;
    ret += ANeuralNetworksExecution_setOutput(run, 0, <span class="org-constant">NULL</span>, &amp;myOutput, <span class="org-keyword">sizeof</span>(myOutput));

    <span class="org-type">ANeuralNetworksEvent</span>* <span class="org-variable-name">run_end</span> = <span class="org-constant">NULL</span>;
    ret += ANeuralNetworksExecution_startCompute(run, &amp;run_end);

    ret += ANeuralNetworksEvent_wait(run_end);
    printf(<span class="org-string">"%f\n"</span>, myOutput);

    ANeuralNetworksEvent_free(run_end);
    ANeuralNetworksExecution_free(run);
}

</pre>
</div>

<p>
使用如下的 Android.bp 进行编译:
</p>
<div class="org-src-container">
<pre class="src src-makefile">cc_binary {
    <span class="org-makefile-targets">srcs</span>: [<span class="org-string">"nn api_test.cpp"</span>],
    <span class="org-makefile-targets">cflags</span>: [<span class="org-string">"-Wno-error-unused-parameter"</span>],
    <span class="org-makefile-targets">name</span>: <span class="org-string">"nn api_test"</span>,
    <span class="org-keyword"><span class="org-makefile-targets">include</span></span><span class="org-variable-name"><span class="org-makefile-targets">_dirs</span></span>: [<span class="org-string">"frameworks/ml/nn/runtime/include"</span>],
    <span class="org-makefile-targets">shared_libs</span>: [<span class="org-string">"libneuralnetworks"</span>],
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000007" class="outline-3">
<h3 id="org0000007"><span class="section-number-3">1.3.</span> NN HAL</h3>
<div class="outline-text-3" id="text-1-3">
<p>
HAL 定义在 `hardware/interfaces/neuralnetworks`
HAL 有一个 sample 实现在 `frameworks/ml/nn/driver/sample`
</p>

<ol class="org-ol">
<li><p>
IDevice
</p>

<p>
IDevice 主要用来实现设备的查询, 例如
</p>

<ul class="org-ul">
<li><p>
getCapabilities
</p>

<p>
getCapabilities 会返回设备支持哪类运算以及相应的性能, 例如:
</p>

<div class="org-src-container">
<pre class="src src-c">Return&lt;<span class="org-type">void</span>&gt; SampleDriverMinimal::getCapabilities(<span class="org-type">getCapabilities_cb</span> <span class="org-variable-name">cb</span>) {
  <span class="org-type">Capabilities</span> <span class="org-variable-name">capabilities</span> = {.float32Performance = {.execTime = 0.4f, .powerUsage = 0.5f},
                               .quantized8Performance = {.execTime = 1.0f, .powerUsage = 1.0f}};
  cb(ErrorStatus::NONE, capabilities);
  <span class="org-keyword">return</span> Void();
}
</pre>
</div>

<p>
表示该设备支持 float32 和 int8 量化, 以及相应的性能和功耗. 上层 NN runtime
会根据这些信息决定是否使用该设备
</p></li>

<li><p>
getSupportedOperations
</p>

<p>
NN API 一共定义了 29 种 operation, 定义在 `NeuralNetworks.h`, 具体包括:
</p>

<pre class="example" id="org0000006">
ANEURALNETWORKS_ADD = 0
ANEURALNETWORKS_AVERAGE_POOL_2D = 1
ANEURALNETWORKS_CONCATENATION = 2
ANEURALNETWORKS_CONV_2D = 3
ANEURALNETWORKS_DEPTHWISE_CONV_2D = 4
ANEURALNETWORKS_DEPTH_TO_SPACE = 5
ANEURALNETWORKS_DEQUANTIZE = 6
ANEURALNETWORKS_EMBEDDING_LOOKUP = 7
ANEURALNETWORKS_FLOOR = 8
ANEURALNETWORKS_FULLY_CONNECTED = 9
ANEURALNETWORKS_HASHTABLE_LOOKUP = 10
ANEURALNETWORKS_L2_NORMALIZATION = 11
ANEURALNETWORKS_L2_POOL_2D = 12
ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION = 13
ANEURALNETWORKS_LOGISTIC = 14
ANEURALNETWORKS_LSH_PROJECTION = 15
ANEURALNETWORKS_LSTM = 16
ANEURALNETWORKS_MAX_POOL_2D = 17
ANEURALNETWORKS_MUL = 18
ANEURALNETWORKS_RELU = 19
ANEURALNETWORKS_RELU1 = 20
ANEURALNETWORKS_RELU6 = 21
ANEURALNETWORKS_RESHAPE = 22
ANEURALNETWORKS_RESIZE_BILINEAR = 23
ANEURALNETWORKS_RNN = 24
ANEURALNETWORKS_SOFTMAX = 25
ANEURALNETWORKS_SPACE_TO_DEPTH = 26
ANEURALNETWORKS_SVDF = 27
ANEURALNETWORKS_TANH = 28
</pre></li>
</ul></li>

<li><p>
IPreparedModel
</p>

<p>
IPreparedModel 主要定义了 `execute` 方向, 以便 runtime 能够把 operation 委派给 device 去执行
</p></li>
</ol>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2018-08-04 Sat 00:00<br />
Last updated: 2022-07-17 Sun 11:39</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
