<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-01-14 五 12:04 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>DMS Program</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Wei Sun (孙伟)" />
<link rel="stylesheet" type="text/css" href="../stylesheets/main.css" media="screen" />
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<h1 class="title">DMS Program</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org15ef3f5">1. DMS Program</a>
<ul>
<li><a href="#org0d676a7">1.1. INU</a>
<ul>
<li><a href="#orgdecb15b">1.1.1. Host SDK</a></li>
<li><a href="#org05eaa36">1.1.2. Firmware SDK (FDK)</a></li>
</ul>
</li>
<li><a href="#org093aa68">1.2. 算法</a>
<ul>
<li><a href="#org0442922">1.2.1. face detection (mediapipe)</a></li>
<li><a href="#orgdd3d53c">1.2.2. face landmark (mediapipe)</a></li>
<li><a href="#org65d8218">1.2.3. iris detection (mediapipe)</a></li>
<li><a href="#org7c6b0d2">1.2.4. <span class="priority">[B]</span> palm detection &amp; gesture detection (mediapipe)</a></li>
<li><a href="#org1e77a0d">1.2.5. <span class="priority">[B]</span> face recognition</a></li>
<li><a href="#org852c512">1.2.6. <span class="priority">[C]</span> 自己实现和训练上述所有模型</a></li>
<li><a href="#orgc01b26d">1.2.7. <span class="priority">[A]</span> 在终端设备上运行上述所有模型的 inference</a></li>
</ul>
</li>
<li><a href="#org0c9c870">1.3. 应用</a>
<ul>
<li><a href="#org3c071e1">1.3.1. <span class="priority">[A]</span> 算法 SDK</a></li>
<li><a href="#orga533679">1.3.2. <span class="priority">[B]</span> 疲劳检测 (drowsiness detection)</a></li>
<li><a href="#orgf36bc7f">1.3.3. <span class="priority">[B]</span> 分心检测 与 gaze region detection</a></li>
<li><a href="#orgabb3ff0">1.3.4. <span class="priority">[B]</span> 驾驶员识别</a></li>
<li><a href="#org094b44f">1.3.5. <span class="priority">[B]</span> 驾驶员手势</a></li>
<li><a href="#org603c216">1.3.6. <span class="priority">[A]</span> animoji demo (face motion capture)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org15ef3f5" class="outline-2">
<h2 id="org15ef3f5"><span class="section-number-2">1</span> DMS Program</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org0d676a7" class="outline-3">
<h3 id="org0d676a7"><span class="section-number-3">1.1</span> INU</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-orgdecb15b" class="outline-4">
<h4 id="orgdecb15b"><span class="section-number-4">1.1.1</span> Host SDK</h4>
<div class="outline-text-4" id="text-1-1-1">
</div>
<div id="outline-container-org0171722" class="outline-5">
<h5 id="org0171722"><span class="section-number-5">1.1.1.1</span> webcam stream</h5>
<div class="outline-text-5" id="text-1-1-1-1">
<p>
现在已经试过了可以通过 webcam stream 把 INU 当作一个普通摄像头使用.
用 c++ 写的 face detection demo 可以正常工作
</p>
</div>
</div>

<div id="outline-container-org515f44d" class="outline-5">
<h5 id="org515f44d"><span class="section-number-5">1.1.1.2</span> <span class="priority">[A]</span> depth stream</h5>
<div class="outline-text-5" id="text-1-1-1-2">
<p>
拿到 depth 数据 <a href="#org603c216">animoji demo (face motion capture)</a>
</p>
</div>
</div>

<div id="outline-container-org71a833f" class="outline-5">
<h5 id="org71a833f"><span class="section-number-5">1.1.1.3</span> NN stream</h5>
<div class="outline-text-5" id="text-1-1-1-3">
<p>
如果需要在 INU 上跑 NN, 则需要使用 NN stream
</p>
</div>

<ol class="org-ol">
<li><a id="org6cab8f1"></a><span class="priority">[C]</span> 转换模型<br />
<div class="outline-text-6" id="text-1-1-1-3-1">
<p>
tflite 模型需要 INU 转换成它自己的格式才能使用. INU 已经转换过一个, 可以看到转换工具不怎么健壮, 容易出错, 转换后的正确性也需要验证
</p>
</div>
</li>

<li><a id="orgdf32b45"></a><span class="priority">[C]</span> 使用 NN stream<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org05eaa36" class="outline-4">
<h4 id="org05eaa36"><span class="section-number-4">1.1.2</span> Firmware SDK (FDK)</h4>
<div class="outline-text-4" id="text-1-1-2">
</div>
<div id="outline-container-orge356db7" class="outline-5">
<h5 id="orge356db7"><span class="section-number-5">1.1.2.1</span> <span class="priority">[C]</span> graph</h5>
<div class="outline-text-5" id="text-1-1-2-1">
<p>
有时需要多个 NN 模型在 INU 上配合执行, 例如
</p>

<ol class="org-ol">
<li>face detection 模型执行后获得人脸 ROI</li>
<li>face landmark 模型根据人脸 ROI 获得 landmark 信息, 同时获得 iris ROI</li>
<li>iris detection 根据 iris ROI 获得 iris landmark 信息</li>
</ol>

<p>
上面三个模型一起工作时, 需要通过 INU graph 描述成一个 graph, 或 pipeline, 各个模型前后需要的数据处理需要通过 FDK 在 INU 内部完成 (而不是在 host 完成)
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org093aa68" class="outline-3">
<h3 id="org093aa68"><span class="section-number-3">1.2</span> 算法</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org0442922" class="outline-4">
<h4 id="org0442922"><span class="section-number-4">1.2.1</span> face detection (mediapipe)</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
检测人脸
</p>
</div>
</div>

<div id="outline-container-orgdd3d53c" class="outline-4">
<h4 id="orgdd3d53c"><span class="section-number-4">1.2.2</span> face landmark (mediapipe)</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
检测人脸上的关键点, 可以用来
</p>

<ol class="org-ol">
<li>获得人脸的姿态 (head pose detection)</li>
<li>嘴的开闭</li>
<li>配合 depth 信息, 对人脸进行 3d 建模 <a href="#org603c216">animoji demo (face motion capture)</a></li>
</ol>
</div>

<div id="outline-container-org397e269" class="outline-5">
<h5 id="org397e269"><span class="section-number-5">1.2.2.1</span> <span class="priority">[A]</span> head pose detection</h5>
<div class="outline-text-5" id="text-1-2-2-1">
<p>
现在 head pose detection 不太准确
</p>
</div>
</div>
</div>

<div id="outline-container-org65d8218" class="outline-4">
<h4 id="org65d8218"><span class="section-number-4">1.2.3</span> iris detection (mediapipe)</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
检测眼部的 landmark, 可以用来
</p>

<ol class="org-ol">
<li>检测是否闭眼</li>
<li>检测眼球的方向 (gaze detection)</li>
</ol>
</div>

<div id="outline-container-org1f54945" class="outline-5">
<h5 id="org1f54945"><span class="section-number-5">1.2.3.1</span> <span class="priority">[A]</span> gaze detection</h5>
</div>
</div>

<div id="outline-container-org7c6b0d2" class="outline-4">
<h4 id="org7c6b0d2"><span class="section-number-4">1.2.4</span> <span class="priority">[B]</span> palm detection &amp; gesture detection (mediapipe)</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
检测手掌和手势
</p>
</div>
</div>

<div id="outline-container-org1e77a0d" class="outline-4">
<h4 id="org1e77a0d"><span class="section-number-4">1.2.5</span> <span class="priority">[B]</span> face recognition</h4>
<div class="outline-text-4" id="text-1-2-5">
<p>
识别不同的人, face embedding 可以很好的支持这个功能 <a href="#orgabb3ff0">驾驶员识别</a>
</p>
</div>
</div>

<div id="outline-container-org852c512" class="outline-4">
<h4 id="org852c512"><span class="section-number-4">1.2.6</span> <span class="priority">[C]</span> 自己实现和训练上述所有模型</h4>
<div class="outline-text-4" id="text-1-2-6">
<p>
上述算法有些使用的是 google 开放的 mediapipe 里提供的 tflite 模型, 我们需要自己去实现和训练这些模型, 避免被 mediapipe 无法解决的问题 block
</p>
</div>
</div>

<div id="outline-container-orgc01b26d" class="outline-4">
<h4 id="orgc01b26d"><span class="section-number-4">1.2.7</span> <span class="priority">[A]</span> 在终端设备上运行上述所有模型的 inference</h4>
<div class="outline-text-4" id="text-1-2-7">
<p>
inference 时最终我们需要跑在 710 或 INU 这样的设备上, 所以需要把上面所有的模型用
c++ 重写
</p>
</div>
</div>
</div>

<div id="outline-container-org0c9c870" class="outline-3">
<h3 id="org0c9c870"><span class="section-number-3">1.3</span> 应用</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org3c071e1" class="outline-4">
<h4 id="org3c071e1"><span class="section-number-4">1.3.1</span> <span class="priority">[A]</span> 算法 SDK</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
上面的算法需要提供统一的服务, 方便应用使用. 主要的问题是需要屏蔽各种硬件/软件的差异:
</p>

<p>
硬件方面: CPU, GPU, NN 加速器. 软件方面: python, c++, linux 等
</p>

<p>
目前的 target 是: linux, c++, tflite on CPU, 后续会把 tflite on CPU 换成 710 或
INU 的 NN 加速器
</p>
</div>
</div>


<div id="outline-container-orga533679" class="outline-4">
<h4 id="orga533679"><span class="section-number-4">1.3.2</span> <span class="priority">[B]</span> 疲劳检测 (drowsiness detection)</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
face landrmark, head pose detection, iris landmark 等可以检测眨眼, 哈欠, 点头等
</p>
</div>
</div>

<div id="outline-container-orgf36bc7f" class="outline-4">
<h4 id="orgf36bc7f"><span class="section-number-4">1.3.3</span> <span class="priority">[B]</span> 分心检测 与 gaze region detection</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
基于 head pose detection 和 gaze detection
</p>
</div>
</div>

<div id="outline-container-orgabb3ff0" class="outline-4">
<h4 id="orgabb3ff0"><span class="section-number-4">1.3.4</span> <span class="priority">[B]</span> 驾驶员识别</h4>
<div class="outline-text-4" id="text-1-3-4">
<p>
基于 face recognition, 驾驶员需要进行一次 enroll 动作, 后续就可以识别这个人了.
</p>
</div>
</div>

<div id="outline-container-org094b44f" class="outline-4">
<h4 id="org094b44f"><span class="section-number-4">1.3.5</span> <span class="priority">[B]</span> 驾驶员手势</h4>
<div class="outline-text-4" id="text-1-3-5">
<p>
基于 gesture detection
</p>
</div>
</div>

<div id="outline-container-org603c216" class="outline-4">
<h4 id="org603c216"><span class="section-number-4">1.3.6</span> <span class="priority">[A]</span> animoji demo (face motion capture)</h4>
<div class="outline-text-4" id="text-1-3-6">
<p>
综合 face landmark, head pose, gaze 和 depth 信息, 通过 blender 对人脸进行 3d 建模
</p>
</div>

<div id="outline-container-org1d8cfa6" class="outline-5">
<h5 id="org1d8cfa6"><span class="section-number-5">1.3.6.1</span> <span class="priority">[A]</span> INU python 封装</h5>
<div class="outline-text-5" id="text-1-3-6-1">
<p>
blender 只支持 python 做为脚本语言, 所以需要把 INU 的 Host SDK 中与 webcam
stream, depth stream 相关的接口用 python 封装一遍.
</p>

<p>
如果用 realsense 可以省掉这部分工作量, 因为 realsense 本身提供了 python binding
</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
