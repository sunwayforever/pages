<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>TVM User Pass</title>


           <link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
           <link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
           <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
           <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
           <script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
           <script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
           <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
           <link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
           <link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
           <link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
           <link rel = "icon" href = "/icon.png"  type = "image/x-icon">
</head>
<body>
<div id="content" class="content">
<h1 class="title">TVM User Pass</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0000000">1. TVM User Pass</a></li>
</ul>
</div>
</div>

<div id="outline-container-org0000000" class="outline-2">
<h2 id="org0000000"><span class="section-number-2">1.</span> TVM User Pass</h2>
<div class="outline-text-2" id="text-1">
<p>
下面实现的 `Broadcast` transform 是为了解决 dnnl 无法处理 broadcast 的问题, 做法是针对某些操作 (如 add), 把它的 lhs 和 rhs 按需加上 broadcast_to 操作
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-09-24 10:32</span>
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay
<span class="org-keyword">from</span> tvm.contrib <span class="org-keyword">import</span> graph_executor
<span class="org-keyword">from</span> tvm.topi.utils <span class="org-keyword">import</span> get_const_tuple


<span class="org-type">@relay.transform.function_pass</span>(opt_level=1)
<span class="org-keyword">class</span> <span class="org-type">Broadcast</span>:
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>, *args):
        <span class="org-keyword">self</span>.<span class="org-variable-name">supported_ops</span> = args

    <span class="org-keyword">def</span> <span class="org-function-name">transform_function</span>(<span class="org-keyword">self</span>, func, mod, ctx):
        <span class="org-variable-name">obj</span> = <span class="org-keyword">self</span>

        <span class="org-keyword">class</span> <span class="org-type">BroadcastTo</span>(tvm.relay.ExprMutator):
            <span class="org-keyword">def</span> <span class="org-function-name">infer_type</span>(<span class="org-keyword">self</span>, node):
                <span class="org-variable-name">mod</span> = tvm.IRModule.from_expr(node)
                <span class="org-variable-name">mod</span> = relay.transform.InferType()(mod)
                <span class="org-variable-name">entry</span> = mod[<span class="org-string">"main"</span>]
                <span class="org-keyword">return</span> entry <span class="org-keyword">if</span> <span class="org-builtin">isinstance</span>(node, relay.Function) <span class="org-keyword">else</span> entry.body

            <span class="org-keyword">def</span> <span class="org-function-name">visit_call</span>(<span class="org-keyword">self</span>, call):
                <span class="org-keyword">if</span> call.op.name <span class="org-keyword">not</span> <span class="org-keyword">in</span> obj.supported_ops:
                    <span class="org-keyword">return</span> <span class="org-builtin">super</span>().visit_call(call)

                <span class="org-keyword">if</span> <span class="org-builtin">len</span>(call.args) != 2:
                    <span class="org-keyword">raise</span> <span class="org-type">TypeError</span>(
                        f<span class="org-string">"only 2 args is supported, </span>{call.op.name}<span class="org-string"> have </span>{<span class="org-builtin">len</span>(call.args)}<span class="org-string"> args"</span>
                    )
                <span class="org-variable-name">lhs</span> = <span class="org-keyword">self</span>.visit(call.args[0])
                <span class="org-variable-name">rhs</span> = <span class="org-keyword">self</span>.visit(call.args[1])
                <span class="org-variable-name">lhs_shape</span> = get_const_tuple(<span class="org-keyword">self</span>.infer_type(lhs).checked_type.shape)
                <span class="org-variable-name">rhs_shape</span> = get_const_tuple(<span class="org-keyword">self</span>.infer_type(rhs).checked_type.shape)

                <span class="org-variable-name">dtype</span> = <span class="org-keyword">self</span>.infer_type(lhs).checked_type.dtype
                <span class="org-variable-name">out_shape</span> = np.broadcast(np.empty(lhs_shape), np.empty(rhs_shape)).shape

                <span class="org-keyword">if</span> out_shape != lhs_shape:
                    <span class="org-variable-name">lhs</span> = relay.op.broadcast_to(lhs, out_shape)
                <span class="org-keyword">if</span> out_shape != rhs_shape:
                    <span class="org-variable-name">rhs</span> = relay.op.broadcast_to(rhs, out_shape)

                <span class="org-keyword">return</span> relay.expr.Call(
                    call.op, (lhs, rhs), call.attrs, call.type_args, call.span
                )

        <span class="org-keyword">return</span> BroadcastTo().visit(func)


<span class="org-variable-name">shape_a</span>, <span class="org-variable-name">shape_b</span>, <span class="org-variable-name">shape_c</span> = (1, 10), (1,), (1, 10)
<span class="org-variable-name">a</span> = relay.var(<span class="org-string">"a"</span>, shape=shape_a, dtype=<span class="org-string">"float32"</span>)
<span class="org-variable-name">b</span> = relay.var(<span class="org-string">"b"</span>, shape=shape_b, dtype=<span class="org-string">"float32"</span>)
<span class="org-variable-name">c</span> = relay.var(<span class="org-string">"c"</span>, shape=shape_c, dtype=<span class="org-string">"float32"</span>)
<span class="org-variable-name">out</span> = relay.add(a, b)
<span class="org-variable-name">out</span> = relay.add(out, c)

<span class="org-variable-name">func</span> = relay.Function([a, b, c], out)
<span class="org-variable-name">mod</span> = tvm.IRModule.from_expr(func)

<span class="org-builtin">print</span>(<span class="org-string">"----------before----------"</span>)
<span class="org-builtin">print</span>(mod)

<span class="org-builtin">print</span>(<span class="org-string">"----------after----------"</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">tvm &#30340; dnnl &#30340; add &#25805;&#20316;&#19981;&#25903;&#25345;&#33258;&#21160; broadcast, &#25152;&#20197;&#27809;&#26377;&#19979;&#38754;&#19968;&#21477;&#20250;&#25253;&#38169;</span>
<span class="org-variable-name">mod</span> = Broadcast(<span class="org-string">"add"</span>)(mod)
<span class="org-variable-name">mod</span> = relay.transform.AnnotateTarget(<span class="org-string">"dnnl"</span>)(mod)
<span class="org-variable-name">mod</span> = relay.transform.PartitionGraph()(mod)
<span class="org-builtin">print</span>(mod)

<span class="org-keyword">with</span> tvm.transform.PassContext(opt_level=0):
    <span class="org-variable-name">lib</span> = relay.build(mod, target=<span class="org-string">"llvm"</span>, params=<span class="org-constant">None</span>)

<span class="org-variable-name">rt_mod</span> = graph_executor.GraphModule(lib[<span class="org-string">"default"</span>](tvm.cpu(0)))
<span class="org-variable-name">x</span>, <span class="org-variable-name">y</span>, <span class="org-variable-name">z</span> = np.ones(shape_a), np.ones(shape_b), np.ones(shape_c)
rt_mod.set_input(<span class="org-string">"a"</span>, x)
rt_mod.set_input(<span class="org-string">"b"</span>, y)
rt_mod.set_input(<span class="org-string">"c"</span>, z)
rt_mod.run()
<span class="org-variable-name">result</span> = rt_mod.get_output(0).numpy()
<span class="org-builtin">print</span>(result)
</pre>
</div>

<p>
-----&#x2013;&#x2014;before-----&#x2013;&#x2014;
def @main(%a: Tensor[(1, 10), float32], %b: Tensor[(1), float32], %c: Tensor[(1, 10), float32]) {
  %0 = add(%a, %b);
  add(%0, %c)
}
</p>

<p>
-----&#x2013;&#x2014;after-----&#x2013;&#x2014;
def @main(%a: Tensor[(1, 10), float32], %b: Tensor[(1), float32], %c: Tensor[(1, 10), float32]) -&gt; Tensor[(1, 10), float32] {
  %0 = broadcast_to(%b, shape=[1, 10], dtype="") <i>* ty=Tensor[(1, 10), float32] *</i>;
  %1 = @tvmgen_default_dnnl_main_0(%a, %0) <i>* ty=Tensor[(1, 10), float32] *</i>;
  @tvmgen_default_dnnl_main_2(%1, %c) <i>* ty=Tensor[(1, 10), float32] *</i>
}
</p>

<p>
def @tvmgen_default_dnnl_main_0(%dnnl_0_i0: Tensor[(1, 10), float32], %dnnl_0_i1: Tensor[(1, 10), float32], Inline=1, Compiler="dnnl", global_symbol="tvmgen_default_dnnl_main_0", Primitive=1) -&gt; Tensor[(1, 10), float32] {
  add(%dnnl_0_i0, %dnnl_0_i1) <i>* ty=Tensor[(1, 10), float32] *</i>
}
</p>

<p>
def @tvmgen_default_dnnl_main_2(%dnnl_2_i0: Tensor[(1, 10), float32], %dnnl_2_i1: Tensor[(1, 10), float32], Inline=1, Compiler="dnnl", global_symbol="tvmgen_default_dnnl_main_2", Primitive=1) -&gt; Tensor[(1, 10), float32] {
  add(%dnnl_2_i0, %dnnl_2_i1) <i>* ty=Tensor[(1, 10), float32] *</i>
}
</p>

<p>

</p>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway@dogdog.run<br />
Date: 2021-09-26 Sun 00:00<br />
Last updated: 2022-07-17 Sun 11:39</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
</div>
</body>
</html>
