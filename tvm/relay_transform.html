<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>Relay Transform</title>


           <link rel="stylesheet" type="text/css" href="/htmlize.css"/>
           <link rel="stylesheet" type="text/css" href="./htmlize.css"/>
           <link rel="stylesheet" type="text/css" href="../htmlize.css"/>
           <link rel="stylesheet" type="text/css" href="/readtheorg.css"/>
           <link rel="stylesheet" type="text/css" href="./readtheorg.css"/>
           <link rel="stylesheet" type="text/css" href="../readtheorg.css"/>
           <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
           <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
           <script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
           <script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
           <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
           <link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
           <link rel="stylesheet" type="text/css" href="../main.css" media="screen" />
           <link rel="stylesheet" type="text/css" href="./main.css" media="screen" />
           <link rel = "icon" href = "/icon.png"  type = "image/x-icon">
</head>
<body>
<div id="content" class="content">
<h1 class="title">Relay Transform</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0000036">1. Relay Transform</a>
<ul>
<li><a href="#org0000000">1.1. relay::qnn::transform::Legalize</a></li>
<li><a href="#org0000003">1.2. RemoveUnusedFunctions</a></li>
<li><a href="#org0000006">1.3. SimplifyInference</a></li>
<li><a href="#org0000009">1.4. Inline</a></li>
<li><a href="#org000000f">1.5. RunDeviceAnnotationPass</a>
<ul>
<li><a href="#org000000c">1.5.1. device_copy</a></li>
</ul>
</li>
<li><a href="#org000001e">1.6. FuseOps</a>
<ul>
<li><a href="#org0000018">1.6.1. Example</a></li>
<li><a href="#org000001b">1.6.2. 为什么需要 FuseOps</a></li>
</ul>
</li>
<li><a href="#org0000027">1.7. FoldScaleAxis</a>
<ul>
<li><a href="#org0000021">1.7.1. Example</a></li>
<li><a href="#org0000024">1.7.2. Impl</a></li>
</ul>
</li>
<li><a href="#org000002d">1.8. CombineParallelDense</a>
<ul>
<li><a href="#org000002a">1.8.1. Example</a></li>
</ul>
</li>
<li><a href="#org0000033">1.9. CombineParallelConv2D</a>
<ul>
<li><a href="#org0000030">1.9.1. Example</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000036" class="outline-2">
<h2 id="org0000036"><span class="section-number-2">1.</span> Relay Transform</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="file:///home/sunway/source/tvm/tests/python/relay">file:~/source/tvm/tests/python/relay</a>
</p>
</div>

<div id="outline-container-org0000000" class="outline-3">
<h3 id="org0000000"><span class="section-number-3">1.1.</span> relay::qnn::transform::Legalize</h3>
<div class="outline-text-3" id="text-1-1">
<p>
这个 transform 用来把 qnn.xxx 转换成 relay IR <a href="tvm_quantization.html#org0000000">relay.qnn</a>
</p>
</div>
</div>

<div id="outline-container-org0000003" class="outline-3">
<h3 id="org0000003"><span class="section-number-3">1.2.</span> RemoveUnusedFunctions</h3>
<div class="outline-text-3" id="text-1-2">
<p>
从 entry_functions 开始, 递归的标记所有 GlobalVarNode (函数引用), 然后删除没有标记到的函数
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-08-03 11:11</span>
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay

<span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.IRModule()

<span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(1, 1000))
<span class="org-variable-name">mod</span>[<span class="org-string">"fn1"</span>] <span class="org-operator">=</span> relay.Function([x], x)

<span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"y"</span>, shape<span class="org-operator">=</span>(1, 1000))
<span class="org-variable-name">mod</span>[<span class="org-string">"fn2"</span>] <span class="org-operator">=</span> relay.Function([y], y)

<span class="org-variable-name">z</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"z"</span>, shape<span class="org-operator">=</span>(1, 1000))
<span class="org-variable-name">mod</span>[<span class="org-string">"main"</span>] <span class="org-operator">=</span> relay.Function([z], relay.add(z, relay.GlobalVar(<span class="org-string">"fn1"</span>)(z)))

<span class="org-builtin">print</span>(<span class="org-string">"----------before----------"</span>)
<span class="org-builtin">print</span>(mod.get_global_vars())
<span class="org-builtin">print</span>(mod)

<span class="org-builtin">print</span>(<span class="org-string">"----------after----------"</span>)
<span class="org-variable-name">mod</span> <span class="org-operator">=</span> relay.transform.RemoveUnusedFunctions()(mod)
<span class="org-builtin">print</span>(mod)
</pre>
</div>

<p>
-----&#x2013;&#x2014;before-----&#x2013;&#x2014;
[GlobalVar(fn1), GlobalVar(fn2), GlobalVar(main)]
def @fn1(%x: Tensor[(1, 1000), float32]) {
  %x
}
</p>

<p>
def @fn2(%y: Tensor[(1, 1000), float32]) {
  %y
}
</p>

<p>
def @main(%z: Tensor[(1, 1000), float32]) {
  %0 = @fn1(%z);
  add(%z, %0)
}
</p>

<p>
-----&#x2013;&#x2014;after-----&#x2013;&#x2014;
def @fn1(%x: Tensor[(1, 1000), float32]) {
  %x
}
</p>

<p>
def @main(%z: Tensor[(1, 1000), float32]) {
  %0 = @fn1(%z);
  add(%z, %0)
}
</p>
</div>
</div>

<div id="outline-container-org0000006" class="outline-3">
<h3 id="org0000006"><span class="section-number-3">1.3.</span> SimplifyInference</h3>
<div class="outline-text-3" id="text-1-3">
<ol class="org-ol">
<li>把 batchnorm 转换为 multiply/add</li>
<li>去掉 dropout</li>
</ol>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-08-03 11:11</span>
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay

<span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.IRModule()

<span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(1, 10))
<span class="org-variable-name">alpha</span>, <span class="org-variable-name">gamma</span>, <span class="org-variable-name">mean</span>, <span class="org-variable-name">var</span> <span class="org-operator">=</span> (
    relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(10,)),
    relay.var(<span class="org-string">"y"</span>, shape<span class="org-operator">=</span>(10,)),
    relay.var(<span class="org-string">"a"</span>, shape<span class="org-operator">=</span>(10,)),
    relay.var(<span class="org-string">"b"</span>, shape<span class="org-operator">=</span>(10,)),
)

<span class="org-comment-delimiter"># </span><span class="org-comment">fmt:off</span>
<span class="org-variable-name">bn</span>,<span class="org-variable-name">_</span>,<span class="org-variable-name">_</span>, <span class="org-operator">=</span> relay.nn.batch_norm(x, alpha, gamma, mean, var)
<span class="org-comment-delimiter"># </span><span class="org-comment">fmt:on</span>

<span class="org-variable-name">mod</span>[<span class="org-string">"main"</span>] <span class="org-operator">=</span> relay.Function(
    [x, alpha, gamma, mean, var],
    relay.nn.dropout(bn),
)

<span class="org-builtin">print</span>(<span class="org-string">"----------before----------"</span>)
<span class="org-builtin">print</span>(mod)

<span class="org-builtin">print</span>(<span class="org-string">"----------after----------"</span>)
<span class="org-variable-name">mod</span> <span class="org-operator">=</span> relay.transform.InferType()(mod)
<span class="org-variable-name">mod</span> <span class="org-operator">=</span> relay.transform.SimplifyInference()(mod)
<span class="org-builtin">print</span>(mod)
</pre>
</div>

<p>
-----&#x2013;&#x2014;before-----&#x2013;&#x2014;
def @main(%x: Tensor[(1, 10), float32], %x1: Tensor[(10), float32], %y: Tensor[(10), float32], %a: Tensor[(10), float32], %b: Tensor[(10), float32]) {
  %0 = nn.batch_norm(%x, %x1, %y, %a, %b);
  %1 = %0.0;
  %2 = nn.dropout(%1);
  %2.0
}
</p>

<p>
-----&#x2013;&#x2014;after-----&#x2013;&#x2014;
def @main(%x: Tensor[(1, 10), float32], %x1: Tensor[(10), float32], %y: Tensor[(10), float32], %a: Tensor[(10), float32], %b: Tensor[(10), float32]) -&gt; Tensor[(1, 10), float32] {
  %0 = add(%b, 1e-05f <i>* ty=float32 *</i>) <i>* ty=Tensor[(10), float32] *</i>;
  %1 = sqrt(%0) <i>* ty=Tensor[(10), float32] *</i>;
  %2 = divide(1f <i>* ty=float32 *</i>, %1) <i>* ty=Tensor[(10), float32] *</i>;
  %3 = multiply(%2, %x1) <i>* ty=Tensor[(10), float32] *</i>;
  %4 = negative(%a) <i>* ty=Tensor[(10), float32] *</i>;
  %5 = multiply(%4, %3) <i>* ty=Tensor[(10), float32] *</i>;
  %6 = multiply(%x, %3) <i>* ty=Tensor[(1, 10), float32] *</i>;
  %7 = add(%5, %y) <i>* ty=Tensor[(10), float32] *</i>;
  add(%6, %7) <i>* ty=Tensor[(1, 10), float32] *</i>
}
</p>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-keyword">if</span> (<span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">call</span> = new_n-&gt;tuple.as&lt;CallNode&gt;()) {
    <span class="org-keyword">if</span> (call-&gt;op == batch_norm_op_) {
        <span class="org-keyword">return</span> BatchNormToInferUnpack(
            call-&gt;attrs, call-&gt;args[0], call-&gt;args[1], call-&gt;args[2],
            call-&gt;args[3], call-&gt;args[4], ty_map_.at(call-&gt;args[0]));
    } <span class="org-keyword">else</span> <span class="org-keyword">if</span> (call-&gt;op == dropout_op_) {
        <span class="org-keyword">return</span> call-&gt;args[0];
    }
}

<span class="org-type">Expr</span> <span class="org-function-name">BatchNormToInferUnpack</span>(
    <span class="org-keyword">const</span> <span class="org-type">Attrs</span> <span class="org-variable-name">attrs</span>, <span class="org-type">Expr</span> <span class="org-variable-name">data</span>, <span class="org-type">Expr</span> <span class="org-variable-name">gamma</span>, <span class="org-type">Expr</span> <span class="org-variable-name">beta</span>, <span class="org-type">Expr</span> <span class="org-variable-name">moving_mean</span>,
    <span class="org-type">Expr</span> <span class="org-variable-name">moving_var</span>, <span class="org-type">Type</span> <span class="org-variable-name">tdata</span>) {
    <span class="org-keyword">if</span> (param-&gt;scale) {
        scale = Multiply(scale, gamma);
    }
    <span class="org-type">Expr</span> <span class="org-variable-name">neg_mean</span> = Negative(moving_mean);
    <span class="org-type">Expr</span> <span class="org-variable-name">shift</span> = Multiply(neg_mean, scale);
    <span class="org-keyword">if</span> (param-&gt;center) {
        shift = Add(shift, beta);
    }

    <span class="org-type">Expr</span> <span class="org-variable-name">out</span> = Multiply(data, scale);
    out = Add(out, shift);
    <span class="org-keyword">return</span> out;
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org0000009" class="outline-3">
<h3 id="org0000009"><span class="section-number-3">1.4.</span> Inline</h3>
<div class="outline-text-3" id="text-1-4">
<p>
函数可以被 inline 的条件:
</p>

<ol class="org-ol">
<li>有 `Inline` 属性</li>
<li>不是递归函数</li>
<li>调用的其它函数也是可以 inline 的</li>
</ol>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-08-03 11:11</span>
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay

<span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.IRModule()

<span class="org-variable-name">x1</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x1"</span>, shape<span class="org-operator">=</span>(1, 10))
<span class="org-variable-name">fn1</span> <span class="org-operator">=</span> relay.Function([x1], x1)
<span class="org-variable-name">fn1</span> <span class="org-operator">=</span> fn1.with_attr(<span class="org-string">"Inline"</span>, tvm.tir.IntImm(<span class="org-string">"int32"</span>, 1))
<span class="org-variable-name">g1</span> <span class="org-operator">=</span> relay.GlobalVar(<span class="org-string">"g1"</span>)
<span class="org-variable-name">mod</span>[g1] <span class="org-operator">=</span> fn1

<span class="org-variable-name">x2</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x2"</span>, shape<span class="org-operator">=</span>(1, 10))
<span class="org-variable-name">fn2</span> <span class="org-operator">=</span> relay.Function([x2], x2)
<span class="org-comment-delimiter"># </span><span class="org-comment">fn2 = fn1.with_attr("Inline", tvm.tir.IntImm("int32", 1))</span>
<span class="org-variable-name">g2</span> <span class="org-operator">=</span> relay.GlobalVar(<span class="org-string">"g2"</span>)
<span class="org-variable-name">mod</span>[g2] <span class="org-operator">=</span> fn2

<span class="org-variable-name">p0</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"p0"</span>, shape<span class="org-operator">=</span>(1, 10))
<span class="org-variable-name">mod</span>[<span class="org-string">"main"</span>] <span class="org-operator">=</span> relay.Function([p0], relay.add(g1(p0), g2(p0)))

<span class="org-builtin">print</span>(<span class="org-string">"----------before----------"</span>)
<span class="org-builtin">print</span>(mod)
<span class="org-variable-name">mod</span> <span class="org-operator">=</span> relay.transform.Inline()(mod)
<span class="org-builtin">print</span>(<span class="org-string">"----------after----------"</span>)
<span class="org-builtin">print</span>(mod)

</pre>
</div>

<p>
-----&#x2013;&#x2014;before-----&#x2013;&#x2014;
def @g1(%x1: Tensor[(1, 10), float32], Inline=1) {
  %x1
}
</p>

<p>
def @g2(%x2: Tensor[(1, 10), float32]) {
  %x2
}
</p>

<p>
def @main(%p0: Tensor[(1, 10), float32]) {
  %0 = @g1(%p0);
  %1 = @g2(%p0);
  add(%0, %1)
}
</p>

<p>
-----&#x2013;&#x2014;after-----&#x2013;&#x2014;
def @main(%p0: Tensor[(1, 10), float32]) {
  %0 = @g2(%p0);
  add(%p0, %0)
}
</p>

<p>
def @g2(%x2: Tensor[(1, 10), float32]) {
  %x2
}
</p>
</div>
</div>

<div id="outline-container-org000000f" class="outline-3">
<h3 id="org000000f"><span class="section-number-3">1.5.</span> RunDeviceAnnotationPass</h3>
<div class="outline-text-3" id="text-1-5">
<p>
RunDeviceAnnotationPass 是为了处理 on_device annotation, vta build 时的
<a href="tvm_vta.html#org0000000">graph_pack</a> 依赖 build 时的 RunDeviceAnnotationPass 才能工作
</p>

<p>
NOTE: 新的代码里相关功能放在了 PlanDevices 里了
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-08-03 11:11</span>
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay

<span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(1, 10))
<span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"y"</span>, shape<span class="org-operator">=</span>(1, 10))
<span class="org-variable-name">add</span> <span class="org-operator">=</span> relay.add(x, y)
<span class="org-variable-name">sqrt</span> <span class="org-operator">=</span> relay.sqrt(add)
<span class="org-variable-name">_sqrt</span> <span class="org-operator">=</span> relay.annotation.on_device(sqrt, <span class="org-string">"cuda"</span>)
<span class="org-variable-name">log</span> <span class="org-operator">=</span> relay.log(add)
<span class="org-variable-name">subtract</span> <span class="org-operator">=</span> relay.subtract(_sqrt, log)
<span class="org-variable-name">exp</span> <span class="org-operator">=</span> relay.exp(subtract)
<span class="org-variable-name">_exp</span> <span class="org-operator">=</span> relay.annotation.on_device(exp, <span class="org-string">"cuda"</span>)

<span class="org-variable-name">func</span> <span class="org-operator">=</span> relay.Function([x, y], _exp)
<span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.IRModule.from_expr(func)

<span class="org-builtin">print</span>(<span class="org-string">"----------before----------"</span>)
<span class="org-builtin">print</span>(mod)

<span class="org-builtin">print</span>(<span class="org-string">"----------after----------"</span>)
<span class="org-variable-name">mod</span> <span class="org-operator">=</span> relay.transform.RewriteAnnotatedOps(1)(mod)
<span class="org-builtin">print</span>(mod[<span class="org-string">"main"</span>])
</pre>
</div>

<p>
-----&#x2013;&#x2014;before-----&#x2013;&#x2014;
def @main(%x: Tensor[(1, 10), float32], %y: Tensor[(1, 10), float32]) {
  %0 = add(%x, %y);
  %1 = sqrt(%0);
  %2 = on_device(%1, meta[relay.attrs.OnDeviceAttrs][0]);
  %3 = log(%0);
  %4 = subtract(%2, %3);
  %5 = exp(%4);
  on_device(%5, meta[relay.attrs.OnDeviceAttrs][1])
}
</p>


<p>
-----&#x2013;&#x2014;after-----&#x2013;&#x2014;
fn (%x: Tensor[(1, 10), float32], %y: Tensor[(1, 10), float32]) -&gt; Tensor[(1, 10), float32] {
  %0 = add(%x, %y) <i>* ty=Tensor[(1, 10), float32] *</i>;
  %1 = device_copy(%0, meta[relay.attrs.DeviceCopyAttrs][0]) <i>* ty=Tensor[(1, 10), float32] *</i>;
  %2 = sqrt(%1) <i>* ty=Tensor[(1, 10), float32] *</i>;
  %3 = device_copy(%2, meta[relay.attrs.DeviceCopyAttrs][1]) <i>* ty=Tensor[(1, 10), float32] *</i>;
  %4 = log(%0) <i>* ty=Tensor[(1, 10), float32] *</i>;
  %5 = subtract(%3, %4) <i>* ty=Tensor[(1, 10), float32] *</i>;
  %6 = device_copy(%5, meta[relay.attrs.DeviceCopyAttrs][2]) <i>* ty=Tensor[(1, 10), float32] *</i>;
  exp(%6) <i>* ty=Tensor[(1, 10), float32] *</i>
}
</p>
</div>

<div id="outline-container-org000000c" class="outline-4">
<h4 id="org000000c"><span class="section-number-4">1.5.1.</span> device_copy</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
device_copy 是由 在 LowerTE 时处理的:
</p>

<ol class="org-ol">
<li>一方面它被用来确定 expr 所在的 target, 以确定 topi strategy</li>
<li>另一方面运行时 graph_executor 会根据这个标记做真正的数据拷贝.</li>
</ol>

<p>

</p>

<p>
例如, graph_executor 在执行时碰到 `__copy` 时会调用设备相关的 CopyDataFromTo 等函数, 对于 opencl 来说就是 clEnqueueCopyBuffer:
</p>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">void</span> <span class="org-constant">OpenCLWorkspace</span>::<span class="org-function-name">CopyDataFromTo</span>(
    <span class="org-type">DLTensor</span>* <span class="org-variable-name">from</span>, <span class="org-type">DLTensor</span>* <span class="org-variable-name">to</span>, <span class="org-type">TVMStreamHandle</span> <span class="org-variable-name">stream</span>) {
    <span class="org-keyword">if</span> (IsOpenCLDevice(from-&gt;device) &amp;&amp; IsOpenCLDevice(to-&gt;device)) {
        <span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">from_desc</span> =
            <span class="org-keyword">static_cast</span>&lt;<span class="org-keyword">const</span> <span class="org-constant">cl</span>::<span class="org-type">BufferDescriptor</span>*&gt;(from-&gt;data);
        <span class="org-keyword">auto</span>* <span class="org-variable-name">to_desc</span> = <span class="org-keyword">static_cast</span>&lt;<span class="org-constant">cl</span>::<span class="org-type">BufferDescriptor</span>*&gt;(to-&gt;data);
        clEnqueueCopyBuffer(
            <span class="org-keyword">this</span>-&gt;GetQueue(to-&gt;device), from_desc-&gt;buffer, to_desc-&gt;buffer,
            from-&gt;byte_offset, to-&gt;byte_offset, nbytes, 0, <span class="org-constant">nullptr</span>, <span class="org-constant">nullptr</span>);
    }
    <span class="org-comment-delimiter">// </span><span class="org-comment">...</span>
}
</pre>
</div>

<p>
除了上面 __copy, 使用 opencl 等 target 在 set_input/get_output 时也会通过
CopyDataFromTo 与设备交换数据.
</p>
</div>
</div>
</div>

<div id="outline-container-org000001e" class="outline-3">
<h3 id="org000001e"><span class="section-number-3">1.6.</span> FuseOps</h3>
<div class="outline-text-3" id="text-1-6">
</div>
<div id="outline-container-org0000018" class="outline-4">
<h4 id="org0000018"><span class="section-number-4">1.6.1.</span> Example</h4>
<div class="outline-text-4" id="text-1-6-1">
</div>
<div id="outline-container-org0000012" class="outline-5">
<h5 id="org0000012"><span class="section-number-5">1.6.1.1.</span> 不使用 FuseOps:</h5>
<div class="outline-text-5" id="text-1-6-1-1">
<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-09-08 18:19</span>
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay
<span class="org-keyword">from</span> tvm.relay <span class="org-keyword">import</span> transform
<span class="org-keyword">from</span> tvm.relay.testing <span class="org-keyword">import</span> run_opt_pass
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np


<span class="org-keyword">def</span> <span class="org-function-name">test_fuse_simple</span>():
    <span class="org-doc">"""Simple testcase."""</span>

    <span class="org-keyword">def</span> <span class="org-function-name">before</span>():
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(10, 20))
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(x, x)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">z</span> <span class="org-operator">=</span> relay.exp(y)
        <span class="org-keyword">return</span> relay.Function([x], z)

    <span class="org-variable-name">z</span> <span class="org-operator">=</span> before()
    <span class="org-builtin">print</span>(z)
    <span class="org-comment-delimiter"># </span><span class="org-comment">z = run_opt_pass(z, transform.FuseOps())</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">print(z)</span>
    <span class="org-keyword">with</span> tvm.transform.PassContext(opt_level<span class="org-operator">=</span>0):
        <span class="org-variable-name">graph</span>, <span class="org-variable-name">lib</span>, <span class="org-variable-name">params</span> <span class="org-operator">=</span> relay.build(z, target<span class="org-operator">=</span><span class="org-string">"llvm"</span>, params<span class="org-operator">=</span><span class="org-constant">None</span>)

    <span class="org-builtin">print</span>(graph)


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> <span class="org-operator">==</span> <span class="org-string">"__main__"</span>:
    test_fuse_simple()

</pre>
</div>

<p>
fn (%x: Tensor[(10, 20), float32]) {
  %0 = add(%x, %x);
  %1 = add(%0, %0);
  %2 = add(%1, %1);
  %3 = add(%2, %2);
  %4 = add(%3, %3);
  exp(%4)
}
{
  "nodes": [
    {
      "op": "null", 
      "name": "x", 
      "inputs": []
    }, 
    {
      "op": "tvm_op", 
      "name": "tvmgen_default_fused_add", 
      "attrs": {
        "num_outputs": "1", 
        "num_inputs": "1", 
        "flatten_data": "0", 
        "func_name": "tvmgen_default_fused_add", 
        "hash": "aadf70b47b6beaf4"
      }, 
      "inputs": [
        [
          0, 
          0, 
          0
        ]
      ]
    }, 
    {
      "op": "tvm_op", 
      "name": "tvmgen_default_fused_add1", 
      "attrs": {
        "num_outputs": "1", 
        "num_inputs": "1", 
        "flatten_data": "0", 
        "func_name": "tvmgen_default_fused_add", 
        "hash": "aadf70b47b6beaf4"
      }, 
      "inputs": [
        [
          1, 
          0, 
          0
        ]
      ]
    }, 
    {
      "op": "tvm_op", 
      "name": "tvmgen_default_fused_add2", 
      "attrs": {
        "num_outputs": "1", 
        "num_inputs": "1", 
        "flatten_data": "0", 
        "func_name": "tvmgen_default_fused_add", 
        "hash": "aadf70b47b6beaf4"
      }, 
      "inputs": [
        [
          2, 
          0, 
          0
        ]
      ]
    }, 
    {
      "op": "tvm_op", 
      "name": "tvmgen_default_fused_add3", 
      "attrs": {
        "num_outputs": "1", 
        "num_inputs": "1", 
        "flatten_data": "0", 
        "func_name": "tvmgen_default_fused_add", 
        "hash": "aadf70b47b6beaf4"
      }, 
      "inputs": [
        [
          3, 
          0, 
          0
        ]
      ]
    }, 
    {
      "op": "tvm_op", 
      "name": "tvmgen_default_fused_add4", 
      "attrs": {
        "num_outputs": "1", 
        "num_inputs": "1", 
        "flatten_data": "0", 
        "func_name": "tvmgen_default_fused_add", 
        "hash": "aadf70b47b6beaf4"
      }, 
      "inputs": [
        [
          4, 
          0, 
          0
        ]
      ]
    }, 
    {
      "op": "tvm_op", 
      "name": "tvmgen_default_fused_exp", 
      "attrs": {
        "num_outputs": "1", 
        "num_inputs": "1", 
        "flatten_data": "0", 
        "func_name": "tvmgen_default_fused_exp", 
        "hash": "de3b50c71256954a"
      }, 
      "inputs": [
        [
          5, 
          0, 
          0
        ]
      ]
    }
  ], 
  "arg_nodes": [0], 
  "heads": [
    [
      6, 
      0, 
      0
    ]
  ], 
  "attrs": {
    "dltype": [
      "list_str", 
      [
        "float32", 
        "float32", 
        "float32", 
        "float32", 
        "float32", 
        "float32", 
        "float32"
      ]
    ], 
    "device_index": [
      "list_int", 
      [1, 1, 1, 1, 1, 1, 1]
    ], 
    "storage_id": [
      "list_int", 
      [0, 1, 2, 1, 2, 1, 2]
    ], 
    "shape": [
      "list_shape", 
      [
        [10, 20], 
        [10, 20], 
        [10, 20], 
        [10, 20], 
        [10, 20], 
        [10, 20], 
        [10, 20]
      ]
    ]
  }, 
  "node_row_ptr": [0, 1, 2, 3, 4, 5, 6, 7]
}
</p>

<p>
可以看过每个 add 操作都会对应一个 graph 中的 node
</p>
</div>
</div>

<div id="outline-container-org0000015" class="outline-5">
<h5 id="org0000015"><span class="section-number-5">1.6.1.2.</span> 使用 FuseOps</h5>
<div class="outline-text-5" id="text-1-6-1-2">
<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-09-08 18:19</span>
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay
<span class="org-keyword">from</span> tvm.relay <span class="org-keyword">import</span> transform
<span class="org-keyword">from</span> tvm.relay.testing <span class="org-keyword">import</span> run_opt_pass

<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np


<span class="org-keyword">def</span> <span class="org-function-name">test_fuse_simple</span>():
    <span class="org-doc">"""Simple testcase."""</span>

    <span class="org-keyword">def</span> <span class="org-function-name">before</span>():
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(10, 20))
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(x, x)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y, y)
        <span class="org-variable-name">z</span> <span class="org-operator">=</span> relay.exp(y)
        <span class="org-keyword">return</span> relay.Function([x], z)

    <span class="org-variable-name">z</span> <span class="org-operator">=</span> before()
    <span class="org-variable-name">z</span> <span class="org-operator">=</span> run_opt_pass(z, transform.FuseOps())
    <span class="org-builtin">print</span>(z)
    <span class="org-keyword">with</span> tvm.transform.PassContext(opt_level<span class="org-operator">=</span>0):
        <span class="org-variable-name">graph</span>, <span class="org-variable-name">lib</span>, <span class="org-variable-name">params</span> <span class="org-operator">=</span> relay.build(z, target<span class="org-operator">=</span><span class="org-string">"llvm"</span>, params<span class="org-operator">=</span><span class="org-constant">None</span>)

    <span class="org-builtin">print</span>(graph)


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> <span class="org-operator">==</span> <span class="org-string">"__main__"</span>:
    test_fuse_simple()
</pre>
</div>

<p>
fn (%x: Tensor[(10, 20), float32]) -&gt; Tensor[(10, 20), float32] {
  %5 = fn (%p0: Tensor[(10, 20), float32], Primitive=1) -&gt; Tensor[(10, 20), float32] {
    %0 = add(%p0, %p0) <i>* ty=Tensor[(10, 20), float32] *</i>;
    %1 = add(%0, %0) <i>* ty=Tensor[(10, 20), float32] *</i>;
    %2 = add(%1, %1) <i>* ty=Tensor[(10, 20), float32] *</i>;
    %3 = add(%2, %2) <i>* ty=Tensor[(10, 20), float32] *</i>;
    %4 = add(%3, %3) <i>* ty=Tensor[(10, 20), float32] *</i>;
    exp(%4) <i>* ty=Tensor[(10, 20), float32] *</i>
  };
  %5(%x) <i>* ty=Tensor[(10, 20), float32] *</i>
}
{
  "nodes": [
    {
      "op": "null", 
      "name": "x", 
      "inputs": []
    }, 
    {
      "op": "tvm_op", 
      "name": "tvmgen_default_fused_add_add_add_add_add_exp", 
      "attrs": {
        "num_outputs": "1", 
        "num_inputs": "1", 
        "flatten_data": "0", 
        "func_name": "tvmgen_default_fused_add_add_add_add_add_exp", 
        "hash": "bcd04c940b541895"
      }, 
      "inputs": [
        [
          0, 
          0, 
          0
        ]
      ]
    }
  ], 
  "arg_nodes": [0], 
  "heads": [
    [
      1, 
      0, 
      0
    ]
  ], 
  "attrs": {
    "dltype": [
      "list_str", 
      [
        "float32", 
        "float32"
      ]
    ], 
    "device_index": [
      "list_int", 
      [1, 1]
    ], 
    "storage_id": [
      "list_int", 
      [0, 1]
    ], 
    "shape": [
      "list_shape", 
      [
        [10, 20], 
        [10, 20]
      ]
    ]
  }, 
  "node_row_ptr": [0, 1, 2]
}
</p>

<p>
所有的 op 都被合并到同一个函数 tvmgen_default_fused_add_add_add_add_add_exp
</p>
</div>
</div>
</div>

<div id="outline-container-org000001b" class="outline-4">
<h4 id="org000001b"><span class="section-number-4">1.6.2.</span> 为什么需要 FuseOps</h4>
<div class="outline-text-4" id="text-1-6-2">
<p>
通过 FuseOps 显然可以减少函数调用的开销. 那么, 每次都把所有的 op 都合并到一个函数中不就可以了么?
</p>

<p>
每个 op 都有一个 schedule, 如果 schedule 不是 `相容` 的, 则它们是无法合并在一起的, 例如:
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay
<span class="org-keyword">from</span> tvm.relay <span class="org-keyword">import</span> transform
<span class="org-keyword">from</span> tvm.relay.testing <span class="org-keyword">import</span> run_opt_pass
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np


<span class="org-keyword">def</span> <span class="org-function-name">test_fuse_simple</span>():
    <span class="org-keyword">def</span> <span class="org-function-name">before</span>():
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(20, 20))
        <span class="org-variable-name">y1</span> <span class="org-operator">=</span> relay.add(x, x)
        <span class="org-variable-name">y2</span> <span class="org-operator">=</span> relay.add(y1, y1)
        <span class="org-variable-name">y3</span> <span class="org-operator">=</span> relay.<span class="org-builtin">sum</span>(y2, axis<span class="org-operator">=-</span>1)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.add(y3, y3)

        <span class="org-keyword">return</span> relay.Function([x], y)

    <span class="org-variable-name">z</span> <span class="org-operator">=</span> before()
    <span class="org-variable-name">z</span> <span class="org-operator">=</span> run_opt_pass(z, transform.FuseOps())
    <span class="org-builtin">print</span>(z)

    <span class="org-keyword">with</span> tvm.transform.PassContext(opt_level<span class="org-operator">=</span>0):
        <span class="org-variable-name">graph</span>, <span class="org-variable-name">lib</span>, <span class="org-variable-name">params</span> <span class="org-operator">=</span> relay.build(z, target<span class="org-operator">=</span><span class="org-string">"c"</span>, params<span class="org-operator">=</span><span class="org-constant">None</span>)

    <span class="org-builtin">print</span>(lib.get_source())


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> <span class="org-operator">==</span> <span class="org-string">"__main__"</span>:
    test_fuse_simple()
</pre>
</div>

<p>
fn (%x: Tensor[(20, 20), float32]) -&gt; Tensor[(20), float32] {
  %2 = fn (%p01: Tensor[(20, 20), float32], Primitive=1) -&gt; Tensor[(20), float32] {
    %0 = add(%p01, %p01) <i>* ty=Tensor[(20, 20), float32] *</i>;
    %1 = add(%0, %0) <i>* ty=Tensor[(20, 20), float32] *</i>;
    sum(%1, axis=[-1]) <i>* ty=Tensor[(20), float32] *</i>
  };
  %3 = %2(%x) <i>* ty=Tensor[(20), float32] *</i>;
  %4 = fn (%p0: Tensor[(20), float32], Primitive=1) -&gt; Tensor[(20), float32] {
    add(%p0, %p0) <i>* ty=Tensor[(20), float32] *</i>
  };
  %4(%3) <i>* ty=Tensor[(20), float32] *</i>
}
// tvm target: c -keys=cpu -link-params=0
#define TVM_EXPORTS
#include "tvm/runtime/c_runtime_api.h"
#include "tvm/runtime/c_backend_api.h"
#include &lt;math.h&gt;
#ifdef __cplusplus
extern "C"
#endif
TVM_DLL int32_t tvmgen_default_fused_add_add_sum(void* args, void* arg_type_ids, int32_t num_args, void* out_ret_value, void* out_ret_tcode, void* resource_handle) {
  void* arg0 = (((TVMValue*)args)[0].v_handle);
  int32_t arg0_code = ((int32_t*)arg_type_ids)[(0)];
  void* arg1 = (((TVMValue*)args)[1].v_handle);
  int32_t arg1_code = ((int32_t*)arg_type_ids)[(1)];
  void* placeholder = (((DLTensor*)arg0)[0].data);
  void* arg0_shape = (((DLTensor*)arg0)[0].shape);
  void* arg0_strides = (((DLTensor*)arg0)[0].strides);
  int32_t dev_id = (((DLTensor*)arg0)[0].device.device_id);
  void* T_add_red = (((DLTensor*)arg1)[0].data);
  void* arg1_shape = (((DLTensor*)arg1)[0].shape);
  void* arg1_strides = (((DLTensor*)arg1)[0].strides);
  if (!(arg0_strides <code>= NULL)) {
  }
  if (!(arg1_strides =</code> NULL)) {
  }
  for (int32_t ax0 = 0; ax0 &lt; 20; ++ax0) {
    ((float*)T_add_red)[(ax0)] = 0.000000e+00f;
    for (int32_t k1 = 0; k1 &lt; 20; ++k1) {
      ((float*)T_add_red)[(ax0)] = (((float*)T_add_red)[(ax0)] + ((((float*)placeholder)[(((ax0 * 20) + k1))] + ((float*)placeholder)[(((ax0 * 20) + k1))]) + (((float*)placeholder)[(((ax0 * 20) + k1))] + ((float*)placeholder)[(((ax0 * 20) + k1))])));
    }
  }
  return 0;
}
</p>

<p>
#ifdef __cplusplus
extern "C"
#endif
TVM_DLL int32_t tvmgen_default_fused_add(void* args, void* arg_type_ids, int32_t num_args, void* out_ret_value, void* out_ret_tcode, void* resource_handle) {
  void* arg0 = (((TVMValue*)args)[0].v_handle);
  int32_t arg0_code = ((int32_t*)arg_type_ids)[(0)];
  void* arg1 = (((TVMValue*)args)[1].v_handle);
  int32_t arg1_code = ((int32_t*)arg_type_ids)[(1)];
  void* placeholder = (((DLTensor*)arg0)[0].data);
  void* arg0_shape = (((DLTensor*)arg0)[0].shape);
  void* arg0_strides = (((DLTensor*)arg0)[0].strides);
  int32_t dev_id = (((DLTensor*)arg0)[0].device.device_id);
  void* T_add = (((DLTensor*)arg1)[0].data);
  void* arg1_shape = (((DLTensor*)arg1)[0].shape);
  void* arg1_strides = (((DLTensor*)arg1)[0].strides);
  if (!(arg0_strides <code>= NULL)) {
  }
  if (!(arg1_strides =</code> NULL)) {
  }
  for (int32_t ax0_outer = 0; ax0_outer &lt; 2; ++ax0_outer) {
    for (int32_t ax0_inner_s = 0; ax0_inner_s &lt; 16; ++ax0_inner_s) {
      if (((ax0_outer * 16) + ax0_inner_s) &lt; 20) {
        ((float*)T_add)[(((ax0_outer * 16) + ax0_inner_s))] = (((float*)placeholder)[(((ax0_outer * 16) + ax0_inner_s))] + ((float*)placeholder)[(((ax0_outer * 16) + ax0_inner_s))]);
      }
    }
  }
  return 0;
}
</p>

<p>
y1, y2, y3 三个操作使用的 schedule 都是要处理一个 20x20 的循环, 但 y 的 schdule
处理的是 20x1 的循环, 所以它们无法合并成一个 op. 
</p>
</div>
</div>
</div>

<div id="outline-container-org0000027" class="outline-3">
<h3 id="org0000027"><span class="section-number-3">1.7.</span> FoldScaleAxis</h3>
<div class="outline-text-3" id="text-1-7">
<p>
FoldScaleAxis 可以把 Conv2D 和 BatchNorm 融合在一起.
</p>

<p>
算子融合的好处:
</p>

<ol class="org-ol">
<li>减少算子间的中间内存分配</li>
<li>两个算子的 loop 可以做成同一个 loop</li>
</ol>

<p>
FoldScaleAxis 除了上面的好处, 还有一个原因是许多加速器并不支持 scalar
multiplication, 例如 BatchNorm
</p>

<p>
TVM 的 FoldScaleAxis 实际上包含三个 transform:
</p>

<div class="org-src-container">
<pre class="src src-C++"><span class="org-type">Pass</span> <span class="org-function-name">FoldScaleAxis</span>() {
    <span class="org-type">Pass</span> <span class="org-variable-name">pass</span> = Sequential(
        {BackwardFoldScaleAxis(), ForwardFoldScaleAxis(), FoldConstant()},
        <span class="org-string">"FoldScaleAxis"</span>);
    <span class="org-keyword">return</span> pass;
}
</pre>
</div>

<p>
其中:
</p>

<ul class="org-ul">
<li>BackwardFoldScaleAxis 是把某个 Op (例如 Conv2D) 后面的 scale 与 Op fold 在一起</li>
<li>ForwardFoldScaleAxis 是把 Op 前面的 scale 与 Op fold</li>
<li>ForwardFoldScaleAxis 或 BackwardFoldScaleAxis 只是负责把 x*scale 或 y*scale 变成 w*scale, 最终还需要 FoldConstant 把 w*scale fold 成一个 constant (前提是 w,
scale 都是常量)</li>
</ul>
</div>


<div id="outline-container-org0000021" class="outline-4">
<h4 id="org0000021"><span class="section-number-4">1.7.1.</span> Example</h4>
<div class="outline-text-4" id="text-1-7-1">
<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-10-14 22:36</span>
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> te
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay
<span class="org-keyword">from</span> tvm.relay <span class="org-keyword">import</span> transform

<span class="org-variable-name">I</span> <span class="org-operator">=</span> N <span class="org-operator">=</span> 1
<span class="org-variable-name">O</span> <span class="org-operator">=</span> C <span class="org-operator">=</span> 2
<span class="org-variable-name">H</span> <span class="org-operator">=</span> W <span class="org-operator">=</span> 3


<span class="org-keyword">def</span> <span class="org-function-name">run_opt_pass</span>(expr, opt_pass):
    <span class="org-keyword">assert</span> <span class="org-builtin">isinstance</span>(opt_pass, tvm.transform.Pass)
    <span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.IRModule.from_expr(expr)
    <span class="org-variable-name">mod</span> <span class="org-operator">=</span> opt_pass(mod)
    <span class="org-variable-name">entry</span> <span class="org-operator">=</span> mod[<span class="org-string">"main"</span>]
    <span class="org-keyword">return</span> entry <span class="org-keyword">if</span> <span class="org-builtin">isinstance</span>(expr, relay.Function) <span class="org-keyword">else</span> entry.body


<span class="org-keyword">def</span> <span class="org-function-name">test_fold</span>():
    <span class="org-keyword">def</span> <span class="org-function-name">get_model</span>(x, weight, scale):
        <span class="org-variable-name">args</span> <span class="org-operator">=</span> [x]
        <span class="org-comment-delimiter"># </span><span class="org-comment">x = relay.multiply(x, scale)</span>
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.nn.conv2d(
            x,
            weight,
            channels<span class="org-operator">=</span>C,
            kernel_size<span class="org-operator">=</span>(3, 3),
            padding<span class="org-operator">=</span>(1, 1),
        )
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.multiply(y, scale)

        <span class="org-keyword">return</span> relay.Function(args, y)

    <span class="org-keyword">def</span> <span class="org-function-name">check</span>(shape):
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>shape)

        <span class="org-variable-name">weight</span> <span class="org-operator">=</span> relay.const(np.random.randn(O, I, H, W).astype(<span class="org-string">"float32"</span>))
        <span class="org-variable-name">scale</span> <span class="org-operator">=</span> relay.const(np.random.randn(C, 1, 1).astype(<span class="org-string">"float32"</span>))

        <span class="org-variable-name">y</span> <span class="org-operator">=</span> get_model(x, weight, scale)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> run_opt_pass(y, transform.InferType())
        <span class="org-builtin">print</span>(y)

        <span class="org-variable-name">y_folded</span> <span class="org-operator">=</span> run_opt_pass(y, transform.BackwardFoldScaleAxis())
        <span class="org-builtin">print</span>(y_folded)

        <span class="org-variable-name">y_folded</span> <span class="org-operator">=</span> run_opt_pass(y_folded, transform.FoldConstant())
        <span class="org-builtin">print</span>(y_folded)

    check((1, N, 10, 10))


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> <span class="org-operator">==</span> <span class="org-string">"__main__"</span>:
    test_fold()
</pre>
</div>

<p>
fn (%x: Tensor[(1, 1, 10, 10), float32]) -&gt; Tensor[(1, 2, 10, 10), float32] {
  %0 = nn.conv2d(%x, meta[relay.Constant][0] <i>* ty=Tensor[(2, 1, 3, 3), float32] *</i>, padding=[1, 1, 1, 1], channels=2, kernel_size=[3, 3]) <i>* ty=Tensor[(1, 2, 10, 10), float32] *</i>;
  multiply(%0, meta[relay.Constant][1] <i>* ty=Tensor[(2, 1, 1), float32] *</i>) <i>* ty=Tensor[(1, 2, 10, 10), float32] *</i>
}
</p>

<p>
fn (%x: Tensor[(1, 1, 10, 10), float32]) -&gt; Tensor[(1, 2, 10, 10), float32] {
  %0 = squeeze(meta[relay.Constant][1] <i>* ty=Tensor[(2, 1, 1), float32] *</i>, axis=[1, 2]) <i>* ty=Tensor[(2), float32] *</i>;
  %1 = expand_dims(%0, axis=1, num_newaxis=3) <i>* ty=Tensor[(2, 1, 1, 1), float32] *</i>;
  %2 = multiply(meta[relay.Constant][0] <i>* ty=Tensor[(2, 1, 3, 3), float32] *</i>, %1) <i>* ty=Tensor[(2, 1, 3, 3), float32] *</i>;
  nn.conv2d(%x, %2, padding=[1, 1, 1, 1], channels=2, kernel_size=[3, 3]) <i>* ty=Tensor[(1, 2, 10, 10), float32] *</i>
}
</p>

<p>
fn (%x: Tensor[(1, 1, 10, 10), float32]) -&gt; Tensor[(1, 2, 10, 10), float32] {
  nn.conv2d(%x, meta[relay.Constant][0] <i>* ty=Tensor[(2, 1, 3, 3), float32] *</i>, padding=[1, 1, 1, 1], channels=2, kernel_size=[3, 3]) <i>* ty=Tensor[(1, 2, 10, 10), float32] *</i>
}
</p>
</div>
</div>

<div id="outline-container-org0000024" class="outline-4">
<h4 id="org0000024"><span class="section-number-4">1.7.2.</span> Impl</h4>
<div class="outline-text-4" id="text-1-7-2">
<div class="org-src-container">
<pre class="src src-C++"><span class="org-comment-delimiter">// </span><span class="org-comment">multiply &#20250;&#20808;&#20110; conv2d &#34987;&#36941;&#21382;&#21040;, &#35760;&#19979; scale</span>
<span class="org-type">Expr</span> <span class="org-function-name">MultiplyBackwardTransform</span>(
    <span class="org-keyword">const</span> <span class="org-type">Call</span>&amp; <span class="org-variable-name">call</span>, <span class="org-keyword">const</span> <span class="org-type">Message</span>&amp; <span class="org-variable-name">message</span>, <span class="org-keyword">const</span> <span class="org-type">Expr</span>&amp; <span class="org-variable-name">scale</span>,
    <span class="org-keyword">const</span> <span class="org-type">BackwardTransformer</span>&amp; <span class="org-variable-name">transformer</span>) {
    ICHECK(<span class="org-negation-char">!</span>message.defined()) &lt;&lt; <span class="org-string">"outstanding scale"</span>;
    <span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">tlhs</span> = call-&gt;args[0]-&gt;type_as&lt;TensorTypeNode&gt;();
    <span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">trhs</span> = call-&gt;args[1]-&gt;type_as&lt;TensorTypeNode&gt;();
    <span class="org-type">Message</span> <span class="org-variable-name">lhs_message</span> = transformer-&gt;GetMessage(call-&gt;args[0]);
    <span class="org-type">Message</span> <span class="org-variable-name">rhs_message</span> = transformer-&gt;GetMessage(call-&gt;args[1]);
    <span class="org-keyword">if</span> (lhs_message.defined()) {
        <span class="org-type">Expr</span> <span class="org-variable-name">rhs</span> = call-&gt;args[1];
        <span class="org-keyword">if</span> (MatchBroadcastToLeftAxes(tlhs, trhs, lhs_message-&gt;axes, &amp;rhs) &amp;&amp;
            (<span class="org-negation-char">!</span>lhs_message-&gt;require_positive || IsAllPositiveConstant(rhs))) {
            <span class="org-comment-delimiter">// </span><span class="org-comment">&#20363;&#22914;, mul(conv2d, scale), call-&gt;args[0] &#21363; conv2d, rhs &#21363; scale</span>
            <span class="org-keyword">return</span> transformer-&gt;Transform(call-&gt;args[0], lhs_message, rhs);
        }
    } <span class="org-keyword">else</span> <span class="org-keyword">if</span> (rhs_message.defined()) {
        <span class="org-type">Expr</span> <span class="org-variable-name">lhs</span> = call-&gt;args[0];
        <span class="org-keyword">if</span> (MatchBroadcastToLeftAxes(trhs, tlhs, rhs_message-&gt;axes, &amp;lhs) &amp;&amp;
            (<span class="org-negation-char">!</span>rhs_message-&gt;require_positive || IsAllPositiveConstant(lhs))) {
            <span class="org-comment-delimiter">// </span><span class="org-comment">mul(scale,conv2d), call-&gt;args[1] &#21363; conv2d, lhs &#21363; scale</span>
            <span class="org-keyword">return</span> transformer-&gt;Transform(call-&gt;args[1], rhs_message, lhs);
        }
    }
    <span class="org-keyword">return</span> transformer-&gt;NormalCallTransform(call.<span class="org-keyword">operator</span>-&gt;());
}

<span class="org-type">Expr</span> <span class="org-function-name">Conv2DBackwardTransform</span>(
    <span class="org-keyword">const</span> <span class="org-type">Call</span>&amp; <span class="org-variable-name">call</span>, <span class="org-keyword">const</span> <span class="org-type">Message</span>&amp; <span class="org-variable-name">message</span>, <span class="org-keyword">const</span> <span class="org-type">Expr</span>&amp; <span class="org-variable-name">scale</span>,
    <span class="org-keyword">const</span> <span class="org-type">BackwardTransformer</span>&amp; <span class="org-variable-name">transformer</span>) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">...</span>
    <span class="org-type">Expr</span> <span class="org-variable-name">data</span> = transformer-&gt;Transform(
        call-&gt;args[0], NullValue&lt;<span class="org-type">Message</span>&gt;(), NullValue&lt;<span class="org-type">Expr</span>&gt;());
    <span class="org-type">Expr</span> <span class="org-variable-name">weight</span> = transformer-&gt;Transform(
        call-&gt;args[1], NullValue&lt;<span class="org-type">Message</span>&gt;(), NullValue&lt;<span class="org-type">Expr</span>&gt;());
    <span class="org-comment-delimiter">// </span><span class="org-comment">scale on input for deptwise.</span>
    <span class="org-type">Expr</span> <span class="org-variable-name">wscale</span> =
        ExpandBiasToMatchAxis(scale, kernel_layout.ndim(), {big_ko_axis});
    weight = Multiply(weight, wscale);
    <span class="org-keyword">return</span> Call(call-&gt;op, {data, weight}, call-&gt;attrs, call-&gt;type_args);
}
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org000002d" class="outline-3">
<h3 id="org000002d"><span class="section-number-3">1.8.</span> CombineParallelDense</h3>
<div class="outline-text-3" id="text-1-8">
<p>
FuseOps, FoldScaleAxis 等 transform 属于纵向的融合, 而 CombineXXX 属于横向的融合
</p>
</div>

<div id="outline-container-org000002a" class="outline-4">
<h4 id="org000002a"><span class="section-number-4">1.8.1.</span> Example</h4>
<div class="outline-text-4" id="text-1-8-1">
<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-10-14 22:36</span>
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> te
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay
<span class="org-keyword">from</span> tvm.relay <span class="org-keyword">import</span> transform


<span class="org-keyword">def</span> <span class="org-function-name">run_opt_pass</span>(expr, opt_pass):
    <span class="org-keyword">assert</span> <span class="org-builtin">isinstance</span>(opt_pass, tvm.transform.Pass)
    <span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.IRModule.from_expr(expr)
    <span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.relay.transform.InferType()(mod)
    <span class="org-variable-name">mod</span> <span class="org-operator">=</span> opt_pass(mod)
    <span class="org-keyword">return</span> mod[<span class="org-string">"main"</span>]


<span class="org-keyword">def</span> <span class="org-function-name">test_combine_parallel_dense</span>():
    <span class="org-doc">"""Simple testcase. One dense cannot be combined due to shape mismatch"""</span>

    <span class="org-keyword">def</span> <span class="org-function-name">before</span>(x, w1, w2):
        <span class="org-variable-name">args</span> <span class="org-operator">=</span> [x, w1, w2]
        <span class="org-variable-name">y1</span> <span class="org-operator">=</span> relay.nn.dense(x, w1)
        <span class="org-variable-name">y2</span> <span class="org-operator">=</span> relay.nn.dense(x, w2)

        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.Tuple((y1, y2))
        <span class="org-keyword">return</span> relay.Function(args, y)

    <span class="org-keyword">def</span> <span class="org-function-name">check</span>(i, j, k):
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>(i, k))
        <span class="org-variable-name">w1</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"w1"</span>, shape<span class="org-operator">=</span>(j, k))
        <span class="org-variable-name">w2</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"w2"</span>, shape<span class="org-operator">=</span>(j, k))

        <span class="org-variable-name">y_before</span> <span class="org-operator">=</span> before(x, w1, w2)
        <span class="org-builtin">print</span>(y_before)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> run_opt_pass(y_before, transform.CombineParallelDense(min_num_branches<span class="org-operator">=</span>2))
        <span class="org-builtin">print</span>(y)

    <span class="org-comment-delimiter"># </span><span class="org-comment">3x4 &#20998;&#21035;&#21644;&#20004;&#20010; 4x5 &#30456;&#20056;, &#24471;&#21040;&#20004;&#20010; 3x5</span>
    check(3, 5, 4)


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> <span class="org-operator">==</span> <span class="org-string">"__main__"</span>:
    test_combine_parallel_dense()
</pre>
</div>

<p>
fn (%x: Tensor[(3, 4), float32], %w1: Tensor[(5, 4), float32], %w2: Tensor[(5, 4), float32]) {
  %0 = nn.dense(%x, %w1, units=None);
  %1 = nn.dense(%x, %w2, units=None);
  (%0, %1)
}
fn (%x: Tensor[(3, 4), float32], %w1: Tensor[(5, 4), float32], %w2: Tensor[(5, 4), float32]) -&gt; (Tensor[(3, 5), float32], Tensor[(3, 5), float32]) {
  %0 = (%x, %x);
  %1 = (%w1, %w2);
  %2 = stack(%0) <i>* ty=Tensor[(2, 3, 4), float32] *</i>;
  %3 = stack(%1) <i>* ty=Tensor[(2, 5, 4), float32] *</i>;
  %4 = nn.batch_matmul(%2, %3, transpose_b=True) <i>* ty=Tensor[(2, 3, 5), float32] *</i>;
  %5 = split(%4, indices_or_sections=2) <i>* ty=(Tensor[(1, 3, 5), float32], Tensor[(1, 3, 5), float32]) *</i>;
  %6 = %5.0;
  %7 = %5.1;
  %8 = squeeze(%6, axis=[0]) <i>* ty=Tensor[(3, 5), float32] *</i>;
  %9 = squeeze(%7, axis=[0]) <i>* ty=Tensor[(3, 5), float32] *</i>;
  (%8, %9)
}
</p>
</div>
</div>
</div>

<div id="outline-container-org0000033" class="outline-3">
<h3 id="org0000033"><span class="section-number-3">1.9.</span> CombineParallelConv2D</h3>
<div class="outline-text-3" id="text-1-9">
</div>
<div id="outline-container-org0000030" class="outline-4">
<h4 id="org0000030"><span class="section-number-4">1.9.1.</span> Example</h4>
<div class="outline-text-4" id="text-1-9-1">
<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-10-22 16:46</span>

<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> relay
<span class="org-keyword">from</span> tvm.relay <span class="org-keyword">import</span> transform


<span class="org-keyword">def</span> <span class="org-function-name">test_combine_parallel_conv2d</span>():
    <span class="org-keyword">def</span> <span class="org-function-name">before</span>(x, w1, w2):
        <span class="org-variable-name">args</span> <span class="org-operator">=</span> [x, w1, w2]
        <span class="org-variable-name">y1</span> <span class="org-operator">=</span> relay.nn.conv2d(x, w1)
        <span class="org-variable-name">y2</span> <span class="org-operator">=</span> relay.nn.conv2d(x, w2)
        <span class="org-variable-name">y3</span> <span class="org-operator">=</span> relay.nn.max_pool2d(x)
        <span class="org-variable-name">y</span> <span class="org-operator">=</span> relay.Tuple((y1, y2, y3))
        <span class="org-variable-name">func</span> <span class="org-operator">=</span> relay.Function(args, y)
        <span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.IRModule.from_expr(func)
        <span class="org-variable-name">mod</span> <span class="org-operator">=</span> tvm.relay.transform.InferType()(mod)
        <span class="org-keyword">return</span> mod

    <span class="org-keyword">def</span> <span class="org-function-name">check</span>(x_shape, channels1, channels2):
        <span class="org-variable-name">x</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"x"</span>, shape<span class="org-operator">=</span>x_shape)
        <span class="org-variable-name">in_c</span> <span class="org-operator">=</span> x_shape[1]
        <span class="org-variable-name">w1</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"w1"</span>, shape<span class="org-operator">=</span>(channels1, in_c, 1, 1))
        <span class="org-variable-name">w2</span> <span class="org-operator">=</span> relay.var(<span class="org-string">"w2"</span>, shape<span class="org-operator">=</span>(channels2, in_c, 1, 1))

        <span class="org-variable-name">mod</span> <span class="org-operator">=</span> before(x, w1, w2)
        <span class="org-builtin">print</span>(<span class="org-string">"------before------"</span>)
        <span class="org-builtin">print</span>(mod)
        <span class="org-variable-name">mod</span> <span class="org-operator">=</span> transform.CombineParallelConv2D(min_num_branches<span class="org-operator">=</span>2)(mod)
        <span class="org-builtin">print</span>(<span class="org-string">"------after------"</span>)
        <span class="org-builtin">print</span>(mod)

    check((1, 4, 16, 16), 4, 4)


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> <span class="org-operator">==</span> <span class="org-string">"__main__"</span>:
    test_combine_parallel_conv2d()
</pre>
</div>

<p>
-&#x2013;&#x2014;before-&#x2013;&#x2014;
def @main(%x: Tensor[(1, 4, 16, 16), float32], %w1: Tensor[(4, 4, 1, 1), float32], %w2: Tensor[(4, 4, 1, 1), float32]) -&gt; (Tensor[(1, 4, 16, 16), float32], Tensor[(1, 4, 16, 16), float32], Tensor[(1, 4, 16, 16), float32]) {
  %0 = nn.conv2d(%x, %w1, padding=[0, 0, 0, 0]) <i>* ty=Tensor[(1, 4, 16, 16), float32] *</i>;
  %1 = nn.conv2d(%x, %w2, padding=[0, 0, 0, 0]) <i>* ty=Tensor[(1, 4, 16, 16), float32] *</i>;
  %2 = nn.max_pool2d(%x, pool_size=[1, 1], padding=[0, 0, 0, 0]) <i>* ty=Tensor[(1, 4, 16, 16), float32] *</i>;
  (%0, %1, %2)
}
</p>

<p>
-&#x2013;&#x2014;after-&#x2013;&#x2014;
def @main(%x: Tensor[(1, 4, 16, 16), float32], %w1: Tensor[(4, 4, 1, 1), float32], %w2: Tensor[(4, 4, 1, 1), float32]) -&gt; (Tensor[(1, 4, 16, 16), float32], Tensor[(1, 4, 16, 16), float32], Tensor[(1, 4, 16, 16), float32]) {
  %0 = (%w1, %w2);
  %1 = concatenate(%0) <i>* ty=Tensor[(8, 4, 1, 1), float32] *</i>;
  %2 = nn.conv2d(%x, %1, padding=[0, 0, 0, 0], channels=8) <i>* ty=Tensor[(1, 8, 16, 16), float32] *</i>;
  %3 = strided_slice(%2, begin=[0, 0], end=[-1, 4], strides=[1, 1], slice_mode="size", axes=None) <i>* ty=Tensor[(1, 4, 16, 16), float32] *</i>;
  %4 = strided_slice(%2, begin=[0, 4], end=[-1, 4], strides=[1, 1], slice_mode="size", axes=None) <i>* ty=Tensor[(1, 4, 16, 16), float32] *</i>;
  %5 = nn.max_pool2d(%x, pool_size=[1, 1], padding=[0, 0, 0, 0]) <i>* ty=Tensor[(1, 4, 16, 16), float32] *</i>;
  (%3, %4, %5)
}
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway@dogdog.run<br />
Date: 2021-10-25 Mon 00:00<br />
Last updated: 2022-01-24 Mon 19:34</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
</div>
</body>
</html>