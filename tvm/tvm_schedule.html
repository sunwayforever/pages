<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>TVM Schedule</title>

<link rel="stylesheet" type="text/css" href="/main.css" media="screen" />
<link rel = "icon" href = "/icon.png"  type = "image/x-icon">
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<h1 class="title">TVM Schedule</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0000057">1. TVM Schedule</a>
<ul>
<li><a href="#org0000030">1.1. Schedule</a>
<ul>
<li><a href="#org0000000">1.1.1. Overview</a></li>
<li><a href="#org0000003">1.1.2. Example</a></li>
<li><a href="#org0000027">1.1.3. TVM Schedule Primitives</a></li>
<li><a href="#org000002a">1.1.4. Injective Schedule</a></li>
<li><a href="#org000002d">1.1.5. Reduce Schedule</a></li>
</ul>
</li>
<li><a href="#org0000036">1.2. AutoTVM</a>
<ul>
<li><a href="#org0000033">1.2.1. MicroTVM 与 AutoTVM</a></li>
</ul>
</li>
<li><a href="#org0000054">1.3. TVM Auto Scheduler</a>
<ul>
<li><a href="#org0000039">1.3.1. Testing Function</a></li>
<li><a href="#org000003c">1.3.2. AutoScheduler Tunning</a></li>
<li><a href="#org000003f">1.3.3. Evaluation</a></li>
<li><a href="#org000004e">1.3.4. Auto Scheduler Internals</a></li>
<li><a href="#org0000051">1.3.5. Auto Scheduler and MicroTVM</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0000057" class="outline-2">
<h2 id="org0000057"><span class="section-number-2">1</span> TVM Schedule</h2>
<div class="outline-text-2" id="text-1">
</div>

<div id="outline-container-org0000030" class="outline-3">
<h3 id="org0000030"><span class="section-number-3">1.1</span> Schedule</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org0000000" class="outline-4">
<h4 id="org0000000"><span class="section-number-4">1.1.1</span> Overview</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
<a href="http://tvm.apache.org/docs/api/python/te.html">http://tvm.apache.org/docs/api/python/te.html</a>
</p>

<p>
<a href="https://github.com/StrongSpoon/tvm.schedule">https://github.com/StrongSpoon/tvm.schedule</a>
</p>

<p>
TE (tensor expression) 位于 Relay IR 和 TIR 之间, TE 包含 compute + schedule, 其中 compute 用 TIR 来描述运算的核心操作，schedule 用来描述如何调度.
</p>

<p>
Q: 什么是调度 &amp; 为什么需要调度
</p>

<p>
<a href="http://people.csail.mit.edu/jrk/halide-pldi13.pdf">Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines</a>
</p>

<p>
<a href="https://arxiv.org/pdf/1805.08166.pdf">Learning to Optimize Tensor Programs</a>
</p>
</div>
</div>

<div id="outline-container-org0000003" class="outline-4">
<h4 id="org0000003"><span class="section-number-4">1.1.2</span> Example</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
Relay IR 先经过 tvm.relay.transform 进行优化，然后转换为 TE, 然后通过 schedule
产生最佳性能的代码 (例如 vectorize scheduler 会使用 SIMD 指令加速)
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> te

<span class="org-variable-name">M</span> = 1024
<span class="org-variable-name">N</span> = 1024
<span class="org-variable-name">A</span> = te.placeholder((M, N), name=<span class="org-string">"A"</span>)
<span class="org-variable-name">B</span> = te.placeholder((M, N), name=<span class="org-string">"B"</span>)
<span class="org-variable-name">C</span> = te.compute((M, N), <span class="org-keyword">lambda</span> x, y: A[x, y] + B[x, y], name=<span class="org-string">"C"</span>)

<span class="org-variable-name">s</span> = te.create_schedule(C.op)
<span class="org-keyword">print</span>(tvm.lower(s, [A, B, C]))

<span class="org-variable-name">f</span> = tvm.build(s, [A, B, C], <span class="org-string">"c"</span>)
<span class="org-keyword">print</span>(f.get_source())
</pre>
</div>

<p>
primfn(A_1: handle, B_1: handle, C_1: handle) -&gt; ()
  attr = {"global_symbol": "main", "tir.noalias": True}
  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),
             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}
  buffer_map = {A_1: A, B_1: B, C_1: C} {
  for (x: int32, 0, 1024) {
    for (y: int32, 0, 1024) {
      C_2[((x*1024) + y)] = ((float32*)A_2[((x*1024) + y)] + (float32*)B_2[((x*1024) + y)])
    }
  }
}
</p>


<p>
// tvm target: c -keys=cpu -link-params=0
#define TVM_EXPORTS
#include "tvm/runtime/c_runtime_api.h"
#include "tvm/runtime/c_backend_api.h"
#include &lt;math.h&gt;
#ifdef __cplusplus
extern "C"
#endif
TVM_DLL int32_t default_function(void* args, void* arg_type_ids, int32_t num_args, void* out_ret_value, void* out_ret_tcode, void* resource_handle) {
  void* arg0 = (((TVMValue*)args)[0].v_handle);
  int32_t arg0_code = ((int32_t*)arg_type_ids)[(0)];
  void* arg1 = (((TVMValue*)args)[1].v_handle);
  int32_t arg1_code = ((int32_t*)arg_type_ids)[(1)];
  void* arg2 = (((TVMValue*)args)[2].v_handle);
  int32_t arg2_code = ((int32_t*)arg_type_ids)[(2)];
  void* A = (((DLTensor*)arg0)[0].data);
  void* arg0_shape = (((DLTensor*)arg0)[0].shape);
  void* arg0_strides = (((DLTensor*)arg0)[0].strides);
  int32_t dev_id = (((DLTensor*)arg0)[0].device.device_id);
  void* B = (((DLTensor*)arg1)[0].data);
  void* arg1_shape = (((DLTensor*)arg1)[0].shape);
  void* arg1_strides = (((DLTensor*)arg1)[0].strides);
  void* C = (((DLTensor*)arg2)[0].data);
  void* arg2_shape = (((DLTensor*)arg2)[0].shape);
  void* arg2_strides = (((DLTensor*)arg2)[0].strides);
  if (!(arg0_strides == NULL)) {
  }
  if (!(arg1_strides == NULL)) {
  }
  if (!(arg2_strides == NULL)) {
  }
  for (int32_t x = 0; x &lt; 1024; ++x) {
    for (int32_t y = 0; y &lt; 1024; ++y) {
      ((float*)C)[(((x * 1024) + y))] = (((float*)A)[(((x * 1024) + y))] + ((float*)B)[(((x * 1024) + y))]);
    }
  }
  return 0;
}
</p>

<p>
使用 split schedule 后：
</p>

<div class="org-src-container">
<pre class="src src-ipython">s[C].split(C.op.axis[0], factor=20)
<span class="org-keyword">print</span>(tvm.lower(s, [A, B, C]))
</pre>
</div>

<p>
primfn(A_1: handle, B_1: handle, C_1: handle) -&gt; ()
  attr = {"global_symbol": "main", "tir.noalias": True}
  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),
             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}
  buffer_map = {A_1: A, B_1: B, C_1: C} {
  for (x.outer: int32, 0, 52) {
    for (x.inner: int32, 0, 20) {
      if (((x.outer*20) + x.inner) &lt; 1024) {
        for (y: int32, 0, 1024) {
          C_2[(((x.outer*20480) + (x.inner*1024)) + y)] = ((float32*)A_2[(((x.outer*20480) + (x.inner*1024)) + y)] + (float32*)B_2[(((x.outer*20480) + (x.inner*1024)) + y)])
        }
      }
    }
  }
}
</p>

<p>
使用 vectorize schedule 后:
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">s</span> = te.create_schedule(C.op)
<span class="org-variable-name">xo</span>, <span class="org-variable-name">yo</span>, <span class="org-variable-name">xi</span>, <span class="org-variable-name">yi</span> = s[C].tile(C.op.axis[0], C.op.axis[1], 32, 32)

<span class="org-keyword">print</span>(tvm.lower(s, [A, B, C], simple_mode=<span class="org-constant">True</span>))
<span class="org-keyword">print</span>(<span class="org-string">"---------cutting line---------"</span>)

s[C].vectorize(yi)

<span class="org-keyword">print</span>(tvm.lower(s, [A, B, C], simple_mode=<span class="org-constant">True</span>))
</pre>
</div>

<p>
primfn(A_1: handle, B_1: handle, C_1: handle) -&gt; ()
  attr = {"global_symbol": "main", "tir.noalias": True}
  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),
             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}
  buffer_map = {A_1: A, B_1: B, C_1: C} {
  for (x.outer: int32, 0, 32) {
    for (y.outer: int32, 0, 32) {
      for (x.inner: int32, 0, 32) {
        for (y.inner: int32, 0, 32) {
          C_2[((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)] = ((float32*)A_2[((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)] + (float32*)B_2[((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)])
        }
      }
    }
  }
}
</p>


<p>
----&#x2013;&#x2014;cutting line----&#x2013;&#x2014;
primfn(A_1: handle, B_1: handle, C_1: handle) -&gt; ()
  attr = {"global_symbol": "main", "tir.noalias": True}
  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),
             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}
  buffer_map = {A_1: A, B_1: B, C_1: C} {
  for (x.outer: int32, 0, 32) {
    for (y.outer: int32, 0, 32) {
      for (x.inner: int32, 0, 32) {
        C_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] = ((float32x32*)A_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] + (float32x32*)B_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)])
      }
    }
  }
}
</p>
</div>
</div>

<div id="outline-container-org0000027" class="outline-4">
<h4 id="org0000027"><span class="section-number-4">1.1.3</span> TVM Schedule Primitives</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
<a href="https://tvm.apache.org/docs/tutorials/language/schedule_primitives.html">https://tvm.apache.org/docs/tutorials/language/schedule_primitives.html</a>
</p>

<p>
schedule 主要分为以下几类:
</p>

<ol class="org-ol">
<li>memory tiling</li>
<li>loop transformation (splitting, reording, unrolling)</li>
<li>vectorization/tensorization</li>
<li>parallelization</li>
</ol>
</div>

<div id="outline-container-org0000006" class="outline-5">
<h5 id="org0000006"><span class="section-number-5">1.1.3.1</span> split</h5>
</div>

<div id="outline-container-org0000009" class="outline-5">
<h5 id="org0000009"><span class="section-number-5">1.1.3.2</span> ternsorize</h5>
<div class="outline-text-5" id="text-1-1-3-2">
<p>
<a href="https://tvm.apache.org/docs/tutorials/language/tensorize.html">https://tvm.apache.org/docs/tutorials/language/tensorize.html</a>
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-10-22 16:46</span>
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> te

<span class="org-comment-delimiter"># </span><span class="org-comment">a = 1024 x 64</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">b = 512  x 64</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">c = a @ b.T = 1024 x 512</span>
<span class="org-variable-name">N</span>, <span class="org-variable-name">M</span>, <span class="org-variable-name">L</span> = 1024, 512, 64
<span class="org-variable-name">A</span> = te.placeholder((N, L), name=<span class="org-string">"A"</span>)
<span class="org-variable-name">B</span> = te.placeholder((M, L), name=<span class="org-string">"B"</span>)
<span class="org-variable-name">k</span> = te.reduce_axis((0, L), name=<span class="org-string">"k"</span>)
<span class="org-variable-name">C</span> = te.compute((N, M), <span class="org-keyword">lambda</span> i, j: te.<span class="org-builtin">sum</span>(A[i, k] * B[j, k], axis=k), name=<span class="org-string">"C"</span>)
<span class="org-variable-name">s</span> = te.create_schedule(C.op)

<span class="org-variable-name">factor</span> = 32
<span class="org-variable-name">x</span>, <span class="org-variable-name">y</span> = C.op.axis
(z,) = C.op.reduce_axis
<span class="org-variable-name">yo</span>, <span class="org-variable-name">yi</span> = s[C].split(y, factor=factor)
<span class="org-comment-delimiter"># </span><span class="org-comment">s[C].reorder(x, yo, yi, z)</span>
<span class="org-keyword">print</span>(<span class="org-string">"------ before ------"</span>)
<span class="org-keyword">print</span>(tvm.lower(s, [A, B, C], simple_mode=<span class="org-constant">True</span>))


<span class="org-keyword">def</span> <span class="org-function-name">intrin_gemv</span>(m, l):
    <span class="org-variable-name">a</span> = te.placeholder((l,), name=<span class="org-string">"a"</span>)
    <span class="org-variable-name">b</span> = te.placeholder((m, l), name=<span class="org-string">"b"</span>)
    <span class="org-variable-name">k</span> = te.reduce_axis((0, l), name=<span class="org-string">"k"</span>)
    <span class="org-variable-name">c</span> = te.compute((m,), <span class="org-keyword">lambda</span> i: te.<span class="org-builtin">sum</span>(a[k] * b[i, k], axis=k), name=<span class="org-string">"c"</span>)

    <span class="org-variable-name">Abuf</span> = tvm.tir.decl_buffer(a.shape, a.dtype, name=<span class="org-string">"A"</span>, offset_factor=1, strides=[1])
    <span class="org-variable-name">Bbuf</span> = tvm.tir.decl_buffer(
        b.shape, b.dtype, name=<span class="org-string">"B"</span>, offset_factor=1, strides=[te.var(<span class="org-string">"s1"</span>), 1]
    )
    <span class="org-variable-name">Cbuf</span> = tvm.tir.decl_buffer(c.shape, c.dtype, name=<span class="org-string">"C"</span>, offset_factor=1, strides=[1])

    <span class="org-keyword">def</span> <span class="org-function-name">intrin_func</span>(ins, outs):
        <span class="org-variable-name">ib</span> = tvm.tir.ir_builder.create()
        <span class="org-variable-name">aa</span>, <span class="org-variable-name">bb</span> = ins
        <span class="org-variable-name">cc</span> = outs[0]
        ib.emit(
            tvm.tir.call_extern(
                <span class="org-string">"int32"</span>,
                <span class="org-string">"gemv_update"</span>,
                cc.access_ptr(<span class="org-string">"w"</span>),
                aa.access_ptr(<span class="org-string">"r"</span>),
                bb.access_ptr(<span class="org-string">"r"</span>),
                m,
                l,
                bb.strides[0],
            )
        )
        <span class="org-keyword">return</span> ib.get()

    <span class="org-keyword">return</span> te.decl_tensor_intrin(c.op, intrin_func, binds={a: Abuf, b: Bbuf, c: Cbuf})


<span class="org-comment-delimiter"># </span><span class="org-comment">def gemv_impl():</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment">cc_code = """</span>
<span class="org-comment-delimiter">#       </span><span class="org-comment">extern "C" int gemv_update(float *cc, float *aa, float *bb, int m, int l, int stride) {</span>
<span class="org-comment-delimiter">#         </span><span class="org-comment">for (int i = 0; i &lt; m; ++i) {</span>
<span class="org-comment-delimiter">#             </span><span class="org-comment">for (int j = 0; j &lt; l; ++j) {</span>
<span class="org-comment-delimiter">#                 </span><span class="org-comment">cc[i] += aa[j] * bb[i * stride + j];</span>
<span class="org-comment-delimiter">#             </span><span class="org-comment">}</span>
<span class="org-comment-delimiter">#         </span><span class="org-comment">}</span>
<span class="org-comment-delimiter">#         </span><span class="org-comment">return 0;</span>
<span class="org-comment-delimiter">#       </span><span class="org-comment">}</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment">"""</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment">from tvm.contrib import utils, clang</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment">temp = utils.tempdir()</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment">ll_path = temp.relpath("temp.ll")</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment"># Create LLVM ir from c source code</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment">ll_code = clang.create_llvm(cc_code, output=ll_path)</span>
<span class="org-comment-delimiter">#     </span><span class="org-comment">return ll_code</span>
<span class="org-comment-delimiter">#</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">s[C].pragma(x, "import_llvm", gemv_impl())</span>

<span class="org-keyword">print</span>(<span class="org-string">"------ after ------"</span>)
<span class="org-variable-name">gemv</span> = intrin_gemv(factor, L)
s[C].tensorize(yi, gemv)
<span class="org-keyword">print</span>(tvm.lower(s, [A, B, C], simple_mode=<span class="org-constant">True</span>))
</pre>
</div>

<p>
-&#x2013;&#x2014; before -&#x2013;&#x2014;
primfn(A_1: handle, B_1: handle, C_1: handle) -&gt; ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 512], []),
             B: Buffer(B_2: Pointer(float32), float32, [512, 64], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 64], [])}
  buffer_map = {A_1: A, B_1: B, C_1: C} {
  for (i: int32, 0, 1024) {
    for (j.outer: int32, 0, 16) {
      for (j.inner: int32, 0, 32) {
        C_2[(((i*512) + (j.outer*32)) + j.inner)] = 0f32
        for (k: int32, 0, 64) {
          C_2[(((i*512) + (j.outer*32)) + j.inner)] = ((float32*)C_2[(((i*512) + (j.outer*32)) + j.inner)] + ((float32*)A_2[((i*64) + k)]*(float32*)B_2[(((j.outer*2048) + (j.inner*64)) + k)]))
        }
      }
    }
  }
}
</p>


<p>
-&#x2013;&#x2014; after -&#x2013;&#x2014;
primfn(A_1: handle, B_1: handle, C_1: handle) -&gt; ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 512], []),
             B: Buffer(B_2: Pointer(float32), float32, [512, 64], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 64], [])}
  buffer_map = {A_1: A, B_1: B, C_1: C} {
  for (i: int32, 0, 1024) {
    for (j.outer: int32, 0, 16) {
      @tir.
    }
  }
}
</p>
</div>
</div>

<div id="outline-container-org000000c" class="outline-5">
<h5 id="org000000c"><span class="section-number-5">1.1.3.3</span> parallel</h5>
<div class="outline-text-5" id="text-1-1-3-3">
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> te

<span class="org-variable-name">n</span> = 1024
<span class="org-variable-name">m</span> = 1024

<span class="org-variable-name">A</span> = te.placeholder((n, m), name=<span class="org-string">"A"</span>)
<span class="org-variable-name">l</span> = te.reduce_axis((0, m), name=<span class="org-string">"l"</span>)

<span class="org-variable-name">B</span> = te.compute((n,), <span class="org-keyword">lambda</span> i: te.<span class="org-builtin">sum</span>(A[i, l], axis=l), name=<span class="org-string">"B"</span>)

<span class="org-variable-name">s</span> = te.create_schedule(B.op)

<span class="org-keyword">print</span>(tvm.lower(s, [A, B], simple_mode=<span class="org-constant">True</span>))
<span class="org-keyword">print</span>(<span class="org-string">"---------cutting line---------"</span>)

s[B].parallel(B.op.reduce_axis[0])
<span class="org-keyword">print</span>(tvm.lower(s, [A, B], simple_mode=<span class="org-constant">True</span>))
</pre>
</div>

<p>
primfn(A_1: handle, B_1: handle) -&gt; ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {B: Buffer(B_2: Pointer(float32), float32, [1024], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], [])}
  buffer_map = {A_1: A, B_1: B} {
  for (i: int32, 0, 1024) {
    B_2[i] = 0f32
    for (l: int32, 0, 1024) {
      B_2[i] = ((float32*)B_2[i] + (float32*)A_2[((i*1024) + l)])
    }
  }
}
</p>


<p>
----&#x2013;&#x2014;cutting line----&#x2013;&#x2014;
primfn(A_1: handle, B_1: handle) -&gt; ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {B: Buffer(B_2: Pointer(float32), float32, [1024], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], [])}
  buffer_map = {A_1: A, B_1: B} {
  for (i: int32, 0, 1024) {
    B_2[i] = 0f32
    for (l: int32, 0, 1024) "parallel" {
      B_2[i] = ((float32*)B_2[i] + (float32*)A_2[((i*1024) + l)])
    }
  }
}
</p>
</div>
</div>

<div id="outline-container-org000000f" class="outline-5">
<h5 id="org000000f"><span class="section-number-5">1.1.3.4</span> vectorize</h5>
</div>

<div id="outline-container-org0000012" class="outline-5">
<h5 id="org0000012"><span class="section-number-5">1.1.3.5</span> tile</h5>
</div>

<div id="outline-container-org0000015" class="outline-5">
<h5 id="org0000015"><span class="section-number-5">1.1.3.6</span> reorder</h5>
</div>

<div id="outline-container-org0000018" class="outline-5">
<h5 id="org0000018"><span class="section-number-5">1.1.3.7</span> compute_at</h5>
</div>

<div id="outline-container-org000001b" class="outline-5">
<h5 id="org000001b"><span class="section-number-5">1.1.3.8</span> compute_inline</h5>
</div>

<div id="outline-container-org000001e" class="outline-5">
<h5 id="org000001e"><span class="section-number-5">1.1.3.9</span> compute_root</h5>
</div>

<div id="outline-container-org0000021" class="outline-5">
<h5 id="org0000021"><span class="section-number-5">1.1.3.10</span> fuse</h5>
<div class="outline-text-5" id="text-1-1-3-10">
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> te

<span class="org-variable-name">n</span> = 1024
<span class="org-variable-name">A</span> = te.placeholder((n,), name=<span class="org-string">"A"</span>)
<span class="org-variable-name">k</span> = te.reduce_axis((0, n), name=<span class="org-string">"k"</span>)

<span class="org-variable-name">B</span> = te.compute((1,), <span class="org-keyword">lambda</span> i: te.<span class="org-builtin">sum</span>(A[k], axis=k), name=<span class="org-string">"B"</span>)

<span class="org-variable-name">s</span> = te.create_schedule(B.op)

<span class="org-variable-name">ko</span>, <span class="org-variable-name">ki</span> = s[B].split(B.op.reduce_axis[0], factor=32)

<span class="org-keyword">print</span>(<span class="org-string">"------before------"</span>)
<span class="org-keyword">print</span>(tvm.lower(s, [A, B], simple_mode=<span class="org-constant">True</span>))

s[B].fuse(ko, ki)
<span class="org-keyword">print</span>(<span class="org-string">"------after------"</span>)
<span class="org-keyword">print</span>(tvm.lower(s, [A, B], simple_mode=<span class="org-constant">True</span>))
</pre>
</div>

<p>
-&#x2013;&#x2014;before-&#x2013;&#x2014;
primfn(A_1: handle, B_1: handle) -&gt; ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {B: Buffer(B_2: Pointer(float32), float32, [1], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024], [])}
  buffer_map = {A_1: A, B_1: B} {
  B_2[0] = 0f32
  for (k.outer: int32, 0, 32) {
    for (k.inner: int32, 0, 32) {
      B_2[0] = ((float32*)B_2[0] + (float32*)A_2[((k.outer*32) + k.inner)])
    }
  }
}
</p>


<p>
-&#x2013;&#x2014;after-&#x2013;&#x2014;
primfn(A_1: handle, B_1: handle) -&gt; ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {B: Buffer(B_2: Pointer(float32), float32, [1], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024], [])}
  buffer_map = {A_1: A, B_1: B} {
  B_2[0] = 0f32
  for (k.outer.k.inner.fused: int32, 0, 1024) {
    B_2[0] = ((float32*)B_2[0] + (float32*)A_2[k.outer.k.inner.fused])
  }
}
</p>
</div>
</div>

<div id="outline-container-org0000024" class="outline-5">
<h5 id="org0000024"><span class="section-number-5">1.1.3.11</span> bind</h5>
</div>
</div>

<div id="outline-container-org000002a" class="outline-4">
<h4 id="org000002a"><span class="section-number-4">1.1.4</span> Injective Schedule</h4>
<div class="outline-text-4" id="text-1-1-4">
<p>
<a href="https://en.wikipedia.org/wiki/Injective_function">https://en.wikipedia.org/wiki/Injective_function</a>
</p>

<p>
injective function 即单射函数, 也称为 one-to-one function, 在 TVM 中, 有大量的符合 injective 定义的 op 都使用同一个 schedule: schedule_injective, 因为它们执行时除了具体的运算不同, schedule 的要求实际上是一样的.
</p>

<p>
TVM 提供了几个函数来指定 schedule_injective 做为 schedule:
</p>

<ol class="org-ol">
<li>register_injective_schedule</li>
<li>register_broadcast_schedule</li>
</ol>

<p>
例如:
</p>

<div class="org-src-container">
<pre class="src src-python">register_broadcast_schedule(<span class="org-string">"log"</span>)
register_broadcast_schedule(<span class="org-string">"log2"</span>)
register_broadcast_schedule(<span class="org-string">"log10"</span>)
register_broadcast_schedule(<span class="org-string">"tan"</span>)
register_broadcast_schedule(<span class="org-string">"cos"</span>)
register_broadcast_schedule(<span class="org-string">"cosh"</span>)
register_broadcast_schedule(<span class="org-string">"sin"</span>)
register_broadcast_schedule(<span class="org-string">"sinh"</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">...</span>
register_broadcast_schedule(<span class="org-string">"add"</span>)
register_broadcast_schedule(<span class="org-string">"subtract"</span>)
register_broadcast_schedule(<span class="org-string">"multiply"</span>)
register_broadcast_schedule(<span class="org-string">"divide"</span>)
register_broadcast_schedule(<span class="org-string">"floor_divide"</span>)
register_broadcast_schedule(<span class="org-string">"power"</span>)
register_broadcast_schedule(<span class="org-string">"copy"</span>)
register_broadcast_schedule(<span class="org-string">"logical_not"</span>)
register_broadcast_schedule(<span class="org-string">"logical_and"</span>)
register_broadcast_schedule(<span class="org-string">"logical_or"</span>)
register_broadcast_schedule(<span class="org-string">"logical_xor"</span>)
register_broadcast_schedule(<span class="org-string">"bitwise_not"</span>)
register_broadcast_schedule(<span class="org-string">"bitwise_and"</span>)
register_broadcast_schedule(<span class="org-string">"bitwise_or"</span>)
register_broadcast_schedule(<span class="org-string">"bitwise_xor"</span>)
register_broadcast_schedule(<span class="org-string">"negative"</span>)
register_broadcast_schedule(<span class="org-string">"mod"</span>)
register_broadcast_schedule(<span class="org-string">"floor_mod"</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">...</span>
register_injective_schedule(<span class="org-string">"one_hot"</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">...</span>
</pre>
</div>

<p>
register_injective_schedule 会使用一个名为 schedule_injective 的 generic
function, 不同的 target 会通过 schedule_injective.register 注册不同的实现
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-type">@schedule_injective.register</span>(<span class="org-string">"cpu"</span>)
<span class="org-keyword">def</span> <span class="org-function-name">schedule_injective_cpu</span>(attrs, outs, target):
    <span class="org-doc">"""schedule injective ops for x86"""</span>
    <span class="org-keyword">with</span> target:
        <span class="org-keyword">return</span> topi.x86.schedule_injective(outs)


<span class="org-type">@schedule_injective.register</span>([<span class="org-string">"arm_cpu"</span>, <span class="org-string">"micro_dev"</span>])
<span class="org-keyword">def</span> <span class="org-function-name">schedule_injective_arm_cpu</span>(_, outs, target):
    <span class="org-doc">"""schedule injective ops for arm cpu"""</span>
    <span class="org-keyword">with</span> target:
        <span class="org-keyword">return</span> topi.arm_cpu.schedule_injective(outs)
</pre>
</div>

<p>
injective schedule 主要是利用 split+vectorize, 因为 vectorize (simd) 本来就是用来加速 injective 操作的
</p>
</div>
</div>

<div id="outline-container-org000002d" class="outline-4">
<h4 id="org000002d"><span class="section-number-4">1.1.5</span> Reduce Schedule</h4>
<div class="outline-text-4" id="text-1-1-5">
<p>
Reduce Schedule 与 Injective Schedule 类似, 但它针对的是 sum, max 等进行
reduction 的操作, reduce schedule 无法使用 vectorize, tvm 的实现主要是使用
<a href="#org000000c">parallel</a>
</p>

<div class="org-src-container">
<pre class="src src-python">register_reduce_schedule(<span class="org-string">"argmax"</span>)
register_reduce_schedule(<span class="org-string">"argmin"</span>)
register_reduce_schedule(<span class="org-string">"sum"</span>)
register_reduce_schedule(<span class="org-string">"all"</span>)
register_reduce_schedule(<span class="org-string">"any"</span>)
register_reduce_schedule(<span class="org-string">"max"</span>)
register_reduce_schedule(<span class="org-string">"min"</span>)
register_reduce_schedule(<span class="org-string">"prod"</span>)
register_reduce_schedule(<span class="org-string">"mean"</span>)
<span class="org-comment-delimiter"># </span><span class="org-comment">...</span>


<span class="org-type">@schedule_reduce.register</span>(<span class="org-string">"arm_cpu"</span>)
<span class="org-keyword">def</span> <span class="org-function-name">schedule_reduce_cpu</span>(attrs, outs, target):
    <span class="org-doc">"""schedule reduction ops for arm_cpu"""</span>
    <span class="org-keyword">with</span> target:
        <span class="org-keyword">return</span> topi.x86.schedule_reduce(outs)


<span class="org-type">@schedule_reduce.register</span>(<span class="org-string">"cpu"</span>)
<span class="org-keyword">def</span> <span class="org-function-name">schedule_reduce_cpu</span>(attrs, outs, target):
    <span class="org-doc">"""schedule reduction ops for x86"""</span>
    <span class="org-keyword">with</span> target:
        <span class="org-keyword">return</span> topi.x86.schedule_reduce(outs)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org0000036" class="outline-3">
<h3 id="org0000036"><span class="section-number-3">1.2</span> AutoTVM</h3>
<div class="outline-text-3" id="text-1-2">
<p>
<a href="file:///home/sunway/source/tvm/gallery/tutorial/autotvm_matmul_x86.py">file:~/source/tvm/gallery/tutorials/autotvm_matmul_x86.py</a>
</p>
</div>

<div id="outline-container-org0000033" class="outline-4">
<h4 id="org0000033"><span class="section-number-4">1.2.1</span> <a href="micro_tvm.html#org0000001">MicroTVM 与 AutoTVM</a></h4>
</div>
</div>

<div id="outline-container-org0000054" class="outline-3">
<h3 id="org0000054"><span class="section-number-3">1.3</span> TVM Auto Scheduler</h3>
<div class="outline-text-3" id="text-1-3">
<p>
<a href="file:///home/sunway/source/tvm/gallery/tutorial/auto_scheduler_matmul_x86.py">file:~/source/tvm/tutorials/get_started/auto_scheduler_matmul_x86.py</a>
</p>

<p>
<a href="https://tvm.apache.org/docs/tutorials/index.html#autoscheduler-template-free-auto-scheduling">https://tvm.apache.org/docs/tutorials/index.html#autoscheduler-template-free-auto-scheduling</a>
<a href="https://tvm.apache.org/docs/tutorials/get_started/auto_scheduler_matmul_x86.html?highlight=auto">https://tvm.apache.org/docs/tutorials/get_started/auto_scheduler_matmul_x86.html?highlight=auto</a>
</p>
</div>

<div id="outline-container-org0000039" class="outline-4">
<h4 id="org0000039"><span class="section-number-4">1.3.1</span> Testing Function</h4>
<div class="outline-text-4" id="text-1-3-1">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">-*- coding: utf-8 -*-</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">2021-08-09 17:16</span>
<span class="org-keyword">import</span> os

<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> tvm
<span class="org-keyword">from</span> tvm <span class="org-keyword">import</span> te, auto_scheduler

<span class="org-variable-name">N</span> = <span class="org-variable-name">L</span> = <span class="org-variable-name">M</span> = 1024
<span class="org-variable-name">target</span> = tvm.target.Target(<span class="org-string">"llvm -mcpu=skylake-avx512"</span>)

<span class="org-variable-name">A</span> = tvm.nd.array(np.random.uniform(size=(N, L)).astype(np.float32))
<span class="org-variable-name">B</span> = tvm.nd.array(np.random.uniform(size=(L, M)).astype(np.float32))
<span class="org-variable-name">C</span> = tvm.nd.array(np.random.uniform(size=(N, M)).astype(np.float32))
<span class="org-variable-name">OUT</span> = tvm.nd.empty((N, M))


<span class="org-keyword">def</span> <span class="org-function-name">eval</span>(sch, args):
    <span class="org-comment-delimiter"># </span><span class="org-comment">print(tvm.lower(sch, args))</span>
    <span class="org-variable-name">func</span> = tvm.build(sch, args, target)
    <span class="org-variable-name">evaluator</span> = func.time_evaluator(func.entry_name, tvm.cpu())
    <span class="org-keyword">print</span>(
        <span class="org-string">"Execution time of this operator: %.3f ms"</span>
        % (np.median(evaluator(A, B, C, OUT).results) * 100)
    )


<span class="org-type">@auto_scheduler.register_workload</span>
<span class="org-keyword">def</span> <span class="org-function-name">matmul_add</span>(N, L, M, dtype):
    <span class="org-variable-name">A</span> = te.placeholder((N, L), name=<span class="org-string">"A"</span>, dtype=dtype)
    <span class="org-variable-name">B</span> = te.placeholder((L, M), name=<span class="org-string">"B"</span>, dtype=dtype)
    <span class="org-variable-name">C</span> = te.placeholder((N, M), name=<span class="org-string">"C"</span>, dtype=dtype)

    <span class="org-variable-name">k</span> = te.reduce_axis((0, L), name=<span class="org-string">"k"</span>)
    <span class="org-variable-name">matmul</span> = te.compute(
        (N, M),
        <span class="org-keyword">lambda</span> i, j: te.<span class="org-builtin">sum</span>(A[i, k] * B[k, j], axis=k),
        name=<span class="org-string">"matmul"</span>,
        attrs={<span class="org-string">"layout_free_placeholders"</span>: [B]},
    )
    <span class="org-variable-name">out</span> = te.compute((N, M), <span class="org-keyword">lambda</span> i, j: matmul[i, j] + C[i, j], name=<span class="org-string">"out"</span>)

    <span class="org-keyword">return</span> [A, B, C, out]

</pre>
</div>
</div>
</div>

<div id="outline-container-org000003c" class="outline-4">
<h4 id="org000003c"><span class="section-number-4">1.3.2</span> AutoScheduler Tunning</h4>
<div class="outline-text-4" id="text-1-3-2">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">task</span> = tvm.auto_scheduler.SearchTask(
    func=matmul_add, args=(N, L, M, <span class="org-string">"float32"</span>), target=target
)
<span class="org-variable-name">log_file</span> = <span class="org-string">"/tmp/matmul.json"</span>

<span class="org-keyword">print</span>(<span class="org-string">"-------------------- tunning --------------------"</span>)
<span class="org-variable-name">tune_option</span> = auto_scheduler.TuningOptions(
    num_measure_trials=10,
    measure_callbacks=[auto_scheduler.RecordToFile(log_file)],
    verbose=1,
)
task.tune(tune_option)
</pre>
</div>

<p>
---------------&#x2013;&#x2014; tunning ---------------&#x2013;&#x2014;
</p>
<hr />
<p>
-------------------------&#x2013;&#x2014;  [ Search ]
</p>
<hr />
<p>
Generate Sketches		#s: 3
Sample Initial Population	#s: 2015	fail_ct: 1	Time elapsed: 0.67
GA Iter: 0	Max score: 0.9998	Min score: 0.9348	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9887	#Pop: 128	#M+: 1381	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 2.90
</p>
<hr />
<p>
-------------------------&#x2013;&#x2014;  [ Measure ]
</p>
<hr />
<p>
Get 10 programs to measure:
&#x2026;&#x2026;&#x2026;.*T*T*T*T*T*T*T*T*T*T
Time elapsed for measurement: 101.94 s
</p>
<hr />
<p>
-------------------------&#x2013;&#x2014;  [ Done ]
</p>
<hr />
<p>
No valid state found in this search round. Check if it has traversed all of the search space.
</p>
</div>
</div>

<div id="outline-container-org000003f" class="outline-4">
<h4 id="org000003f"><span class="section-number-4">1.3.3</span> Evaluation</h4>
<div class="outline-text-4" id="text-1-3-3">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">print</span>(<span class="org-string">"-------------------- orig_scheuler--------------------"</span>)
<span class="org-variable-name">args</span> = matmul_add(N, L, M, <span class="org-string">"float32"</span>)
<span class="org-variable-name">sch</span> = te.create_schedule(args[-1].op)
<span class="org-builtin">eval</span>(sch, args)

<span class="org-keyword">print</span>(<span class="org-string">"-------------------- auto_scheuler--------------------"</span>)
<span class="org-variable-name">sch</span>, <span class="org-variable-name">args</span> = task.apply_best(log_file)
<span class="org-builtin">eval</span>(sch, args)
</pre>
</div>

<p>
---------------&#x2013;&#x2014; orig_scheuler---------------&#x2013;&#x2014;
Execution time of this operator: 287.769 ms
---------------&#x2013;&#x2014; auto_scheuler---------------&#x2013;&#x2014;
Execution time of this operator: 6.305 ms
</p>
</div>
</div>

<div id="outline-container-org000004e" class="outline-4">
<h4 id="org000004e"><span class="section-number-4">1.3.4</span> Auto Scheduler Internals</h4>
<div class="outline-text-4" id="text-1-3-4">
<p>
auto_scheduler 要解决的问题是:
</p>

<p>
定义一个 schedule 参数的搜索空间, 通过一个 measure 函数在这个空间中 sample, 然后基于这些 sample 用 cost_model 预测最佳的 schedule 参数
</p>
</div>

<div id="outline-container-org0000042" class="outline-5">
<h5 id="org0000042"><span class="section-number-5">1.3.4.1</span> SearchTask</h5>
<div class="outline-text-5" id="text-1-3-4-1">
<div class="org-src-container">
<pre class="src src-python">SearchTask.init:
    <span class="org-comment-delimiter"># </span><span class="org-comment">SearchTask &#25509;&#21463;&#19968;&#20010; target &#21442;&#25968;, &#36825;&#20010;&#21442;&#25968;&#21487;&#20197;&#21578;&#35785; builder &#29983;&#25104;&#38024;&#23545;&#21738;&#20010; target &#30340;&#20195;&#30721; </span>

SearchTask.tune: 
    <span class="org-keyword">if</span> search_policy <span class="org-keyword">is</span> <span class="org-constant">None</span>:
        <span class="org-comment-delimiter"># </span><span class="org-comment">&#40664;&#35748;&#20351;&#29992; xgboost &#26469;&#39044;&#27979;</span>
        <span class="org-variable-name">cost_model</span> = XGBModel()
        <span class="org-variable-name">search_policy</span> = SketchPolicy(<span class="org-keyword">self</span>, cost_model)

    _ffi_api.AutoSchedule(search_policy, tuning_options)

AutoSchedule:
    <span class="org-comment-delimiter"># </span><span class="org-comment">tuning_options-&gt;builder &#30340;&#40664;&#35748;&#20540;&#26159; LocalBuilder</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">tuning_options-&gt;runner &#30340;&#40664;&#35748;&#20540;&#26159; LocalRunner</span>
    ProgramMeasurer <span class="org-variable-name">measurer</span> =
      ProgramMeasurer(tuning_options-&gt;builder, tuning_options-&gt;runner,
                      tuning_options-&gt;measure_callbacks, tuning_options-&gt;verbose);    

    State <span class="org-variable-name">state</span> =
        search_policy-&gt;Search(tuning_options-&gt;num_measure_trials, tuning_options-&gt;early_stopping,
                            tuning_options-&gt;num_measures_per_round, measurer);
    <span class="org-keyword">return</span> search_policy-&gt;search_task-&gt;compute_dag.ApplySteps(state-&gt;transform_steps);

SketchPolicy::Search:
    <span class="org-comment-delimiter"># </span><span class="org-comment">MeasureInput &#21253;&#21547;&#20102; schedule &#21442;&#25968;</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">MeasureResult &#21253;&#21547;&#38024;&#23545;&#19968;&#22871;&#21442;&#25968; measure &#21518;&#30340;&#32467;&#26524; (cost, ...)</span>
    Array&lt;MeasureInput&gt; inputs;
    Array&lt;MeasureResult&gt; results;
    <span class="org-keyword">while</span> (ct &lt; n_trials):
        <span class="org-comment-delimiter"># </span><span class="org-comment">train xgboost, inputs &#30456;&#24403;&#20110; x, results &#30456;&#24403;&#20110; y</span>
        program_cost_model-&gt;Update(inputs, results);

        <span class="org-comment-delimiter"># </span><span class="org-comment">sample &#20986;&#26032;&#30340;&#21442;&#25968;</span>
        <span class="org-variable-name">inputs</span> = PickStatesWithEpsGreedy(best_states, random_states, n_trials - ct);
        <span class="org-comment-delimiter"># </span><span class="org-comment">measure &#36825;&#20123;&#21442;&#25968;</span>
        <span class="org-variable-name">results</span> = measurer-&gt;Measure(search_task, GetRef&lt;SearchPolicy&gt;(this), inputs);        

    <span class="org-keyword">return</span> measurer-&gt;best_state[search_task-&gt;workload_key];        
</pre>
</div>
</div>
</div>

<div id="outline-container-org000004b" class="outline-5">
<h5 id="org000004b"><span class="section-number-5">1.3.4.2</span> Measure</h5>
<div class="outline-text-5" id="text-1-3-4-2">
<div class="org-src-container">
<pre class="src src-c++"><span class="org-constant">ProgramMeasurerNode</span>::Measure:
  <span class="org-comment-delimiter">// </span><span class="org-comment">tvm &#40664;&#35748;&#20250;&#21516;&#26102; measure &#22810;&#22871;&#21442;&#25968;</span>
  <span class="org-keyword">if</span> (batch_size == -1) {
    <span class="org-comment-delimiter">// </span><span class="org-comment">set default batch size</span>
    batch_size = builder-&gt;n_parallel * 2;
  }
  <span class="org-keyword">for</span> (<span class="org-type">size_t</span> <span class="org-variable-name">i</span> = 0; i &lt; inputs.size(); i += batch_size):
    <span class="org-type">Array</span>&lt;MeasureInput&gt; <span class="org-function-name">input_batch</span>(inputs.begin() + i,
                                      inputs.begin() + <span class="org-constant">std</span>::min(i + batch_size, inputs.size()));
    <span class="org-type">Array</span>&lt;MeasureResult&gt; <span class="org-variable-name">result_batch</span>;
    SilentMeasure(task, input_batch, &amp;result_batch);
    <span class="org-keyword">for</span> (<span class="org-keyword">auto</span>&amp; <span class="org-variable-name">res</span> : result_batch) : 
      results.push_back(res);

  <span class="org-keyword">return</span> results;
</pre>
</div>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-constant">SilentMeasure</span>:
  <span class="org-type">Array</span>&lt;BuildResult&gt; <span class="org-variable-name">build_res_batch</span> = builder-&gt;Build(inputs, verbose);
  <span class="org-type">Array</span>&lt;MeasureResult&gt; <span class="org-variable-name">result_batch</span> = runner-&gt;Run(inputs, build_res_batch, verbose);

  <span class="org-comment-delimiter">// </span><span class="org-comment">Store result batch</span>
  <span class="org-keyword">for</span> (<span class="org-keyword">auto</span>&amp; <span class="org-variable-name">res</span> : result_batch) {
    results-&gt;push_back(res);
  }
</pre>
</div>
</div>

<div id="outline-container-org0000045" class="outline-6">
<h6 id="org0000045"><span class="section-number-6">1.3.4.2.1</span> builder.Build</h6>
<div class="outline-text-6" id="text-1-3-4-2-1">
<p>
builder 是一个 ProgramBuilder 接口, LocalBuilder 是一个参考实现. 注: 虽然
TuningOptions 指定的 builder 是 python 对象, 最终调用是在 c++ 代码中
(SilentMeasure), 所以实现一个自定义的 builder 有两种选择:
</p>

<ol class="org-ol">
<li>模仿 LocalBuilder 的写法, 用 c++ 来实现, 然后通过 Registry 再调回到 python</li>
<li>使用 LocalBuilder, 但需要提供一个 python 实现的和 ndk.create_shared 或
tar.tar 类似的自定义 build_func</li>
</ol>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">class</span> <span class="org-type">LocalBuilder</span>(ProgramBuilder):
    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>, timeout=15, n_parallel=multiprocessing.cpu_count(), build_func=<span class="org-string">"default"</span>):
        <span class="org-keyword">if</span> build_func == <span class="org-string">"default"</span>:
            <span class="org-variable-name">BuildFunc.name</span> = <span class="org-string">"default"</span>
            <span class="org-variable-name">BuildFunc.build_func</span> = tar.tar
        <span class="org-keyword">elif</span> build_func == <span class="org-string">"ndk"</span>:
            <span class="org-variable-name">BuildFunc.name</span> = <span class="org-string">"ndk"</span>
            <span class="org-variable-name">BuildFunc.build_func</span> = ndk.create_shared
        <span class="org-keyword">elif</span> <span class="org-builtin">callable</span>(build_func):
            <span class="org-variable-name">BuildFunc.name</span> = <span class="org-string">"custom"</span>
            <span class="org-variable-name">BuildFunc.build_func</span> = build_func
        <span class="org-keyword">else</span>:
            <span class="org-keyword">raise</span> <span class="org-type">ValueError</span>(<span class="org-string">"Invalid build_func"</span> + build_func)

        <span class="org-keyword">self</span>.__init_handle_by_constructor__(
            _ffi_api.LocalBuilder, timeout, n_parallel, BuildFunc.name
        )

</pre>
</div>

<p>
c++ LocalBuilder 会通过 ffi 调用回 python 的 local_builder_build
</p>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-type">Array</span>&lt;BuildResult&gt; <span class="org-constant">LocalBuilderNode</span>::<span class="org-function-name">Build</span>(<span class="org-keyword">const</span> <span class="org-type">Array</span>&lt;MeasureInput&gt;&amp; <span class="org-variable-name">inputs</span>, <span class="org-type">int</span> <span class="org-variable-name">verbose</span>) {
  <span class="org-keyword">if</span> (<span class="org-keyword">const</span> <span class="org-keyword">auto</span>* <span class="org-variable-name">f</span> = <span class="org-constant">runtime</span>::<span class="org-constant">Registry</span>::Get(<span class="org-string">"auto_scheduler.local_builder.build"</span>)) {
    <span class="org-type">Array</span>&lt;BuildResult&gt; <span class="org-variable-name">results</span> = (*f)(inputs, timeout, n_parallel, build_func, verbose);
    <span class="org-keyword">return</span> results;
  }
}
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">local_builder_build</span>(inputs, timeout, n_parallel, build_func=<span class="org-string">"default"</span>, verbose=1):
    <span class="org-variable-name">pool</span> = multiprocessing.pool.ThreadPool(n_parallel)
    <span class="org-variable-name">tuple_res</span> = pool.<span class="org-builtin">map</span>(
        local_build_worker,
        [
            (
                i.serialize(),
                build_func,
                timeout,
                verbose,
            )
            <span class="org-keyword">for</span> i <span class="org-keyword">in</span> inputs
        ],
    )

    <span class="org-variable-name">results</span> = []
    <span class="org-keyword">for</span> res <span class="org-keyword">in</span> tuple_res:
        results.append(BuildResult(*res))

    <span class="org-keyword">return</span> results

<span class="org-keyword">def</span> <span class="org-function-name">local_build_worker</span>(args):
    <span class="org-variable-name">build_func</span> = BuildFunc.build_func
    <span class="org-variable-name">res</span> = call_func_with_timeout(timeout, _timed_func, args=(inp, build_func, verbose))

</pre>
</div>

<p>
最终的 build 过程:
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">_timed_func</span>(inp_serialized, build_func, verbose):
    <span class="org-variable-name">inp</span> = MeasureInput.deserialize(inp_serialized)
    <span class="org-variable-name">task</span> = inp.task
    <span class="org-variable-name">sch</span>, <span class="org-variable-name">args</span> = task.compute_dag.apply_steps_from_state(
        inp.state, layout_rewrite=task.layout_rewrite_option
    )

    <span class="org-variable-name">dirname</span> = tempfile.mkdtemp()
    <span class="org-variable-name">filename</span> = os.path.join(dirname, <span class="org-string">"tmp_func."</span> + build_func.output_format)

    <span class="org-keyword">with</span> transform.PassContext():
        <span class="org-variable-name">func</span> = build_module.build(sch, args, target=task.target)
    func.export_library(filename, build_func)

    <span class="org-keyword">return</span> filename, args, error_no, error_msg, time.time() - tic

</pre>
</div>
</div>
</div>

<div id="outline-container-org0000048" class="outline-6">
<h6 id="org0000048"><span class="section-number-6">1.3.4.2.2</span> runner.Run</h6>
<div class="outline-text-6" id="text-1-3-4-2-2">
<p>
runner 的调用过程和 builder 类似 (python-&gt;c++-&gt;python), 但实现一个自定义的
runner 时没有类似于 build_func 的东西, 需要参照 _timed_eval_func 从头实现, 比较重要的信息是从 build_res 可以拿到 builder.Build 生成的文件名
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">_timed_eval_func</span>(
    inp_serialized,
    build_res,
    number,
    repeat,
    min_repeat_ms,
    cooldown_interval,
    enable_cpu_cache_flush,
    verbose,
):
    <span class="org-variable-name">inp</span> = MeasureInput.deserialize(inp_serialized)
    <span class="org-variable-name">task_input_names</span> = inp.task.task_input_names

    <span class="org-variable-name">func</span> = module.load_module(build_res.filename)
    <span class="org-variable-name">dev</span> = ndarray.device(<span class="org-builtin">str</span>(inp.task.target), 0)

    <span class="org-variable-name">time_f</span> = func.time_evaluator(
        func.entry_name,
        dev,
        number=number,
        repeat=repeat,
        min_repeat_ms=min_repeat_ms,
        f_preproc=f_prepare,
    )

    <span class="org-variable-name">random_fill</span> = tvm.get_global_func(<span class="org-string">"tvm.contrib.random.random_fill"</span>, <span class="org-constant">True</span>)

    <span class="org-variable-name">tensor_input_map</span> = prepare_input_map(build_res.args) <span class="org-keyword">if</span> task_input_names <span class="org-keyword">else</span> {}
    <span class="org-variable-name">args</span> = []
    <span class="org-variable-name">task_inputs_count</span> = 0
    <span class="org-keyword">for</span> arg <span class="org-keyword">in</span> build_res.args:
        <span class="org-keyword">if</span> arg <span class="org-keyword">in</span> tensor_input_map:
            <span class="org-variable-name">tensor_name</span> = tensor_input_map[arg]
            <span class="org-keyword">if</span> tensor_name <span class="org-keyword">in</span> task_input_names:
                args.append(
                    ndarray.array(
                        get_task_input_buffer(inp.task.workload_key, tensor_name), dev
                    )
                )
                <span class="org-variable-name">task_inputs_count</span> += 1
        <span class="org-keyword">else</span>:
            <span class="org-variable-name">empty_array</span> = ndarray.empty(get_const_tuple(arg.shape), arg.dtype, dev)
            random_fill(empty_array)
            args.append(empty_array)
        <span class="org-variable-name">costs</span> = time_f(*args).results

    <span class="org-keyword">return</span> costs, error_no, error_msg, toc - tic + build_res.time_cost, toc
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-org0000051" class="outline-4">
<h4 id="org0000051"><span class="section-number-4">1.3.5</span> Auto Scheduler and MicroTVM</h4>
<div class="outline-text-4" id="text-1-3-5">
<p>
auto_scheduler 自带实现的:
</p>

<ol class="org-ol">
<li>builder

<ul class="org-ul">
<li><p>
LocalBuilder
</p>

<p>
多进程, 最终调用 build_module.build 及 export_library
</p></li>
</ul></li>

<li>runner

<ul class="org-ul">
<li><p>
LocalRunner
</p>

<p>
单进程, 在本地 CPU 上执行, 所以非本机 target 编译的 module 无法用 LocalRunner
</p></li>

<li><p>
RPCRunner
</p>

<p>
多进程, 使用 RPC 在多个远端的 target 设备上执行, 所以这种方式可以并行执行,
而且可以执行为其它 target 编译的 module, 但现在的实现是依赖于一个基于 TCP
的中心 tracker 来连接 PC 和多个 target 设备, 和 MicroTVM 自己那一套基于串口
RPC 机制没有任何关系
</p></li>
</ul></li>
</ol>

<p>
虽然 MicroTVM 有一套自己的 Flasher, Transport 以及 RPC 机制, 现在看和
auto_scheduler 并不能一起工作, 为了让 auto_scheduler 支持 MicroTVM, 需要自己实现
builder 和 runner,
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">

<p class="author">Author: sunway (sunwayforever@gmail.com)<br />
Date: 2021-08-03 Tue 00:00<br />
Last updated: 2022-01-24 Mon 19:34</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
<br />

<div id="disqus_thread"></div>
<script>

(function() { // DON'T EDIT BELOW THIS LINE
         var d = document, s = d.createElement('script');
         s.src = '//sunwayforever-github-io.disqus.com/embed.js';
         s.setAttribute('data-timestamp', +new Date());
         (d.head || d.body).appendChild(s);
         })();
</script>
</div>
</body>
</html>
